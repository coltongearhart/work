[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Work",
    "section": "",
    "text": "Overview\nThese notes are to prepare for Exam 5, which covers basic techniques for ratemaking and estimating claim liabilities.\n\n\n\n\n\n\n\n\n\n\nQuarto blog publish details\n\n\n\nThis book was created using Quarto and published with Github Pages.\n\n\n\n\n\n\n\n\nGithub repository for code\n\n\n\nYou can find the code to reproduce this project at coltongearhart/exam5.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "macros.html",
    "href": "macros.html",
    "title": "1  Macros (Excel VBA)",
    "section": "",
    "text": "1.1 Stillwater",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Macros (Excel VBA)</span>"
    ]
  },
  {
    "objectID": "macros.html#stillwater",
    "href": "macros.html#stillwater",
    "title": "1  Macros (Excel VBA)",
    "section": "",
    "text": "1.1.1 Sort tasks\n\n\n\n1.1.2 Run sim inputs\n\n\n\n1.1.3 Select columns to new tab",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Macros (Excel VBA)</span>"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "\n2  R\n",
    "section": "",
    "text": "2.1 Stillwater",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R</span>"
    ]
  },
  {
    "objectID": "r.html#stillwater",
    "href": "r.html#stillwater",
    "title": "\n2  R\n",
    "section": "",
    "text": "2.1.1 Tiering analysis - Claims\n\n### ---- Load packages and define functions ---- \n\nlibrary(tidyverse)\nlibrary(magrittr)\n\n# define function to set close information to latest transaction where running case reserve is zero\nset_claim_close_info &lt;- function(df){\n  \n  df %&lt;&gt;% \n    mutate(flag_nonzero_case_res_rsum = cumsum(case_res_rsum != 0)) %&gt;% \n    mutate(.by = flag_nonzero_case_res_rsum,\n           row_id = row_number()) %&gt;% \n    filter(flag_nonzero_case_res_rsum == max(flag_nonzero_case_res_rsum),\n           row_id == 2) %&gt;% \n    mutate(claim_close = 1,\n           close_date = as.character.POSIXt(transaction_date),\n           .keep = \"unused\") %&gt;% # just doesn't add rows if no data returned from previous step ==&gt; claim_close = NA\n    {. -&gt;&gt; tmp} %&gt;% \n    select(starts_with(\"transaction\"), claim_close) %&gt;% \n    right_join(df, by = join_by(transaction_id)) %&gt;% \n    mutate(claim_close = ifelse(is.na(claim_close), 0, claim_close),\n           close_date = ifelse(is_empty(tmp$close_date), NA, tmp$close_date)) %&gt;% \n    arrange(transaction_date, transaction_id) %&gt;% \n    relocate(transaction_id, .before = transaction_date) %&gt;% \n    relocate(close_date, .after= loss_date) %&gt;% \n    relocate(claim_close, .after = transaction_date)\n  \n  return(df)\n  \n}\n\n### ---- Load data: SQL ----\n\n# establish connection\ncon &lt;- DBI::dbConnect(odbc::odbc(),\n                      Driver = \"SQL Server\",\n                      Server = \"XXXXXXXXX\\\\XXXXXXX\",\n                      trusted_connection = TRUE)\n\n# run queries to get raw data from AS400\n# -&gt; MTD claims data\ndata_claims_mtd_raw &lt;- DBI::dbGetQuery(con, \"select * from pricing.CLT.tiering_analysis_BPCLM_raw\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(data_pull_date = ymd(data_pull_date),\n         peril_code = trimws(peril_code))\n\n# -&gt; transactional claims data\ndata_claims_tr_raw &lt;- DBI::dbGetQuery(con, \"select * from pricing.CLT.tiering_analysis_BPCLMTR_raw\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(data_pull_date = data_pull_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd)\n\n# close connection\nDBI::dbDisconnect(con)\n\n### ---- Modify transactional claims data ----\n\n# modify transactional claims data\n# -&gt; calculate running sums (used to calculate indicators)\n# -&gt; calculate closing information\n# -&gt; summarize by claim\ndata_claims_tr &lt;- data_claims_tr_raw %&gt;% \n  mutate(.by = c(data_pull_date, policy_number, claim_no),\n         across(c(paid_loss, salv, subr, case_res, alae_paid, alae_rec, alae_res),\n                ~ round(cumsum(.x), 5),\n                .names = \"{.col}_rsum\")\n  ) %&gt;% \n  group_by(data_pull_date, policy_number, claim_no) %&gt;% \n  group_modify(~ set_claim_close_info(.x)) %&gt;% \n  ungroup() %&gt;% \n  mutate(claim_cwp = ifelse(claim_close == 1 & paid_loss_rsum - salv_rsum - subr_rsum &gt; 0, 1, 0),\n         claim_cwop = ifelse(claim_close == 1 & paid_loss_rsum - salv_rsum - subr_rsum &lt;= 0, 1, 0)) %&gt;% \n  summarize(.by = c(data_pull_date, policy_number, company, state, claim_no, iso_code),\n            across(c(ends_with(\"date\"), -transaction_date), max),\n            last_transaction_date = max(transaction_date),\n            across(c(claim_close, claim_cwp, claim_cwop, paid_loss, salv, subr, case_res, alae_paid, alae_rec, alae_res), ~ round(sum(.x), 5)))\n\n### ---- Join data ----\n\n# join claims datasets\n# -&gt; data checks passed (only recent claim activity was different in terms of the financials)\n# --&gt; so only keeping financial data from one source (OPEU123/6 rather than Majesco) and for non-close dates\n# --&gt; but using Majesco as primary source for claim count data\ndata_claims &lt;- data_claims_mtd_raw %&gt;% \n  full_join(data_claims_tr, by = join_by(pol_num == policy_number, claim_num == claim_no)) %&gt;% \n  # mutate(check_paid_loss = paid_loss - mtd_paid_loss,\n  #        check_salv = salv - mtd_salv,\n  #        check_subr = subr - mtd_subr,\n  #        check_case_res = case_res - mtd_case_res,\n  #        check_alae_paid = alae_paid - mtd_alae_paid,\n  #        check_alae_res = alae_res - mtd_alae_res,\n  #        check_inc_loss = round(mtd_paid_loss - mtd_salv - mtd_subr + mtd_case_res - mtd_inc_loss, 5),\n  #        check_loss_date = loss_date - ymd(as.Date(acc_date)),\n  #        check_rep_date = ymd(as.Date(rep_date)) - reported_date)\n  mutate(pol_state = ifelse(!is.na(pol_state), pol_state, state),\n         company = ifelse(!is.na(company.x), company.x, company.y),\n         term_eff_date = term_eff_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         acc_date = ifelse(!is.na(acc_date), acc_date, loss_date) %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         rep_date = ifelse(!is.na(rep_date), rep_date, reported_date) %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         close_date = close_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         last_transaction_date = last_transaction_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         claim_close = ifelse(!is.na(claim_close), claim_close, ifelse(mtd_case_res &gt; 0, 0, 1)),\n         paid_loss_mtd = ifelse(!is.na(mtd_paid_loss), mtd_paid_loss, paid_loss),\n         salv_mtd = ifelse(!is.na(mtd_salv), mtd_salv, salv),\n         subr_mtd = ifelse(!is.na(mtd_subr), mtd_subr, subr),\n         case_res_mtd = ifelse(!is.na(mtd_case_res), mtd_case_res, case_res),\n         alae_paid_mtd = ifelse(!is.na(mtd_alae_paid), mtd_alae_paid, alae_paid),\n         alae_res_mtd = ifelse(!is.na(mtd_alae_res), mtd_alae_res, alae_res),\n         claim_cwp = ifelse(!is.na(claim_cwp), claim_cwp, ifelse(claim_close == 1 & paid_loss_mtd - salv_mtd - subr_mtd &gt; 0, 1, 0)),\n         claim_cwop = ifelse(!is.na(claim_cwop), claim_cwop, ifelse(claim_close == 1 & paid_loss_mtd - salv_mtd - subr_mtd &lt;= 0, 1, 0))) %&gt;% \n  select(pol_num, claim_num, company, pol_state, term_eff_date, acc_date, rep_date, close_date, last_transaction_date, iso_code, peril_code, claim_close, claim_cwp, claim_cwop, orig_loss_res_mtd = mtd_orig_loss_res, paid_loss_mtd, salv_mtd, subr_mtd, case_res_mtd, alae_paid_mtd, alae_rec_mtd = alae_rec, alae_res_mtd) %&gt;% \n  mutate(data_pull_date = unique(data_claims_mtd_raw$data_pull_date), # not sure why pulling the date from either data source isn't working, just assuming both pulled same day\n         peril_code = case_when(\n           peril_code %in% c(\"HAIL\", \"LIGHTNING\", \"WIND\") ~ \"WIND\",\n           is.na(peril_code) ~ \"NOT_RECORDED\",\n           peril_code == \"\" ~ \"NOT_RECORDED\",\n           .default = peril_code\n         )) %&gt;% \n  filter(year(last_transaction_date) &gt;= 2015) # last 10 years of data\n\n# save and write results\nsave(data_claims, file = \"RData\\\\data_claims.RData\")\n\n# write to csv so can upload flat file into sql\n# -&gt; just file and save as .xlsx into 'Colton Analyses' folder for David\nwrite_csv(data_claims, file = \"Excel data\\\\data_claims.csv\", na = \"\")\n\n### ---- Actuarially modify claims data ----\n\n# load data with calculated term IDs\nload(\"RData\\\\data_claims.RData\")\n\n# remove missing data claims\ndata_claims %&lt;&gt;% \n  filter(!is.na(paid_loss_mtd))\n\n# look at CAT claims\ndata_claims_cat &lt;- data_claims %&gt;% \n  filter(!is.na(iso_code))\n\n# remove CATs\ndata_claims_non_cats &lt;- data_claims %&gt;% \n  filter(is.na(iso_code))\n\n# read in LDFs\n# -&gt; source: in 'Indications q4 2024 eval q1 2025.xlsx'\n# -&gt; NOTE: these are non-CAT LDFs\ndata_ldfs &lt;- list()\ndata_ldfs$incurred_loss &lt;- readxl::read_xlsx(path = \"LDFs.xlsx\",\n                                             sheet = \"incurred_loss\")\ndata_ldfs$incurred_claim_count &lt;- readxl::read_xlsx(path = \"LDFs.xlsx\",\n                                                    sheet = \"incurred_claim_count\")\n\n# -&gt; reformat\ndata_ldfs %&lt;&gt;% \n  map(function(df) {\n    \n    df %&gt;% \n      pivot_longer(cols = everything(), names_to = \"age_to_age\", values_to = \"ldf\") %&gt;% \n      mutate(age_to_age = str_sub(age_to_age, start = 5, -1) %&gt;% str_replace(., \"_to_\", \":\"),\n             row_id = row_number()) %&gt;% \n      arrange(desc(row_id)) %&gt;% \n      mutate(cdf = cumprod(ldf)) %&gt;% \n      rowwise() %&gt;% \n      mutate(age = age_to_age %&gt;% str_sub(1, str_locate(., \":\") - 1) %&gt;% .[1] %&gt;% as.numeric) %&gt;% \n      ungroup %&gt;% \n      arrange(row_id) %&gt;% \n      select(-row_id)\n    \n  })\n\n# develop claims to ultimate individually\n# -&gt; calculate age (rounded to the nearest 3 month period (i.e. quarter))\n# -&gt; as-of-date is the start of the future policy period (described below)\nas_of_date_age &lt;- \"2025-11-03\" %&gt;% ymd %&gt;% add(months(1)) %&gt;% {paste(year(.), month(.), \"1\", sep = \"-\")} %&gt;% ymd\ndata_claims_non_cats_ult &lt;- data_claims_non_cats %&gt;% \n  mutate(age = interval(acc_date, as_of_date_age) %&gt;% divide_by(months(1)) %&gt;% as.numeric %&gt;% divide_by(3) %&gt;% ceiling %&gt;% multiply_by(3)) %&gt;% \n  rowwise %&gt;% \n  mutate(age_join = min(age, max(data_ldfs$incurred_loss$age))) %&gt;% \n  ungroup %&gt;% \n  left_join(data_ldfs$incurred_loss %&gt;% select(age, cdf_incurred_loss = cdf), by = join_by(age_join == age)) %&gt;% \n  left_join(data_ldfs$incurred_claim_count %&gt;% select(age, cdf_incurred_claim_count = cdf), by = join_by(age_join == age)) %&gt;%\n  select(-age_join) %&gt;% \n  rowwise %&gt;% \n  mutate(incurred_loss = sum(paid_loss_mtd, case_res_mtd, alae_paid_mtd, alae_res_mtd, na.rm = TRUE) - sum(salv_mtd, subr_mtd, alae_rec_mtd, na.rm = TRUE),\n         incurred_claim_count = sum(claim_close, 1 - claim_close), # add close and open claim counts ==&gt; results in 1 for every record cause we have data at claim level\n         ult_incurred_loss = round(incurred_loss * cdf_incurred_loss, 2),\n         ult_claim_count = round(incurred_claim_count * cdf_incurred_claim_count, 5)) %&gt;%\n  ungroup\n\n# trend claims individually\n# -&gt; trend selects pulled from 'Indications q4 2024 eval q1 2025.xlsx' for MA\n# -&gt; future policy period = 12/01/2025 - 12/01/2026 ==&gt; avg accident date = 12/01/2026\ntrend_freq &lt;- -0.01868\ntrend_sev &lt;- 0.08833\navg_acc_date_trend &lt;- as_of_date_age %m+% years(1)\ndata_claims_non_cats_ult_trended &lt;- data_claims_non_cats_ult %&gt;% \n  mutate(loss_trend_factor = trend_freq %&gt;% add(1) %&gt;% \n           multiply_by(trend_sev %&gt;% add(1)) %&gt;% \n           raise_to_power(interval(acc_date, avg_acc_date_trend) / years(1)),\n         trended_ult_incurred_loss = round(ult_incurred_loss * loss_trend_factor, 2))\n\n# cap large losses\ndata_claims_non_cats_ult_trended_capped &lt;- data_claims_non_cats_ult_trended %&gt;% \n  mutate(trended_ult_incurred_loss_capped = ifelse(trended_ult_incurred_loss &gt; 100000, 100000, trended_ult_incurred_loss))\n\n\n# reformat trended ult loss as by-peril\n# -&gt; calculate capped losses (still keeping original losses though)\n# -&gt; first aggregate over term effective date (i.e. policy period)\ndata_claims_non_cats_ult_trended_capped_by_peril &lt;- data_claims_non_cats_ult_trended_capped %&gt;% \n  summarize(.by = c(data_pull_date, pol_num, company, pol_state, term_eff_date, peril_code),\n            across(c(starts_with(\"trended_ult_incurred_loss\"), incurred_claim_count), sum)) %&gt;% \n  pivot_wider(names_from = peril_code, values_from = c(incurred_claim_count, trended_ult_incurred_loss, trended_ult_incurred_loss_capped)) %&gt;% \n  rowwise %&gt;% \n  mutate(incurred_claim_count = sum(`incurred_claim_count_OTHER`,\n                                    `incurred_claim_count_LIABILITY`,\n                                    `incurred_claim_count_WATERNONWEATHER`,\n                                    `incurred_claim_count_THEFT`,\n                                    `incurred_claim_count_WIND`,\n                                    `incurred_claim_count_WATERWEATHER`,\n                                    `incurred_claim_count_NOT_RECORDED`,\n                                    `incurred_claim_count_FIRE`,\n                                    `incurred_claim_count_HURRICANE`,\n                                    na.rm = TRUE),\n         .after = term_eff_date) %&gt;% \n  ungroup %&gt;% \n  rename_with(~ str_replace(.x, \"trended_ult_incurred_loss_\", \"peril_\"), starts_with(\"trended_ult_incurred_loss_\")) %&gt;% \n  rename_with(~ str_to_lower(.x), starts_with(\"peril_\"))\n\n# save results\nsave(data_claims_non_cats_ult_trended_capped_by_peril, file = \"RData\\\\data_claims_non_cats_ult_trended_capped_by_peril.RData\")\n\n### ---- Load actuarially modified data: RData ----\n\n# load data with calculated term IDs\nload(\"RData\\\\data_claims_non_cats_ult_trended_capped_by_peril.RData\")\n\n\n2.1.2 Tiering analysis - Exposure\n\n### ---- Load packages and define functions ---- \n\nlibrary(tidyverse)\nlibrary(magrittr)\n\n# define function to modify exposure data\nmodify_exposure_data &lt;- function(df_policy, df_expos) {\n  \n  # split policy data based on if / when renewed with lapse\n  df_policy_split = df_policy %&gt;% \n    nest_by(term_eff_month = month(term_eff_date), term_eff_day = day(term_eff_date))\n  \n  # duplicate exposure data\n  # -&gt; add term_num_id and corresponding term_eff_date\n  # -&gt; calculate modified exposures\n  df_expos_dup_mod = df_policy_split %&gt;% \n    mutate(data = map2(.x = list(data), .y = list(df_expos), \\(df_p, df_expos, last_month_exposure_data) duplicate_rows(df_p, df_expos, last_month_expos_data = last_month_expos_data))) %&gt;% \n    unnest(cols = data) %&gt;% \n    ungroup %&gt;% \n    calc_term_num_id %&gt;% \n    left_join(df_policy %&gt;% select(term_eff_date, cancel_date, term_num_id), by = join_by(term_num_id)) %&gt;% \n    calc_modified_expos %&gt;% \n    select(-c(term_eff_month, term_eff_day)) %&gt;% \n    relocate(term_num_id, .before = term_month_id)\n  \n  # add check for when modified exposure\n  df_expos_dup_mod %&lt;&gt;% \n    left_join(df_expos %&gt;% select(calyr, calmth, exposyr) %&gt;% rename(exposyr_orig = exposyr), by = join_by(calyr, calmth)) %&gt;% \n    mutate(check = exposyr == exposyr_orig)\n  \n  # correct exposures for cancel in first month of renewal term\n  last_row = df_expos_dup_mod %&gt;% tail(n = 1)\n  nrows = nrow(df_expos_dup_mod)\n  if (nrows &gt; 1 & last_row$term_month_id == 1 & !is.na(last_row$cancel_date) & month(last_row$cancel_date) == month(last_row$term_eff_date)) {\n    \n    # get exposure info\n    # -&gt; first have to reset exposyr to its original value (was portioned out wrong)\n    # -&gt; modify total days based on cancellation date \n    expos_info = last_row %&gt;% mutate(exposyr = exposyr_orig) %&gt;% extract_expos_info()\n    expos_info$total_days = day(df_expos_dup_mod[nrows,\"cancel_date\"]$cancel_date) - 1\n    \n    # portion out the 13 term_month_id (if it gets there)\n    df_expos_dup_mod[nrows-1,\"exposyr\"] = expos_info %&gt;% {round(.$days_of_coverage / .$total_days * .$original_exposyr, 5)}\n    \n    # portion out the 1 term_month_id\n    df_expos_dup_mod[nrows,\"exposyr\"] = expos_info %&gt;% {round((.$total_days - .$days_of_coverage) / .$total_days * .$original_exposyr, 5)}\n    \n  }\n  \n  return(df_expos_dup_mod)\n  \n}\n\n# define second function to correctly duplicate rows\nduplicate_rows &lt;- function(df_p, df_expos, last_month_expos_data) {\n  \n  # define endpoints of time interval\n  begin_year = min(df_p$term_eff_date) %&gt;% year\n  begin_month = min(df_p$term_eff_date) %&gt;% month\n  end_year = max(df_p$term_exp_date) %&gt;% year\n  end_month = ifelse(day(max(df_p$term_exp_date)) == 1, max(df_p$term_exp_date) %m-% months(1) %&gt;% month,  max(df_p$term_exp_date) %&gt;% month)\n  \n  # get exposure data within interval of interest\n  # -&gt; also add common variables for next step\n  df_e = df_expos %&gt;% \n    mutate(row_id_total = row_number(),\n           nrows_total = max(row_id_total)) %&gt;% \n    filter(between(calyr, begin_year, end_year)) %&gt;% \n    mutate(keep = case_when(\n      calyr == begin_year & calmth &lt; begin_month ~ FALSE,\n      calyr == begin_year & calmth &gt;= begin_month ~ TRUE,\n      between(calyr, begin_year + 1, end_year - 1) ~ TRUE,\n      calyr == end_year & calmth &lt;= end_month ~ TRUE,\n      calyr == end_year & calmth &gt; end_month ~ FALSE\n    )) %&gt;% \n    filter(keep) %&gt;% \n    select(-keep) %&gt;% \n    mutate(orig_eff_year = year(min(df_p$term_eff_date)),\n           last_eff_year = year(max(df_p$term_eff_date)),\n           term_eff_month = month(min(df_p$term_eff_date)),\n           term_eff_day = day(min(df_p$term_eff_date)),\n           row_id_subset = row_number(),\n           nrows_subset = max(row_id_subset))\n  \n  if (day(min(df_p$term_eff_date)) != 1) {\n    \n    # conditionally duplicate partial months\n    # -&gt; then reassign subset assign row ID and nrows_subset\n    df_e_dup = df_e %&gt;% \n      {. -&gt;&gt; tmp} %&gt;% \n      bind_rows(tmp %&gt;% filter(calmth == term_eff_month, term_eff_day != 1, between(row_id_subset, 2, nrows_subset-1))) %&gt;% # -&gt; duplicate records for \"interim\" ending partial months of the subset of rows\n      bind_rows(tmp %&gt;% filter(calmth == term_eff_month, term_eff_day != 1, nrows_total &gt; 1, row_id_total == nrows_total, last_eff_year == year(pmaccndte), term_eff_month == month(pmaccndte))) %&gt;% # -&gt; duplicate records for cancel first month of renewal term (but not cancel first month of original term)\n      bind_rows(tmp %&gt;% filter(last_eff_year == year(Sys.Date()), term_eff_month == last_month_expos_data, term_eff_day != 1, row_id_total == nrows_total, nrows_total != 1)) %&gt;% # -&gt; duplicate  for renew in last month of exposure data\n      arrange(calyr, calmth) %&gt;% \n      mutate(row_id_subset = ifelse(orig_eff_year &gt;= 2013, row_number(), ifelse(term_eff_month == 1, row_number() + 13 - term_eff_month + 1, row_number() + 13 - term_eff_month)), # correct for policies that are mid-term when 2013-01-01 gets here\n             nrows_subset = max(row_id_subset),\n             term_month_id = case_when(\n               leap_year(orig_eff_year) & term_eff_month == 2 & term_eff_day == 29 & row_id_subset %% 13 != 0 ~ row_id_subset %% 13,\n               leap_year(orig_eff_year) & term_eff_month == 2 & term_eff_day == 29 & row_id_subset %% 13 == 0 ~ 13,\n               row_id_subset %% 13 != 0 ~ row_id_subset %% 13,\n               row_id_subset %% 13 == 0 ~ 13\n             )\n      )\n    \n    \n  } else {\n    \n    # don't need to duplicate any rows\n    # -&gt; reassign subset row ID\n    df_e_dup = df_e %&gt;% \n      mutate(row_id_subset = ifelse(orig_eff_year &gt;= 2013, row_number(), ifelse(term_eff_month == 1, row_number() + 13 - term_eff_month + 1, row_number() + 13 - term_eff_month)), # correct for policies that are mid-term when 2013-01-01 gets here\n             nrows_subset = max(row_id_subset),\n             term_month_id = case_when(\n               row_id_subset %% 12 != 0 ~ row_id_subset %% 12,\n               row_id_subset %% 12 == 0 ~ 12)\n      )\n    \n  }\n  \n  # combine results\n  df_e_dup %&lt;&gt;%  \n    select(-c(starts_with(\"row_id_\"), starts_with(\"nrows_\"), orig_eff_year, last_eff_year, term_eff_month, term_eff_day))\n  \n  return(df_e_dup)\n  \n}\n\n# define function to calculate term_num_id\ncalc_term_num_id &lt;- function(df_expos_dup) {\n  \n  # initialize\n  term_num_id = c()\n  term_num_id_counter = 0\n  \n  for (i in 1:nrow(df_expos_dup)) {\n    \n    # increase counter when term restarts\n    term_num_id_counter = ifelse(df_expos_dup[i,\"term_month_id\"] == 1, term_num_id_counter + 1, term_num_id_counter)\n    \n    # set new term number\n    term_num_id[i] = term_num_id_counter\n    \n  }\n  \n  # add term_num_id\n  df_expos_dup %&lt;&gt;% \n    bind_cols(term_num_id = term_num_id)\n  \n  return(df_expos_dup)\n  \n}\n\n# define function to extract needed exposure information for a record\nextract_expos_info &lt;- function(df_e_dup_i) {\n  \n  # calculate needed values\n  begin_of_month = make_date(df_e_dup_i$calyr, df_e_dup_i$calmth, 1)\n  begin_of_next_month = begin_of_month %m+% months(1)\n  \n  # create named list\n  # -&gt; endpoints, calculated number of days in the month of interest, set original exposure\n  results = list(\"begin_of_month\" = begin_of_month,\n                 \"begin_of_next_month\" = begin_of_next_month,\n                 \"total_days\" = interval(begin_of_month, begin_of_next_month) / days(1),\n                 \"original_exposyr\" = df_e_dup_i$exposyr,\n                 \"days_of_coverage\" = day(df_e_dup_i$term_eff_date) - 1)\n  \n  return(results)\n  \n}\n\n# define function to calculate modified exposures\n# -&gt; input needs to have term_num_id added already\ncalc_modified_expos &lt;- function(df_expos_dup) {\n  \n  # conditionally portion out exposures\n  df_expos_dup_mod = df_expos_dup %&gt;% \n    nest_by(term_num_id) %&gt;% \n    mutate(data = map2(.x = list(data), .y = term_num_id, function(df_e_dup, term_num_id, num_terms = max(.$term_num_id)) {\n      \n      if (term_num_id == 1) { # first_term_num_id\n        \n        if (year(df_e_dup[1,\"pmoeffdte\"]$pmoeffdte) &lt; 2015) {\n          \n          # conditionally portion out the 1 term_month_id for older policies\n          # -&gt; back out starting exposures from prior terms that aren't in the policy data\n          expos_info = extract_expos_info(df_e_dup[1,])\n          df_e_dup[1,\"exposyr\"] = expos_info %&gt;% {round((.$total_days - .$days_of_coverage) / .$total_days * .$original_exposyr, 5)}\n          \n        }\n        \n        # only portion out if it gets there and if there are multiple terms\n        if (nrow(df_e_dup) == 13 & num_terms != 1) {\n          \n          # portion out the 13 term_month_id\n          expos_info = extract_expos_info(df_e_dup[13,])\n          df_e_dup[13,\"exposyr\"] = expos_info %&gt;% {round(.$days_of_coverage / .$total_days * .$original_exposyr, 5)}\n          \n        }\n        \n      } else if (between(term_num_id, 2, num_terms - 1)) { # middle term_num_ids\n        \n        # portion out the 1 term_month_id\n        expos_info = extract_expos_info(df_e_dup[1,])\n        df_e_dup[1,\"exposyr\"] = expos_info %&gt;% {round((.$total_days - .$days_of_coverage) / .$total_days * .$original_exposyr, 5)}\n        \n        if (nrow(df_e_dup) == 13) {\n          \n          # portion out the 13 term_month_id (if it gets there)\n          expos_info = extract_expos_info(df_e_dup[13,])\n          df_e_dup[13,\"exposyr\"] = expos_info %&gt;% {round(.$days_of_coverage / .$total_days * .$original_exposyr, 5)}\n          \n        }    \n        \n      } else { # last term_num_id\n        \n        # portion out the 1 term_month_id\n        expos_info = extract_expos_info(df_e_dup[1,])\n        df_e_dup[1,\"exposyr\"] = expos_info %&gt;% {round((.$total_days - .$days_of_coverage) / .$total_days * .$original_exposyr, 5)}\n        \n      }\n      \n      return(df_e_dup)\n      \n    })) %&gt;% \n    unnest(cols = data) %&gt;% \n    ungroup\n  \n  return(df_expos_dup_mod)\n  \n}\n\n### ---- Load data: SQL ----\n\n# establish connection\ncon &lt;- DBI::dbConnect(odbc::odbc(),\n                      Driver = \"SQL Server\",\n                      Server = \"sql22-jax\\\\pricing\",\n                      trusted_connection = TRUE)\n\n# run query for policy data\n# -&gt; already worked with and finalized data in SSMS\ndata_policy &lt;- DBI::dbGetQuery(con, \"select * from pricing.CLT.tiering_analysis_BPPOL\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(data_pull_date = data_pull_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         across(c(term_num_id, term_premium, term_fees, ends_with(\"loi\"), ends_with(\"ded\"), ends_with(\"lmiit\"), payroll, adv_qt_days, num_sw_pols), as.numeric),\n         across(c(ends_with(\"date\"), -data_pull_date), mdy),\n         data_pull_date = data_pull_date %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd) %&gt;% \n  rename(policy_data_pull_date = data_pull_date) %&gt;% \n  filter(year(term_eff_date) &gt;= 2015) %&gt;% # last 10 years of data\n  mutate(.by = pol_num,\n         term_num_id = row_number()) %&gt;% # reassign term_num_id for better match to exposure data (i.e. starting anew at 2015/01/01)\n  arrange(pol_num, term_num_id)\n\n# close connection\nDBI::dbDisconnect(con)\n\n### ---- Load data: Databricks ----\n\n# establish connection\n# --&gt; !!! NEED TO HAVE .Renviron setup\ncon &lt;- DBI::dbConnect(\n  odbc::databricks(),\n  httpPath = \"/sql/1.0/warehouses/XXXXXXXXXXXXXXXX\",\n)\n\n# run query\ndata_expos_raw &lt;- DBI::dbGetQuery(con,\n                                  \"select * \n                        from database.calmonth_exposure -- exposure file\n                        where left(PMPRFX,2) in ('BC','BP','CM','CZ','XC','ZC', 'ZP')\n                        order by POLNO, CALYR, CALMTH\n                        --limit 100\n                    \") %&gt;% \n  janitor::clean_names() %&gt;% \n  select(-c(pmprfx, pmplnr)) %&gt;% \n  mutate(pmaccndte = pmaccndte %&gt;% as.character.POSIXt %&gt;% as.Date %&gt;% ymd,\n         across(c(calyr, calmth), as.numeric)) %&gt;%  # removes cancels dates of 01/01/0001\n  mutate(data_pull_date = ymd(Sys.Date()), .before = 1) %&gt;% \n  filter(year(pmteffdte) &gt;= 2015) %&gt;% # last 10 years of data\n  filter(month(pmoeffdte) == month(pmteffdte)) %&gt;% # filter out renew with lapse in different month (too difficult and nest_by() messes up the order for Dec to Jan policies)\n  filter(!(leap_year(pmoeffdte) & month(pmoeffdte) == 2 & day(pmoeffdte) == 29)) # filter out policies written on leap day (nest_by() messes up the order)\n\n# close connection\nDBI::dbDisconnect(con)\n\n# save raw data so don't have to rerun in new month\nsave(data_expos_raw, file = \"RData\\\\data_expos_raw.RData\")\n\n### ---- Modify exposure data ----\n\n# load raw exposure data\nload(\"RData\\\\data_expos_raw.RData\")\n\n# create combined nested dataset of policy and exposure information\n# -&gt; only want policies with exposure data\nlast_month_expos_data &lt;- 10\ntictoc::tic()\ndata_policy_expos &lt;- data_policy %&gt;% \n  nest_by(pol_num, .keep = TRUE) %&gt;% \n  rename(data_policy = data) %&gt;% \n  inner_join(data_expos_raw %&gt;% nest_by(polno, .keep = TRUE) %&gt;% rename(data_expos = data), by = join_by(pol_num == polno)) %&gt;% \n  mutate(data_expos = map2(.x = list(data_policy), .y = list(data_expos), \\(df_policy, df_expos) modify_exposure_data(df_policy, df_expos)))\ntictoc::toc()\n\n# save results\nsave(data_policy_expos, file = \"RData\\\\data_policy_expos.RData\")\n\n### ---- Create final datsets ----\n\n# load combined nested dataset of policy and exposure information \nload(\"RData\\\\data_policy_expos.RData\")\n\n# get modified exposure data\ndata_expos &lt;- data_policy_expos %&gt;% \n  select(-data_policy) %&gt;% \n  unnest(data_expos) %&gt;% \n  ungroup %&gt;% \n  relocate(data_pull_date, .before = 1) %&gt;% \n  select(-polno)\n\n# save results\nsave(data_expos, file = \"RData\\\\data_expos.RData\")\n\n# get policy data that matches the exposure data\ndata_policy_matched &lt;- data_policy_expos %&gt;% \n  select(-data_expos) %&gt;% \n  mutate(data_policy = map(.x = list(data_policy), \\(df) select(df, -pol_num))) %&gt;% \n  unnest(data_policy) %&gt;% \n  ungroup %&gt;% \n  relocate(policy_data_pull_date, .before = 1)\n\n# save results\nsave(data_policy_matched, file = \"RData\\\\data_policy_matched.RData\")\n\n### ---- Load data: RData ----\n\n# load combined nested dataset of policy and exposure information \nload(\"RData\\\\data_policy_expos.RData\")\n\n# load modified exposure data\nload(\"RData\\\\data_expos.RData\")\n\n# load matched policy data\nload(\"RData\\\\data_policy_matched.RData\")\n\n\n2.1.3 Tiering analysis - Combined\n\n### ---- Load packages and define functions ---- \n\nlibrary(tidyverse)\nlibrary(magrittr)\n\n# define function to summarize exposures by grouping variables univariately\nsummarize_exposures &lt;- function(df){\n  \n  results = list()\n  \n  for (i in 1:(ncol(df)-2)) {\n    \n    tmp = df %&gt;% \n      select(all_of(i), exposyr, earned_premium_with_fees_trended) %&gt;% \n      summarize(.by = 1,\n                exposyr = sum(exposyr, na.rm = TRUE),\n                earned_premium_with_fees_trended = sum(earned_premium_with_fees_trended, na.rm = TRUE)) %&gt;% \n      arrange(desc(exposyr))\n    \n    results[[i]] = tmp\n    \n  }\n  \n  names(results) = colnames(df %&gt;% select(-c(exposyr, earned_premium_with_fees_trended)))\n  \n  return(results)\n  \n}\n\n### ---- Load data: RData ----\n\n# load matched policy data\nload(\"RData\\\\data_policy_matched.RData\")\n\n# load trended, ult summarized claim data\nload(\"RData\\\\data_claims_non_cats_ult_trended_capped_by_peril.RData\")\n\n# load modified exposure data\nload(\"RData\\\\data_expos.RData\")\n\n### ---- Recode premium data ----\n\n# recode data to levels of tiering variables\ndata_policy_matched_lvls &lt;- data_policy_matched %&gt;% \n  mutate(across(starts_with(\"claim_type_\"),\n                ~ case_when(\n                  .x %in% c(\"RIOT\",\"HAIL\",\"LIGHT\",\"VMM\",\"WEATH\",\"WIND\") ~ 1,\n                  is.na(.x) ~ 0,\n                  .default = 2\n                )),\n         credit_range = case_when(\n           credit_score == 0 ~ \"No Score\",\n           credit_score &lt;= 582 ~ \"582 or Less\",\n           credit_score &lt;= 596 ~ \"583 - 596\",\n           credit_score &lt;= 609 ~ \"597 - 609\",\n           credit_score &lt;= 622 ~ \"610 - 622\",\n           credit_score &lt;= 635 ~ \"623 - 635\",\n           credit_score &lt;= 645 ~ \"636 - 645\",\n           credit_score &lt;= 654 ~ \"646 - 654\",\n           credit_score &lt;= 663 ~ \"655 - 663\",\n           credit_score &lt;= 672 ~ \"664 - 672\",\n           credit_score &lt;= 681 ~ \"673 - 681\",\n           credit_score &lt;= 689 ~ \"682 - 689\",\n           credit_score &lt;= 696 ~ \"690 - 696\",\n           credit_score &lt;= 704 ~ \"697 - 704\",\n           credit_score &lt;= 711 ~ \"705 - 711\",\n           credit_score &lt;= 717 ~ \"712 - 717\",\n           credit_score &lt;= 722 ~ \"718 - 722\",\n           credit_score &lt;= 728 ~ \"723 - 728\",\n           credit_score &lt;= 734 ~ \"729 - 734\",\n           credit_score &lt;= 740 ~ \"735 - 740\",\n           credit_score &lt;= 745 ~ \"741 - 745\",\n           credit_score &lt;= 750 ~ \"746 - 750\",\n           credit_score &lt;= 758 ~ \"751 - 758\",\n           credit_score &lt;= 764 ~ \"759 - 764\",\n           credit_score &lt;= 771 ~ \"765 - 771\",\n           credit_score &lt;= 777 ~ \"772 - 777\",\n           credit_score &lt;= 786 ~ \"778 - 786\",\n           credit_score &lt;= 794 ~ \"787 - 794\",\n           credit_score &lt;= 802 ~ \"795 - 802\",\n           credit_score &lt;= 810 ~ \"803 - 810\",\n           credit_score &lt;= 828 ~ \"811 - 828\",\n           credit_score &lt;= 845 ~ \"829 - 845\",\n           credit_score &lt;= 862 ~ \"846 - 862\",\n           credit_score &lt;= 879 ~ \"863 - 879\",\n           credit_score &gt;= 880 ~ \"880 or More\",\n         ) %&gt;% factor(levels = c(\"582 or Less\",\"583 - 596\",\"597 - 609\",\"610 - 622\",\"623 - 635\",\"636 - 645\",\"646 - 654\",\n                                 \"655 - 663\",\"664 - 672\",\"673 - 681\",\"682 - 689\",\"690 - 696\",\"697 - 704\",\"705 - 711\",\n                                 \"712 - 717\",\"718 - 722\",\"723 - 728\",\"729 - 734\",\"735 - 740\",\"741 - 745\",\"746 - 750\",\n                                 \"751 - 758\",\"759 - 764\",\"765 - 771\",\"772 - 777\",\"778 - 786\",\"787 - 794\",\"795 - 802\",\n                                 \"803 - 810\",\"811 - 828\",\"829 - 845\",\"846 - 862\",\"863 - 879\",\"880 or More\", \"No Score\"), ordered = TRUE),\n         credit_range2 = case_when(\n           credit_range %in%  c(\"582 or Less\",\"583 - 596\") ~ \"596 or Less\",\n           credit_range %in%  c(\"597 - 609\",\"610 - 622\") ~ \"597 - 622\",\n           credit_range %in%  c(\"623 - 635\",\"636 - 645\") ~ \"623 - 645\",\n           credit_range %in%  c(\"646 - 654\",\"655 - 663\") ~ \"646 - 663\",\n           credit_range %in%  c(\"664 - 672\",\"673 - 681\") ~ \"664 - 681\",\n           credit_range %in%  c(\"682 - 689\",\"690 - 696\") ~ \"682 - 696\",\n           credit_range %in%  c(\"697 - 704\",\"705 - 711\") ~ \"697 - 711\",\n           credit_range %in%  c(\"712 - 717\",\"718 - 722\") ~ \"712 - 722\",\n           credit_range %in%  c(\"723 - 728\",\"729 - 734\") ~ \"723 - 734\",\n           credit_range %in%  c(\"735 - 740\",\"741 - 745\") ~ \"735 - 745\",\n           credit_range %in%  c(\"746 - 750\",\"751 - 758\") ~ \"746 - 758\",\n           credit_range %in%  c(\"759 - 764\",\"765 - 771\") ~ \"759 - 771\",\n           credit_range %in%  c(\"772 - 777\",\"778 - 786\") ~ \"772 - 786\",\n           credit_range %in%  c(\"787 - 794\",\"795 - 802\") ~ \"787 - 802\",\n           credit_range %in%  c(\"803 - 810\",\"811 - 828\") ~ \"803 - 828\",\n           credit_range %in%  c(\"829 - 845\",\"846 - 862\") ~ \"829 - 862\",\n           credit_range %in%  c(\"863 - 879\",\"880 or More\") ~ \"863 or More\",\n           credit_range == \"No Score\" ~ \"No Score\",\n           .default = credit_range\n         ) %&gt;% factor(levels = c(\"596 or Less\",\"597 - 622\",\"623 - 645\",\"646 - 663\",\"664 - 681\",\"682 - 696\",\"697 - 711\",\n                                 \"712 - 722\",\"723 - 734\",\"735 - 745\",\"746 - 758\",\"759 - 771\",\"772 - 786\",\"787 - 802\",\n                                 \"803 - 828\",\"829 - 862\",\"863 or More\",\"No Score\"), ordered = TRUE),\n         years_in_business = case_when(\n           year_bus_start == 0 ~ NA,\n           year(term_eff_date) - year_bus_start &lt;= 9 ~ as.character(year(term_eff_date) - year_bus_start),\n           year(term_eff_date) - year_bus_start &gt;= 10 ~ \"10 or More\"\n         ) %&gt;% factor(levels = c(paste(0:9), \"10 or More\"), ordered = TRUE),\n         age_of_building = case_when(\n           year_built == 0 ~ \"Unknown\",\n           year(term_eff_date) - year_built &lt;= 2 ~ \"0-2\",\n           year(term_eff_date) - year_built &lt;= 10 ~ as.character(year(term_eff_date) - year_built),\n           year(term_eff_date) - year_built &lt;= 12 ~ \"11-12\",\n           year(term_eff_date) - year_built &lt;= 15 ~ \"13-15\",\n           year(term_eff_date) - year_built &lt;= 17 ~ \"16-17\",\n           year(term_eff_date) - year_built &lt;= 20 ~ \"18-20\",\n           year(term_eff_date) - year_built &lt;= 24 ~ \"21-24\",\n           year(term_eff_date) - year_built &lt;= 29 ~ \"25-29\",\n           year(term_eff_date) - year_built &lt;= 33 ~ \"30-33\",\n           year(term_eff_date) - year_built &lt;= 44 ~ \"34-44\",\n           year(term_eff_date) - year_built &lt;= 49 ~ \"45-49\",\n           year(term_eff_date) - year_built &lt;= 59 ~ \"50-59\",\n           year(term_eff_date) - year_built &lt;= 74 ~ \"60-74\",\n           year(term_eff_date) - year_built &lt;= 99 ~ \"75-99\",\n           year(term_eff_date) - year_built &gt;= 100 ~ \"100 or More\",\n           .default = \"Unknown\"\n         ) %&gt;% factor(levels = c(\"0-2\",paste(3:10),\"11-12\",\"13-15\",\"16-17\",\"18-20\",\"21-24\",\"25-29\",\"30-33\",\n                                 \"34-44\",\"45-49\",\"50-59\",\"60-74\",\"75-99\",\"100 or More\",\"Unknown\"), ordered = TRUE),\n         age_of_roof = case_when(\n           roof_year == 0 ~ \"Unknown\",\n           year(term_eff_date) - roof_year &lt;= 39 ~ as.character(year(term_eff_date) - roof_year),\n           year(term_eff_date) - roof_year &gt;= 40 ~ \"40 or More\",\n           .default = \"Unknown\"\n         ) %&gt;% factor(levels = c(paste(0:39),\"40 or More\",\"Unknown\"), ordered = TRUE),\n         roof_type = case_when(\n           str_to_lower(roof_type) %in% c(\"asphault shingle\",\"as\",\"shingle\",\"asphalt comp roll\",\"comp roll\",\"comp\",\"comp toll\",\"composition\") ~ \"asphalt shingle\",\n           str_to_lower(roof_type) %in% c(\"tile, slate, stone\",\"tile\") ~ \"tile\",\n           str_to_lower(roof_type) %in% c(\"rubber\",\"rubber membrane\",\"membrane\") ~ \"synthetic\",\n           str_to_lower(roof_type) %in% c(\"tar, tar and gravel\",\"tar & gravel\",\"t&g\",\"t & g\") ~ \"tar and gravel\",\n           str_to_lower(roof_type) %in% c(\"thermo-plastic membrane\",\"thermo plastic\") ~ \"TPO\",\n           str_to_lower(roof_type) == \"plastic membrane\" ~ \"EPDM\",\n           str_to_lower(roof_type) == \"concrete\" ~ \"other\",\n           str_to_lower(roof_type) %in% c(\"1\",\"flat\",\"gable\",\"\") ~ \"unknown\",\n           .default = str_to_lower(roof_type)\n         ),\n         num_empl = case_when(\n           num_empl == 0 ~ \"Missing\",\n           num_empl &lt;= 3 ~ \"1-3\",\n           num_empl &lt;= 6 ~ \"4-6\",\n           num_empl &lt;= 12 ~ \"7-12\",\n           num_empl &gt;= 13 ~ \"13 or More\",\n           .default = \"Missing\"\n         ) %&gt;% factor(levels = c(\"Missing\",\"1-3\",\"4-6\",\"7-12\",\"13 or More\"), ordered = TRUE),\n         num_sw_pols = case_when(\n           num_sw_pols &lt;= 3 ~ as.character(num_sw_pols),\n           num_sw_pols &gt;= 4 ~ \"4 or More\",\n           .default = NA\n         ) %&gt;% factor(levels = c(paste(1:3),\"4 or More\"), ordered = TRUE),\n         adv_qt_days = case_when(\n           adv_qt_days &lt;= 14 ~ \"0-14\",\n           adv_qt_days &lt;= 30 ~ \"15-30\",\n           adv_qt_days &gt;= 31 ~ \"31 or More\",\n           .default = \"Missing\"\n         ) %&gt;% factor(levels = c(\"Missing\",\"0-14\",\"15-30\",\"31 or More\"), ordered = TRUE)\n  ) %&gt;% \n  mutate(prior_loss_history_points = claim_type_1 + claim_type_2 + claim_type_3 + claim_type_4 + claim_type_5)\n\n### ---- Combine data ----\n\n# combine policy and claim data\n# -&gt; don't need the tiering info now, will join back on after aggregating\ndata_combined &lt;- data_policy_matched_lvls %&gt;% \n  select(policy_data_pull_date, pol_num, trans_type, term_num_id, pol_state, orig_eff_date, term_eff_date, term_exp_date, cancel_date, pol_status, expos_base, bdg_loi, bpp_loi, sales, payroll, term_premium, term_fees) %&gt;% \n  left_join(data_claims_non_cats_ult_trended_capped_by_peril %&gt;% select(-c(company, pol_state))%&gt;% rename(claims_data_pull_date = data_pull_date), by = join_by(pol_num == pol_num, term_eff_date == term_eff_date))\n\n# combine policy and exposure data\n# -&gt; zero out repeated premium and claim amounts\ndata_combined %&lt;&gt;%  \n  filter(term_eff_date &lt; ymd(\"2025-11-01\")) %&gt;% # don't have exposure data for the current month\n  left_join(data_expos %&gt;% rename(expos_data_pull_date = data_pull_date) %&gt;% select(-c(term_eff_date, cancel_date)), by = join_by(pol_num == pol_num, term_num_id == term_num_id)) %&gt;% \n  select(policy_data_pull_date, expos_data_pull_date, pol_num, pol_state, company, poltyp, trans_type, term_num_id, term_month_id, orig_eff_date, term_eff_date, term_exp_date, cancel_date, pol_status, calyr, calmth, \n         term_premium, term_fees, exposyr, exposyr_orig, check, expos_base, bdg_loi, bpp_loi, sales, payroll,\n         claims_data_pull_date, starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\")) %&gt;% \n  mutate(.by = c(pol_num, term_num_id),\n         row_id = row_number(),\n         across(c(term_premium, term_fees, starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\")),\n                ~ case_when(\n                  row_id == 1 ~ .x,\n                  is.na(.x) ~ NA,\n                  .default = 0\n                )\n         )\n  ) %&gt;% \n  select(-row_id) %&gt;% \n  filter(!is.na(exposyr)) # real tiny amount of exposure data missing, not my fault\n\n# save results\nsave(data_combined, file = \"RData\\\\data_combined.RData\")\n\n# write to csv for Karen to check trending\nwrite_csv(data_combined, \"Excel data\\\\data_combined.csv\", na = \"\")\n\n### ---- Aggregate all data and trend premium data ----\n\n# load combined data\nload(\"RData\\\\data_combined.RData\")\n\n# aggregate data by policy number / term\n# -&gt; rolling up over pol_num and term_num_id\n# -&gt; !!!! ASSUMING this correction / data error (I'm done...)\n# ---&gt; missing beginning policy term ==&gt; inflated first term exposyr\n# ---&gt; full last month of exposure when it shouldn't be\n# -&gt; calculate EP and add fees, and both written and earned exposures for property and liability\n# --&lt; !!! had approx 7800 policy terms with 0 exposure base (commercial landloards with no BPP), see notes below\ndata_combined_agg &lt;- data_combined %&gt;% \n  summarize(.by = c(pol_num,\n                    term_num_id,\n                    term_eff_date,\n                    expos_base),\n            across(c(term_premium, term_fees, exposyr, bdg_loi, bpp_loi, sales, payroll, starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\")),\n                   ~ round(sum(.x, na.rm = TRUE), 3))) %&gt;% \n  mutate(exposyr = ifelse(exposyr &gt; 1, 1, exposyr)) %&gt;% \n  mutate(earned_premium_with_fees = round((term_premium + term_fees) * exposyr, 2),\n         term_premium_with_fees = term_premium + term_fees,\n         written_expos_property = (bdg_loi + bpp_loi) / 100,\n         written_expos_liability = case_when(\n           expos_base == \"LOI\" & bpp_loi != 0 ~ bpp_loi / 100,\n           expos_base == \"LOI\" & bpp_loi == 0 ~ sales / 1000, # executive decision, correcting for $0 exposure base data errors by using a different exposure base\n           expos_base == \"SALES\" & sales != 0 ~ sales / 1000,\n           expos_base == \"SALES\" & sales == 0 ~ bpp_loi / 100, # correcting ... \n           expos_base == \"PAY\" & payroll &gt;= 1000 ~ payroll / 1000, # another executive decision, if less than 1000 of payroll, then set to missing\n           expos_base == \"PAY\" & payroll == 0 ~ sales / 1000 # correcting ...\n         ),\n         earned_expos_property = round(written_expos_property * exposyr, 2),\n         earned_expos_liability = round(written_expos_liability * exposyr, 2)) %&gt;% \n  select(pol_num, term_eff_date, term_num_id, term_premium_with_fees, earned_premium_with_fees, exposyr, contains(\"_expos_\"), starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\"))\n\n# check\n# (before simplifying assumption)\ndata_check &lt;- data_combined_agg %&gt;% filter(exposyr &gt; 1.01)\n\n# trend premiums individually\n# -&gt; trend select pulled from 'Indications q4 2024 eval q1 2025.xlsx' for MA\n# -&gt; as-of-date is the start of the future policy period (described below)\n# -&gt; future policy period = 12/01/2025 - 12/01/2026 ==&gt; avg written date = 06/01/2026 and avg earned date = 12/01/2026\n# --&gt; written premium trend period length and earned premium trend period length should be the same (just minor differences due to timing of year)\nas_of_date_age &lt;- \"2025-11-03\" %&gt;% ymd %&gt;% add(months(1)) %&gt;% {paste(year(.), month(.), \"1\", sep = \"-\")} %&gt;% ymd\ntrend_premium &lt;- 0.04259\navg_written_date_trend &lt;- as_of_date_age %m+% months(6)\navg_earned_date_trend &lt;- as_of_date_age  %m+% years(1)\ndata_combined_agg %&lt;&gt;% \n  mutate(written_premium_trend_factor = trend_premium %&gt;% add(1) %&gt;%\n           raise_to_power(interval(term_eff_date, avg_written_date_trend) / years(1)),\n         earned_premium_trend_factor = trend_premium %&gt;% add(1) %&gt;%\n           raise_to_power(interval(term_eff_date %m+% months(6), avg_earned_date_trend) / years(1)),\n         term_premium_with_fees_trended = round(term_premium_with_fees * written_premium_trend_factor, 2),\n         earned_premium_with_fees_trended = round(earned_premium_with_fees * earned_premium_trend_factor, 2)) %&gt;% \n  select(pol_num, term_eff_date, term_num_id, starts_with(\"term_premium_with\"), starts_with(\"earned_premium_with\"), written_premium_trend_factor, earned_premium_trend_factor, exposyr, contains(\"_expos_\"), starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\"))\n\n# aggregate data by tiering variables\n# -&gt; calculate last tiering variable\n# -&gt; need one record for each combination of tiering variables\n# -&gt; in CA BOP UWG word doc, 6. Number of locations ==&gt; this is always 1 (never built this in), so skipping\ndata_combined_agg_agg &lt;- data_combined_agg %&gt;% \n  left_join(data_policy_matched_lvls %&gt;% select(pol_num, term_num_id, credit_range, prior_loss_history_points, years_in_business, age_of_building, age_of_roof, roof_type, num_empl, num_sw_pols, num_renewals, adv_qt_days, entity_type),\n            by = join_by(pol_num, term_num_id)) %&gt;% \n  mutate(num_renewals = term_num_id - 1) %&gt;% \n  summarize(.by = c(credit_range,\n                    prior_loss_history_points,\n                    years_in_business,\n                    age_of_building,\n                    age_of_roof,\n                    roof_type,\n                    num_empl,\n                    num_sw_pols,\n                    num_renewals,\n                    adv_qt_days,\n                    entity_type),\n            across(c(term_premium_with_fees_trended, earned_premium_with_fees_trended, exposyr, contains(\"_expos_\"), starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\")),\n                   ~ sum(.x, na.rm = TRUE)))\n\n# repeat for credit_range2\ndata_combined_agg_agg2 &lt;- data_combined_agg %&gt;% \n  left_join(data_policy_matched_lvls %&gt;% select(pol_num, term_num_id, credit_range2, prior_loss_history_points, years_in_business, age_of_building, age_of_roof, roof_type, num_empl, num_sw_pols, num_renewals, adv_qt_days, entity_type),\n            by = join_by(pol_num, term_num_id)) %&gt;% \n  mutate(num_renewals = term_num_id - 1) %&gt;% \n  summarize(.by = c(credit_range2,\n                    prior_loss_history_points,\n                    years_in_business,\n                    age_of_building,\n                    age_of_roof,\n                    roof_type,\n                    num_empl,\n                    num_sw_pols,\n                    num_renewals,\n                    adv_qt_days,\n                    entity_type),\n            across(c(term_premium_with_fees_trended, earned_premium_with_fees_trended, exposyr, contains(\"_expos_\"), starts_with(\"incurred_claim_count_\"), starts_with(\"peril_\")),\n                   ~ sum(.x, na.rm = TRUE)))\n\n# !!! some combinations have zero written liability exposure, don't think there's anything we can\n\n# save results\nsave(data_combined_agg_agg, file = \"RData\\\\data_combined_agg_agg.RData\")\nsave(data_combined_agg_agg2, file = \"RData\\\\data_combined_agg_agg2.RData\")\n\n# calculate univariate exposure and earned premium by tiering variable\nsumm_expos &lt;- data_combined_agg_agg %&gt;% \n  select(credit_range, prior_loss_history_points, years_in_business, age_of_building, age_of_roof, roof_type, num_empl, num_sw_pols, num_renewals, adv_qt_days, entity_type, exposyr, earned_premium_with_fees_trended) %&gt;% \n  summarize_exposures %T&gt;% \n  {names(.) -&gt;&gt; nms} %&gt;% \n  map2(.x = names(.), .y = ., function(nm, df) {\n    \n    total &lt;- df %&gt;% \n      summarize(across(all_of(2:3), ~ round(sum(.x, 2)))) %&gt;% \n      mutate(var = \"total\",\n             .before = 1) %&gt;% \n      rename(!!nm := var)\n    \n    df %&lt;&gt;% \n      mutate(across(all_of(1), as.character)) %&gt;% \n      bind_rows(total)\n    \n    return(df)\n    \n  })\nnames(summ_expos) &lt;- nms\n\n# &lt; write to temporary csv and combine into single file, tiering-levels-exposure-premium.xlsx &gt;\nwrite_csv(summ_expos[[1]], \"temp.csv\")\n\n### ---- Load and write final data: RData ----\n\n# load interim data\nload(\"RData\\\\data_combined.RData\")\n\n# load final data\nload(\"RData\\\\data_combined_agg_agg.RData\")\nload(\"RData\\\\data_combined_agg_agg2.RData\")\n\n# write to xlsx (to avoid formatting errors) so can upload flat file into sql\nopenxlsx2::write_xlsx(data_combined_agg_agg, file = \"Excel data\\\\data_combined_agg_agg.xlsx\", na.strings = \"NA\")\nopenxlsx2::write_xlsx(data_combined_agg_agg2, file = \"Excel data\\\\data_combined_agg_agg2.xlsx\", na.strings = \"NA\")\n\n\n2.1.4 Analysis projects\n\n### ---- Load packages ---- \n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(gt)\nlibrary(gtExtras)\n\n### ---- Read in and organize data ---- \n\n# old inforce data\ndata_inforce_old &lt;- readxl::read_xlsx(path = \"InForce_20240430.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(date = ymd(\"2024-04-30\"), .before = 1)\n\n# new inforce data\ndata_inforce_new &lt;- readxl::read_xlsx(path = \"InForce_20250502.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n    mutate(date = ymd(\"2025-05-02\"), .before = 1)\n\n# combine datsets\ndata_inforce_all &lt;- data_inforce_old %&gt;% \n  bind_rows(data_inforce_new)\n\n# export for excel version of analysis\n# data_inforce_all %&gt;% \n#   openxlsx2::write_xlsx(file = \"InForce_all.xlsx\", na.strings = \"\")\n\n# set highlight cutoff\nhl_cutoff &lt;- 0.10\n\n# define shortcut for conditional highlighting\nformat_tbl_conditional_hl_changes &lt;- function(x) {\n  \n  x %&gt;% \n    tab_style(\n    style = cell_fill(color = \"red\", alpha = 0.05),\n    locations = list(\n      cells_body(\n        columns = change,\n        rows = percent_change &lt; -1 * hl_cutoff\n      ),\n      cells_body(\n        columns = percent_change,\n        rows =  percent_change &lt; -1 * hl_cutoff\n      ))\n  ) %&gt;% \n  tab_style(\n    style = cell_fill(color = \"green\", alpha = 0.05),\n    locations = list(\n      cells_body(\n        columns = change,\n        rows = percent_change &gt; hl_cutoff\n      ),\n      cells_body(\n        columns = percent_change,\n        rows =  percent_change &gt; hl_cutoff\n      ))\n  )\n  \n}\n\n### ---- Nail salons ----\n\n# define function\nformat_liability_limits &lt;- function(x) {\n  case_when(\n      x &lt; 1e3 ~ as.character(x),\n      x &lt; 1e6 ~ paste0(as.character(x/1e3), \"K\"),\n      x &lt; 1e9 ~ paste0(as.character(x/1e6), \"M\"),\n      TRUE ~ \"To be implemented...\"\n  )\n}\n\n# save sub datasets\ndata_nails &lt;- data_inforce_all %&gt;% \n  filter(stillwater_class_description == \"Nail Salon\") %&gt;%\n  mutate(across(c(occur_limit, aggregate_limit, premises_comp_ops_limit), format_liability_limits))\n\n# a) How many PIF compared to same time last year?\n# d) Average Premium change\ndata_nails %&gt;% \n  group_by(date) %&gt;% \n  summarize(n = n(),\n            mean_premium = mean(term_premium)) %&gt;% \n  pivot_longer(2:3, names_to = \"statistic\") %&gt;% \n  pivot_wider(names_from = 1) %&gt;% \n  mutate(statistic = if_else(statistic == \"mean_premium\", \"avg premium\", statistic),\n         change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Nail salons - PIF and average premium\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(rows = 1, columns = contains(\"-\"), decimals = 0) %&gt;% \n  fmt_currency(rows = 2, columns = contains(\"-\"), decimals = 2) %&gt;% \n  fmt_number(rows = 1, columns = change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_currency(rows = 2, columns = change, decimals = 2, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n# b) How many have the ISO Professional Liability coverage compared to last year?\ndata_nails %&gt;% \n  count(date, pls_cov) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Nail salons - PLS cov\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(pls_cov = \"PLS cov\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# c) Distribution of limits compared to last year?\n\n# i) Liability Limits\ndata_nails %&gt;% \n  mutate(liability_limits = paste(occur_limit, aggregate_limit, premises_comp_ops_limit, sep = \"/\")) %&gt;% \n  count(date, liability_limits) %&gt;% \n  mutate(.by = date,,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Nail salons - Liability limits\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(liability_limits = \"Liability limits\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# ii)   BPP limits\nbreaks_pls &lt;- c(-1,1,25000,50000,100000,1000000)\ndata_nails %&gt;% \n  mutate(bpp_loi_group = cut(bpp_loi, breaks = breaks_pls, labels = c(\"0\",\"(0,25k]\",\"(25k,50k]\",\"(50k,100k]\",\"&gt;100k\"))) %&gt;% \n  count(date, bpp_loi_group) %&gt;% \n  mutate(.by = date,,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Nail salons - BPP LOI\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(bpp_loi_group = \"BPP LOI\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n### ---- Restaurants ----\n\n# save sub datasets\n# -&gt; modified raw data for class descriptions to make part b easier\ndata_restaurants &lt;- data_inforce_all %&gt;% \n  filter(hierarchy_1 == \"Restaurants, Eating and Drinking Places\") %&gt;% \n  mutate(stillwater_class_description_corrected_grouped = str_extract(stillwater_class_description_corrected, \".*(?=\\\\ -)\"))\n\n# a) How many PIF compared to same time last year?\n# e) Average Premium change\ndata_restaurants %&gt;% \n  group_by(date) %&gt;% \n  summarize(n = n(),\n            mean_premium = mean(term_premium)) %&gt;% \n  pivot_longer(2:3, names_to = \"statistic\") %&gt;% \n  pivot_wider(names_from = 1) %&gt;% \n  mutate(statistic = if_else(statistic == \"mean_premium\", \"avg premium\", statistic),\n         change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Restaurants - PIF\") %&gt;% \n  cols_label(change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(rows = 1, columns = contains(\"-\"), decimals = 0) %&gt;% \n  fmt_currency(rows = 2, columns = contains(\"-\"), decimals = 2) %&gt;% \n  fmt_number(rows = 1, columns = change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_currency(rows = 2, columns = change, decimals = 2, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n# b) Distribution among main restaurant classes?\n\n# i) Asian, Pizza, Buffet, etc. \n\n# find counts for all classes\ndata_restaurants_regrouped &lt;- data_restaurants %&gt;%\n  group_by(date, stillwater_class_description_corrected_grouped) %&gt;% \n  summarize(n = n(),\n            mean_sales = mean(sales),\n            mean_premium = mean(term_premium)) %&gt;% \n  ungroup() %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n),\n         .after = n) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  mutate(stillwater_class_description_corrected_grouped = \n           case_when(\n             n &lt; 50 ~ \"Other\",\n             .default = stillwater_class_description_corrected_grouped\n           )\n         )\n\n# create counts for summary other row\ndata_restaurants_regrouped_other &lt;- data_restaurants_regrouped %&gt;% \n  filter(stillwater_class_description_corrected_grouped == \"Other\") %&gt;% \n  mutate(temp1 = n * mean_sales,\n         temp2 = n* mean_premium) %&gt;% \n  group_by(date, stillwater_class_description_corrected_grouped) %&gt;% \n  summarize(n = sum(n),\n            percent = sum(percent),\n            mean_sales = sum(temp1) / sum(n),\n            mean_premium = sum(temp2) / sum(n))\n\n# define helper function\ngrouped_mean &lt;- function(x, n) {\n  sum(x*n) / sum(n)\n}\n\n# create final table\ndata_restaurants_regrouped %&gt;% \n  filter(stillwater_class_description_corrected_grouped != \"Other\") %&gt;% \n  bind_rows(data_restaurants_regrouped_other) %&gt;% \n  gt(groupname_col = \"date\") %&gt;% \n  tab_header(title = \"Restaurants - PIF, sales and premium by class\") %&gt;% \n  cols_label(stillwater_class_description_corrected_grouped = \"class description\",\n             mean_sales = \"avg sales\",\n             mean_premium = \"avg premium\") %&gt;% \n  summary_rows(columns = n,\n               fns = list(id = \"Total\", fn = ~ sum(.x)),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  summary_rows(columns = percent,\n               fns = list(id = \"Total\", fn = ~ sum(.x)),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  summary_rows(columns = mean_sales,\n               fns = list(id = \"Total\", fn = ~ grouped_mean(mean_sales, n)),\n               fmt = ~ fmt_currency(., decimals = 0)) %&gt;%\n  summary_rows(columns = mean_premium,\n               fns = list(id = \"Total\", fn = ~ grouped_mean(mean_premium, n)),\n               fmt = ~ fmt_currency(., decimals = 0)) %&gt;% \n  fmt_number(columns = n, decimals = 0) %&gt;% \n  fmt_percent(columns = percent, decimals = 1) %&gt;% \n  fmt_currency(columns = c(mean_sales, mean_premium), decimals = 0)\n\n# ii) Alcohol percent distributions - Percent of policies with LQL\ndata_restaurants %&gt;% \n  count(date, lql_cov) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Restaurants - LQL cov\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(lql_cov = \"LQL cov\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# c) Percent with Building coverage\ndata_restaurants %&gt;% \n  count(date, bdg_cov) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Restaurants - BDG cov\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(bdg_cov = \"BDG cov\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# d) Annual Sales averages / distributions compared to last year\ndata_restaurants %&gt;% \n  summarise(.by = date,\n            across(sales, c(mean = mean, sd = sd, median = median, min = min, max = max), .names = \"{.fn}\"),\n            q1 = quantile(sales, probs = c(0.25)),\n            q3 = quantile(sales, probs = c(0.75))) %&gt;% \n  select(date, min, q1, median, mean, q3, max, sd) %&gt;% \n  pivot_longer(cols = -date, names_to = \"statistic\", values_to = \"value\") %&gt;% \n  pivot_wider(names_from = date) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Restaurants - Annual sales\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_currency(columns = contains(\"-\"), decimals = 0) %&gt;% \n  fmt_currency(columns = change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n# i) By class\n# see part b) i)) above\n\n# e) Average Premium change\n# see above part a)\n\n# i) By Class\n# see part b) i)) above\n\n### ---- Lessor’s risks / commercial landlords ----\n\n# save sub datasets\ndata_lessors &lt;- data_inforce_all %&gt;% \n  filter(lessor == \"Yes\") %&gt;% \n  mutate(hierarchy_1_grouped = \n           case_when(\n             hierarchy_1 == \"Landlord (aka Lessor)\" ~ hierarchy_1,\n             .default = \"Other\"\n           )\n         )\n\n# a) PIF compared to last year\ndata_lessors %&gt;% \n  count(date, occupy, hierarchy_1_grouped) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1:2, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Lessor's risks / commercial landlords - PIF\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(hierarchy_1_grouped = \"hierarchy 1\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# b) Distribution of Building Limits – how has it changed in last year?\ndata_lessors %&gt;% \n  summarise(.by = date,\n            date = max(date),\n            across(bdg_loi, c(mean = mean, sd = sd, median = median, min = min, max = max), .names = \"{.fn}\"),\n            q1 = quantile(bdg_loi, probs = c(0.25)),\n            q3 = quantile(bdg_loi, probs = c(0.75))) %&gt;% \n  select(date, min, q1, median, mean, q3, max, sd) %&gt;% \n  pivot_longer(cols = -1, names_to = \"statistic\", values_to = \"value\") %&gt;% \n  pivot_wider(names_from = date) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Lessor's risks / commercial landlords - BDG LOI\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_currency(columns = contains(\"-\"), decimals = 0) %&gt;% \n  fmt_currency(columns = change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n# c) Deductible distributions\n\n# –&gt; all perils\ndata_lessors %&gt;% \n  count(date, aop_deduct) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Lessor's risks / commercial landlords - All other perils deductibles\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(aop_deduct = \"AOP ded\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = c(starts_with(\"n\"), aop_deduct), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# -&gt; wind/hail\ndata_lessors %&gt;% \n  count(date, wh_percent_deduct, wh_dollar_deduct) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1:2, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Lessor's risks / commercial landlords - Wind / Hail deductibles\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(wh_percent_deduct = \"W/H % ded\",\n             wh_dollar_deduct = \"W/H $ ded\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = c(starts_with(\"n\"), contains(\"dollar\")), decimals = 0) %&gt;% \n  fmt_percent(columns = contains(\"percent\"), decimals = 1)\n\n# d) Age of building distribution and compared to last year\ndata_lessors %&gt;% \n  mutate(building_age = subtract(date %&gt;% year, year_built)) %&gt;% \n  summarise(.by = date,\n            date = max(date),\n            across(building_age, c(mean = mean, sd = sd, median = median, min = min, max = max), .names = \"{.fn}\"),\n            q1 = quantile(building_age, probs = c(0.25)),\n            q3 = quantile(building_age, probs = c(0.75))) %&gt;% \n  select(date, min, q1, median, mean, q3, max, sd) %&gt;% \n  pivot_longer(cols = -1, names_to = \"statistic\", values_to = \"value\") %&gt;% \n  pivot_wider(names_from = date) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Lessor's risks / commercial landlords - Age of building\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(columns = contains(\"-\"), decimals = 1) %&gt;% \n  fmt_number(columns = change, decimals = 1, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n### ---- Roofs ----\n\n# split data\ndata_bdg &lt;- data_inforce_all %&gt;% \n  mutate(building = if_else(building_owned == \"Yes\" | bdg_cov == \"Y\", TRUE, FALSE))\ndata_roofs &lt;- data_bdg %&gt;% \n  split(f = .$building)\n\n# 0) look at own buildings\ndata_bdg %&gt;% \n  count(date, building_owned, bdg_cov) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1:2, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Own building / building coverage\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(building_owned = \"Own building?\",\n             bdg_cov = \"BDG cov?\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = c(starts_with(\"n\"), contains(\"dollar\")), decimals = 0) %&gt;% \n  fmt_percent(columns = contains(\"percent\"), decimals = 1)\n  \n# a) Distribution of roof types\ndata_roofs[[\"FALSE\"]] %&gt;%  \n  count(date, roof_type) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Roofs - No BDG cov - Type\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(roof_type = \"Type\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\ndata_roofs[[\"TRUE\"]] %&gt;%  \n  count(date, roof_type) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent)) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Roofs - BDG cov - Type\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(roof_type = \"Type\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# b) Age of roof distributions\ndata_roofs[[\"FALSE\"]] %&gt;% \n  mutate(roof_age = subtract(date %&gt;% year, roof_year)) %&gt;% \n  summarise(.by = date,\n            date = max(date),\n            across(roof_age, c(mean = mean, sd = sd, median = median, min = min, max = max), .names = \"{.fn}\"),\n            q1 = quantile(roof_age, probs = c(0.25), na.rm = TRUE),\n            q3 = quantile(roof_age, probs = c(0.75), na.rm = TRUE)) %&gt;% \n  select(date, min, q1, median, mean, q3, max, sd) %&gt;% \n  pivot_longer(cols = -1, names_to = \"statistic\", values_to = \"value\") %&gt;% \n  pivot_wider(names_from = date) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Roofs - No BDG cov - Age\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(columns = contains(\"-\"), decimals = 1) %&gt;% \n  fmt_number(columns = change, decimals = 1, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\ndata_roofs[[\"TRUE\"]] %&gt;% \n  mutate(roof_age = subtract(date %&gt;% year, roof_year)) %&gt;% \n  summarise(.by = date,\n            date = max(date),\n            across(roof_age, c(mean = mean, sd = sd, median = median, min = min, max = max), .names = \"{.fn}\"),\n            q1 = quantile(roof_age, probs = c(0.25), na.rm = TRUE),\n            q3 = quantile(roof_age, probs = c(0.75), na.rm = TRUE)) %&gt;% \n  select(date, min, q1, median, mean, q3, max, sd) %&gt;% \n  pivot_longer(cols = -1, names_to = \"statistic\", values_to = \"value\") %&gt;% \n  pivot_wider(names_from = date) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Roofs - BDG cov - Age\") %&gt;% \n  cols_label(statistic = \"\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(columns = contains(\"-\"), decimals = 1) %&gt;% \n  fmt_number(columns = change, decimals = 1, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n### ---- Classes ----\n\n# a) How has our overall policy count by classes and Program changed over the past year?\n\n# find counts for all classes\ndata_classes_regrouped &lt;- data_inforce_all %&gt;%\n  count(date, stillwater_class_description_corrected) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n),\n         .after = n) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  mutate(stillwater_class_description_corrected = \n           case_when(\n             n &lt; 50 ~ \"Other\",\n             .default = stillwater_class_description_corrected\n            )\n         )\n\n# create counts for summary other row\ndata_classes_regrouped_other &lt;- data_classes_regrouped %&gt;% \n  filter(stillwater_class_description_corrected == \"Other\") %&gt;% \n  group_by(date, stillwater_class_description_corrected) %&gt;% \n  summarize(n = sum(n),\n            percent = sum(percent))\n\n# create final table\ndata_classes_regrouped %&gt;% \n  filter(stillwater_class_description_corrected != \"Other\") %&gt;% \n  bind_rows(data_classes_regrouped_other) %&gt;% \n  gt(groupname_col = \"date\") %&gt;% \n  tab_header(title = \"Classes - PIF\") %&gt;% \n  cols_label(stillwater_class_description_corrected = \"class description\") %&gt;% \n  summary_rows(columns = n,\n               fns = list(id = \"Total\", fn = ~ sum(.x)),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  summary_rows(columns = percent,\n               fns = list(id = \"Total\", fn = ~ sum(.x)),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = n, decimals = 0) %&gt;% \n  fmt_percent(columns = percent, decimals = 1)\n\n### ---- States ----\n\n# a) Which states are growing and shrinking? By how much?\ndata_inforce_all %&gt;% \n  group_by(date, policy_state) %&gt;% \n  summarize(n = n(),\n            mean_premium = mean(term_premium)) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, mean_premium), values_fill = 0) %&gt;% \n  mutate(n_change = `n_2025-05-02` - `n_2024-04-30`,\n         n_percent_change = if_else(is.nan(n_change / `n_2024-04-30`) | is.infinite(n_change / `n_2024-04-30`) | is.infinite(n_change / `n_2024-04-30`), NA, n_change / `n_2024-04-30`),\n         mean_premium_change = `mean_premium_2025-05-02` - `mean_premium_2024-04-30`,\n         mean_premium_percent_change = mean_premium_change / `mean_premium_2024-04-30`) %&gt;% \n  select(policy_state, `n_2024-04-30`, `n_2025-05-02`, n_change, n_percent_change, `mean_premium_2024-04-30`, `mean_premium_2025-05-02`, mean_premium_change, mean_premium_percent_change) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"States - PIF\") %&gt;% \n  tab_spanner(columns = c(`n_2024-04-30`, `n_2025-05-02`, n_change, n_percent_change),\n              label = \"n\") %&gt;% \n  tab_spanner(columns = c(`mean_premium_2024-04-30`, `mean_premium_2025-05-02`, mean_premium_change, mean_premium_percent_change),\n              label = \"mean premium\") %&gt;% \n  cols_label(policy_state = \"State\",\n             `n_2024-04-30` = \"2024-04-30\",\n             `n_2025-05-02` = \"2025-05-02\",\n             `mean_premium_2024-04-30` = \"2024-04-30\",\n             `mean_premium_2025-05-02` = \"2025-05-02\",\n             n_change = \"change\",\n             n_percent_change = \"% change\",\n             mean_premium_change = \"$ change\",\n             mean_premium_percent_change = \"% change\") %&gt;% \n  grand_summary_rows(columns = c(`n_2024-04-30`, `n_2025-05-02`),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = `mean_premium_2024-04-30`,\n               fns = list(id = \"Total\", fn = ~ grouped_mean(.x, `n_2024-04-30`)),\n               fmt = ~ fmt_currency(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = `mean_premium_2025-05-02`,\n               fns = list(id = \"Total\", fn = ~ grouped_mean(.x, `n_2025-05-02`)),\n               fmt = ~ fmt_currency(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns  = n_change,\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0, force_sign = TRUE)) %&gt;% \n  grand_summary_rows(columns = `mean_premium_change`,\n                     fns = list(id = \"Total\", fn = ~ grouped_mean(`mean_premium_2025-05-02`, `n_2025-05-02`) - grouped_mean(`mean_premium_2024-04-30`, `n_2024-04-30`)),\n                     fmt = ~ fmt_currency(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = n_percent_change,\n                     fns = list(id = \"Total\", fn = ~ (sum(`n_2025-05-02`) - sum(`n_2024-04-30`)) / sum(`n_2024-04-30`)),\n                     fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  grand_summary_rows(columns = mean_premium_percent_change,\n                     fns = list(id = \"Total\", fn = ~ (grouped_mean(`mean_premium_2025-05-02`, `n_2025-05-02`) - grouped_mean(`mean_premium_2024-04-30`, `n_2024-04-30`)) / grouped_mean(`mean_premium_2024-04-30`, `n_2024-04-30`)),\n                     fmt = ~ fmt_percent(., decimals = 1)) %&gt;%\n  fmt_number(columns = c(`n_2024-04-30`, `n_2025-05-02`, n_change), decimals = 0) %&gt;% \n  fmt_currency(columns = c(`mean_premium_2024-04-30`, `mean_premium_2025-05-02`), decimals = 0) %&gt;% \n  fmt_currency(columns = mean_premium_change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = contains(\"percent_change\"), decimals = 1, force_sign = TRUE) %&gt;% \n  gt_add_divider(columns = n_percent_change, color = \"grey30\")\n\n# follow-up -&gt; look into negative average premium changes\n# split data\ndata_split_premium &lt;- data_inforce_all %&gt;% \n  split(f = .$date)\n\n# combine data again and create status variable\ndata_states &lt;- data_split_premium[[1]] %&gt;% \n  select(policy_state, policy_number, term_premium) %&gt;% \n  full_join(data_split_premium[[2]] %&gt;% select(policy_state, policy_number, term_premium), by = join_by(policy_number), suffix = c(\"_old\", \"_new\")) %&gt;% \n  mutate(change = term_premium_new - term_premium_old,\n         status = case_when(\n           is.na(term_premium_old) & term_premium_new &gt; 0 ~ 3,\n           term_premium_old &gt; 0 & is.na(term_premium_new) ~ 2,\n           .default = 1\n         ),\n         policy_state = case_when(\n           status == 3 ~ policy_state_new,\n           status == 2 ~ policy_state_old,\n           .default = policy_state_old\n         )) %&gt;% \n  select(policy_state, policy_number, status, term_premium_old, term_premium_new) %&gt;% \n  group_by(policy_state, status) %&gt;% \n  summarize(n = n(),\n            across(contains(\"premium\"), mean))\n\n# create overall summary rows\ndata_summ1 &lt;- data_states %&gt;% \n  select(policy_state, status, n, term_premium_old) %&gt;% \n  filter(!is.na(term_premium_old)) %&gt;% \n  summarize(across(contains(\"premium\"), ~ sum(n * .x) / sum(n))) %&gt;% \n  mutate(status = 4,\n         .before = 1)\ndata_summ2 &lt;- data_states %&gt;% \n  select(policy_state, status, n, term_premium_new) %&gt;% \n  filter(!is.na(term_premium_new)) %&gt;% \n  summarize(across(contains(\"premium\"), ~ sum(n * .x) / sum(n))) %&gt;% \n  mutate(status = 4,\n         .before = 1)\n\n# create final table\ndata_states %&gt;% \n  bind_rows(data_summ1 %&gt;% left_join(data_summ2, by = join_by(policy_state, status))) %&gt;% \n  arrange(policy_state, status) %&gt;% \n  mutate(status = case_when(\n    status == 1 ~ \"renew\",\n    status == 2 ~ \"non-renew\",\n    status == 3 ~ \"new business\",\n    status == 4 ~ \"overall\"\n  ),\n  mean_premium_change = term_premium_new - term_premium_old) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"States - Average premium changes by status\") %&gt;% \n  cols_label(term_premium_old = \"2024-04-30\",\n             term_premium_new = \"2025-05-02\",\n             mean_premium_change = \"mean change in premium\") %&gt;% \n  fmt_number(columns = n, decimals = 0) %&gt;% \n  fmt_currency(columns = contains(\"term\"), decimals = 0) %&gt;% \n  fmt_currency(columns = mean_premium_change, decimals = 0, force_sign = TRUE)\n\n# b) Any particular classes growing quickly in specific states?\ndata_inforce_all %&gt;% \n  count(date, policy_state, stillwater_class_description_corrected) %&gt;% \n  arrange(date, policy_state, desc(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = n, values_fill = 0) %&gt;% \n  mutate(change = `2025-05-02` - `2024-04-30`,\n         percent_change = if_else(is.nan(change / `2024-04-30`) | is.infinite(change / `2024-04-30`) | is.infinite(change / `2024-04-30`), NA, change / `2024-04-30`)) %&gt;% \n  filter(`2024-04-30` &gt; 50 & abs(percent_change) &gt; hl_cutoff) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"States - Large PIF changes by class\") %&gt;% \n  cols_label(policy_state = \"State\",\n             stillwater_class_description_corrected = \"class description\",\n             change = \"change\",\n             percent_change = \"% change\") %&gt;% \n  fmt_number(columns = contains(\"-\"), decimals = 0) %&gt;% \n  fmt_number(columns = change, decimals = 0, force_sign = TRUE) %&gt;% \n  fmt_percent(columns = percent_change, decimals = 1, force_sign = TRUE) %&gt;% \n  format_tbl_conditional_hl_changes() %&gt;% \n  gt_add_divider(columns = `2025-05-02`, color = \"grey30\")\n\n### ---- New business versus renewals ----\n\n# add new variable and save dataset\ndata_new_business &lt;- data_inforce_all %&gt;% \n  mutate(new_business = if_else(policy_effective_date == inception_date, TRUE, FALSE), .before = 3)\n\n# 0) New business rate\ndata_new_business %&gt;% \n  summarize(.by = date,\n            policy_count = n(),\n            new_business_count = sum(new_business),\n            percent_new_business = mean(new_business),\n            percent_renewal = 1 - mean(new_business)) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"New business rates\") %&gt;% \n  cols_label(policy_count = \"Total policies\",\n             new_business_count = \"Count NB\",\n             percent_new_business = \"Percent NB\",\n             percent_renewal = \"Percent Ren\") %&gt;% \n  fmt_number(columns = contains(\"count\"), decimals = 0) %&gt;% \n  fmt_percent(columns = contains(\"percent\"), decimals = 1)\n\n# a) Retention rate\n\n# read in old old inforce data\ndata_inforce_old_old &lt;- readxl::read_xlsx(path = \"InForce_20230430.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n    mutate(date = ymd(\"2023-04-30\"), .before = 1)\n\n# convert datasets to list\ndata_split_retention_1 &lt;- data_inforce_old_old %&gt;% \n  bind_rows(data_inforce_old) %&gt;% \n  split(.$date)\n\n# calculate retention rate\ndata_retention &lt;- data_split_retention_1$`2023-04-30` %&gt;% \n  left_join(data_split_retention_1$`2024-04-30` %&gt;% select(date, policy_number), by = join_by(policy_number), suffix = c(\"_old_old\", \"_old\")) %&gt;% \n  mutate(retained = if_else(!is.na(date_old), TRUE, FALSE)) %&gt;% \n  summarize(starting_policies = n(),\n            retained_count = sum(retained),\n            retained_percent = mean(retained)) %&gt;% \n  mutate(timeframe = \"2023 to 2024\",\n         .before = 1)\n\n# convert datasets to list\ndata_split_retention2 &lt;- data_inforce_all %&gt;% \n  split(.$date)\n\n# calculate retention rate\ndata_split_retention2$`2024-04-30` %&gt;% \n  left_join(data_split_retention2$`2025-05-02` %&gt;% select(date, policy_number), by = join_by(policy_number), suffix = c(\"_old\", \"_new\")) %&gt;% \n  mutate(retained = if_else(!is.na(date_new), TRUE, FALSE)) %&gt;% \n  summarize(starting_policies = n(),\n            retained_count = sum(retained),\n            retained_percent = mean(retained)) %&gt;% \n  mutate(timeframe = \"2024 to 2025\",\n         .before = 1) %&gt;% \n  {bind_rows(data_retention, .)} %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Retention rates\") %&gt;% \n  cols_label(timeframe = \"Timeframe\",\n             starting_policies = \"Starting policies\",\n             retained_count = \"Count retained\",\n             retained_percent = \"Percent retained\") %&gt;% \n  fmt_number(columns = c(starting_policies, retained_count), decimals = 0) %&gt;% \n  fmt_percent(columns = retained_percent, decimals = 1)\n\n# a) Can we determine how the distribution of our new business (last two months?) has changed from the overall in-force book? I’m looking to see how our changes in rules and processes may have changed what is coming through the door as new business.\ndata_recent &lt;- data_new_business %&gt;% \n  filter(date == max(date)) %&gt;% \n  mutate(recent_new_business = if_else(new_business & ymd(policy_effective_date) &gt;= ymd(\"2025-03-01\"), TRUE, FALSE),\n         .before = 4)\n\n# what specifically to look at??? Is there a list of recent actions taken?\n# -&gt; lets start with hierarchy 1 / classes\ndata_recent %&gt;% \n  count(recent_new_business, hierarchy_1) %&gt;% \n  mutate(.by = recent_new_business,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = recent_new_business, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1, contains(\"FALSE\"), contains(\"TRUE\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Recent new business (written &lt; 2 months ago) - Classes\") %&gt;% \n  tab_spanner(columns = contains(\"FALSE\"),\n              label = \"No\") %&gt;% \n  tab_spanner(columns = contains(\"TRUE\"),\n              label = \"Yes\") %&gt;% \n  cols_label(hierarchy_1 = \"Hierarchy 1\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# look into types of restaurants\ndata_recent_restaurants &lt;- data_recent %&gt;% \n  filter(hierarchy_1 == \"Restaurants, Eating and Drinking Places\") %&gt;% \n  mutate(stillwater_class_description_corrected_grouped = str_extract(stillwater_class_description_corrected, \".*(?=\\\\ -)\"))\n\ndata_recent_restaurants %&gt;% \n  count(recent_new_business, stillwater_class_description_corrected_grouped) %&gt;% \n  mutate(.by = recent_new_business,\n         percent = n / sum(n)) %&gt;% \n  arrange(recent_new_business, desc(n)) %&gt;% \n  pivot_wider(names_from = recent_new_business, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1, contains(\"FALSE\"), contains(\"TRUE\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"Recent new business (written &lt; 2 months ago) - Restaurant types\") %&gt;% \n  tab_spanner(columns = contains(\"FALSE\"),\n              label = \"No\") %&gt;% \n  tab_spanner(columns = contains(\"TRUE\"),\n              label = \"Yes\") %&gt;% \n  cols_label(stillwater_class_description_corrected_grouped = \"Class\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n### ---- Tennessee ----\n\n# look into reduction of PIF in TN\ndata_tn &lt;- data_inforce_all %&gt;% \n  filter(policy_state == \"TN\")\n\n# type of policy\ndata_tn %&gt;% \n  count(date, bdg_cov, bpp_cov) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1:2, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"TN - Type of policy\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(bdg_cov = \"BDG\",\n             bpp_cov = \"BPP\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_percent(columns = contains(\"percent\"), decimals = 1)\n\n# location\ndata_tn %&gt;% \n  mutate(location_city = if_else(date == ymd(\"2024-04-30\"), mailing_city, location_city)) %&gt;% \n  count(date, location_city) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  mutate(.by = date,\n         percent = n / sum(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = c(n, percent), values_fill = 0) %&gt;% \n  select(1, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"TN - Locations\") %&gt;% \n  tab_spanner(columns = contains(\"2024\"),\n              label = \"2024-04-30\") %&gt;% \n  tab_spanner(columns = contains(\"2025\"),\n              label = \"2025-05-02\") %&gt;% \n  cols_label(location_city = \"Location city\",\n             starts_with(\"n\") ~ \"n\",\n             starts_with(\"percent\") ~ \"percent\") %&gt;% \n  grand_summary_rows(columns = starts_with(\"n\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  grand_summary_rows(columns = starts_with(\"percent\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_percent(., decimals = 1)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0) %&gt;% \n  fmt_percent(columns = starts_with(\"percent\"), decimals = 1)\n\n# business class\ndata_tn %&gt;% \n  count(date, stillwater_class_description_corrected) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = n, values_fill = 0) %&gt;% \n  select(1:3, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"TN - Business class\") %&gt;% \n  cols_label(stillwater_class_description_corrected = \"class\",\n             starts_with(\"n\") ~ \"n\") %&gt;% \n  grand_summary_rows(columns = contains(\"-\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0)\n\n# agents\ndata_tn %&gt;% \n  count(date, agency, sub_agent, agent) %&gt;% \n  arrange(date, desc(n)) %&gt;% \n  pivot_wider(names_from = date, values_from = n, values_fill = 0) %&gt;% \n  select(1:3, contains(\"2024\"), contains(\"2025\")) %&gt;% \n  gt() %&gt;% \n  tab_header(title = \"TN - Agents\") %&gt;% \n  cols_label(sub_agent = \"sub agent\",\n             starts_with(\"n\") ~ \"n\") %&gt;% \n  grand_summary_rows(columns = contains(\"-\"),\n               fns = list(label = \"Total\", fn = \"sum\"),\n               fmt = ~ fmt_number(., decimals = 0)) %&gt;% \n  fmt_number(columns = starts_with(\"n\"), decimals = 0)\n\n\n2.1.5 Large risks analysis\n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(furrr)\nlibrary(leaflet)\n\n# read in inforce file from excel\ndata_inforce_raw &lt;- readxlsb::read_xlsb(\"InForce_20241001.xlsb\", sheet = 1)\n\n# rename variables\n# -&gt; select only needed columns\n# -&gt; combine address information\ndata_inforce &lt;- data_inforce_raw %&gt;% \n  janitor::clean_names() %&gt;% \n  select(policy_number, policy_effective_date, policy_expiration_date, policy_status, named_insured, location_address, location_city, location_state, location_zip_code, policy_state, longitude, latitude, stillwater_class_description, hierarchy_1, bdg_loi, bpp_loi) %&gt;% \n  mutate(location_address = paste0(location_address, \", \", location_city, \" \", location_zip_code, \" \", location_state), .before = policy_state) %&gt;% \n  select(!c(location_city, location_state, location_zip_code)) %&gt;% \n  mutate(combined_loi = bdg_loi + bpp_loi)\n\n# save as .RData file\nsave(data_inforce, file = \"data-inforce.RData\")\n\n# read in cleaned inforce file from RData file\nload(\"data-inforce.RData\")\n\n# define function to determine large risks\n# criteria: within radius and individually less than limit\n# -&gt; radius of 0.282 gives a quarter-mile in area; limit of $1.5M needs to be looked at\n# -&gt; if above limit, it has already been looked at closely; so focusing on aggregate risks\nfind_large_risks &lt;- function(i, df, radius = 0.282, limit = 1500000) {\n  \n  # tracking purposes\n  if(i %% 100 == 0)\n    print(i)\n  \n  # single out row for comparison\n  data_i = df[i, ] %&gt;% mutate(distance_from_i = 0)\n  \n  # create dataframe of all other rows\n  data_other = df[-i,]\n  \n  # calculate distance to all other policies\n  # -&gt; filter to all within a mile (after converting to miles)\n  data_close = data_other %&gt;% \n    rowwise %&gt;% \n    mutate(distance_from_i = geosphere::distm(x = c(data_i$longitude, data_i$latitude),\n                                              y = c(longitude, latitude), fun = geosphere::distHaversine) %&gt;% as.numeric %&gt;% multiply_by(0.00062137)\n    ) %&gt;% \n    ungroup() %&gt;% \n    bind_rows(data_i, .) %&gt;% \n    filter(distance_from_i &lt;= radius, combined_loi &lt;= limit)\n  \n  # calculate combined LOI for close policies and determine if over limit\n  combined_risk = data_close %&gt;% \n    summarize(sum(combined_loi)) %&gt;% \n    as.numeric()\n  large_risk_flag = if_else(combined_risk &gt; limit, 1, 0)\n  \n  # return results\n  if(large_risk_flag == 1) {\n    data_close$policy_number %&gt;% \n      return\n  }\n}\n\n# setup plan\nplan(multisession, workers = availableCores()-4)\ntictoc::tic()\n\n# find all large risks (within a 1/4 mile of each of the reference policy (first one in list))\n# -&gt; exclude policies with no lat/long\ndata_groups &lt;- data_inforce %&gt;% \n  filter(longitude != 0, latitude != 0) %&gt;% \n  {future_map(1:nrow(.), function(i) find_large_risks(i, df = .))}\ndata_groups[sapply(data_groups, is.null)] &lt;- NULL\n\n# save results\nsave(data_groups, file = \"data-groups.RData\")\n\n# load results\nload(\"data-groups.RData\")\n\n# pull corresponding info from inforce data\ndata_large_risks &lt;- map2(data_groups, 1:length(data_groups),\n                         function(policy_nums, i) {\n                           data_inforce %&gt;% \n                             filter(policy_number %in% policy_nums) %&gt;% \n                             mutate(group = i,\n                                    group_loi = sum(combined_loi),\n                                    .before = 1)\n                         }) %&gt;% \n  reduce(bind_rows) %&gt;% \n  split(.$group_loi) %&gt;% # making assumption that all groups with same group_loi are actually the same group, just different reference policy\n  map(function(df) {\n    \n    # remove repeat records\n    df %&gt;% \n      select(-group) %&gt;% \n      distinct(.keep_all = TRUE)\n    \n  }) %&gt;% \n  reduce(bind_rows) %&gt;% \n  mutate(.by = group_loi, group = cur_group_id(), .before = 1)\n\n# output results\nopenxlsx2::write_xlsx(data_large_risks, \"large-risks-analysis.xlsx\")\ntictoc::toc()\n\n# load states shape file\ndata_states &lt;- tigris::states(cb = TRUE) %&gt;% \n  sf::st_transform('+proj=longlat +datum=WGS84')\n\n# define function to set the color of the icon\nget_color_icon &lt;- function(df) {\n  sapply(df$reinsurance, function(reinsurance) {\n  if(reinsurance == 1) {\n    \"green\"\n  } else {\n    \"black\"\n  } })\n}\n\n# define function to set the color of the marker\nget_color_marker &lt;- function(df) {\n  sapply(df$group_loi, function(group_loi) {\n  if(group_loi / 1000000 &lt;= 2) {\n    \"blue\"\n  } else if(group_loi / 1000000 &lt;= 4)  {\n    \"orange\"\n  } else {\n    \"red\"\n  } })\n}\n\n# calculate reinsurance flag\n# -&gt; determine if named_insured is the same within groups\ndata_large_risks %&lt;&gt;% \n  split(.$group) %&gt;% \n  map(function(df) {\n    \n    # check count of named insured and join calculation back onto original df\n    df %&gt;% \n      count(named_insured) %&gt;% \n      mutate(reinsurance = if_else(n &gt; 1, 1, 0)) %&gt;% \n      right_join(df, by = join_by(named_insured)) %&gt;% \n      select(4:9, 1, 10:18, 3) # manually reorder \n    \n  }) %&gt;% \n  reduce(bind_rows)\n\n# create icons\nicons &lt;- awesomeIcons(\n  icon = \"ios-close\",\n  iconColor = get_color_icon(data_large_risks),\n  library = \"ion\",\n  markerColor = get_color_marker(data_large_risks)\n)\n\n# create map\nm &lt;- leaflet(data_states) %&gt;% \n  setView(-96, 37.8, 4) %&gt;% \n  addTiles() %&gt;% \n  addAwesomeMarkers(data = data_large_risks,\n                    lng = ~longitude,\n                    lat = ~latitude,\n                    icon = icons,\n                    label= ~paste0(\"$\", round(combined_loi / 1000, 0), \"K; \", named_insured, \"; \", policy_number))\n\n# (actually a quarto chunk with the following options)\n\n##| column: screen-inset-right\n##| out-width: 100%\n##| out-height: 1000px\n\n# view plot\n# -&gt; in separate chunk so when rendered the progress bars don't show up\nm\n\n# **How to read plot**:\n\n# -&gt; Marker for every individual policy\n\n# -&gt; Hover over to display the combined LOI, named insured and policy number\n\n# -&gt; Markers are colored by aggregate LOI of nearby policies:\n\n#    - [$1.5M &lt;= Aggregate LOI &lt;= $2M]{style=\"color:blue;\"}\n    \n#    - [$2M &lt; Aggregate LOI &lt;= $4M]{style=\"color:orange;\"}\n    \n#    - [Aggregate LOI &gt; $4M]{style=\"color:red;\"}\n\n#- &gt; [Green X]{style=\"color:green;\"} on marker indicates that this is a policy that has matching named insured as other policies; so, there is potential for reinsurance\n\n# **How data was created**:\n\n# -&gt; For every policy in the inforce file as of 10/1/2024:\n\n#1) Calculate the distance to all other policies\n\n#2) Find policies within a 0.25 square-mile area circle around the reference policy location\n\n#3) For the nearby policies, calculate the aggregate LOI and flag if over $1.5M\n\n# get potential reinsurance policies\ndata_reinsurance &lt;- data_large_risks %&gt;% \n  filter(reinsurance == 1) %&gt;% \n  distinct(policy_number, .keep_all = TRUE) %&gt;% \n  select(-c(starts_with(\"group\"), reinsurance)) %&gt;% \n  arrange(policy_state, named_insured)\n\n# output results\nopenxlsx2::write_xlsx(data_reinsurance, \"data-reinsurance.xlsx\")\n\n\n2.1.6 Long tail analyses\n\n### ---- Load packages ---- \n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\n\n### ---- Read in data ---- \n\n# claims data\ndata_claims_raw &lt;- readxl::read_xlsx(path = \"claims-commercial-detail.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n  select(1:4, 7, 10:11, 17:18, 31) %&gt;% \n  filter(policy_type == \"BP\") %&gt;% \n  mutate(total_incurred = incurred_loss + incurred_lae)\n\n# policy life data\n# -&gt; some odd duplicate policy numbers, just removing them\ndata_policy_life_raw &lt;- readxl::read_xlsx(path = \"policy-life-analysis.xlsx\") %&gt;%\n  janitor::clean_names() %&gt;% \n  distinct(policy_number, .keep_all = TRUE)\n\n### ---- Modify data ---- \n\n# calculate new fields and attach policy life analysis data\ndata_long_tail &lt;- data_claims_raw %&gt;% \n  mutate(date_lag = lubridate::interval(loss_date, report_date) %/% days(1)) %&gt;% \n  summarize(.by = c(claim, policy, state, loss_date, report_date, business_description, date_lag),\n            across(contains(\"incurred\"), sum)) %&gt;% \n  mutate(long_date_lag_flag = ifelse(date_lag &gt; 365, \"Y\", \"N\"),\n         large_loss_flag = ifelse(total_incurred &gt; 100000, \"Y\", \"N\")) %&gt;% \n  left_join(data_policy_life_raw %&gt;% select(-c(policy_state, policy_type)), by = join_by(policy == policy_number), relationship = \"many-to-one\")\n\n# output raw data to add to workbook so can build pivots\nwrite.csv(data_long_tail, \"output/raw-data.csv\")\n\n### ---- Load updated data ---- \n\n# load manually edited data\n# -&gt; David added missing hierarchy1 information, just uploading this\n# claims data\ndata_long_tail &lt;- readxl::read_xlsx(path = \"modified-edited-data.xlsx\")\n\n### ---- Recreating business class analysis ---- \n\n# summarize by business description\n# -&gt; recreating David's pivot table with added requested features\ndata_pivot &lt;- data_long_tail %&gt;% \n  summarize(.by = business_description,\n            claim_count = n(),\n            total_incurred_sum = sum(total_incurred),\n            total_incurred_avg = mean(total_incurred),\n            large_loss_flag = sum(large_loss_flag == \"Y\"),\n            date_lag_avg = mean(date_lag),\n            date_lag_med = median(date_lag),\n            long_date_lag_flag = sum(long_date_lag_flag == \"Y\")) %&gt;% \n  arrange(desc(date_lag_med), desc(total_incurred_sum)) %&gt;% \n  relocate(long_date_lag_flag, date_lag_avg, date_lag_med, .after = claim_count)\n\nwrite.csv(data_pivot, \"output/test.csv\")\n\n### ---- Hierarchy analysis ---- \n\n# new analysis by different grouping variable\n# -&gt; what is the distribution of losses by hierarchy1\ndata_pivot2 &lt;- data_long_tail %&gt;% \n  summarize(.by = hierarchy_1,\n            claim_count = n(),\n            total_incurred_sum = sum(total_incurred),\n            total_incurred_avg = mean(total_incurred),\n            large_loss_flag = sum(large_loss_flag == \"Y\"),\n            date_lag_avg = mean(date_lag),\n            date_lag_med = median(date_lag),\n            #percent_long_date_flag = mean(long_date_lag_flag == \"Y\"),\n            long_date_lag_flag = sum(long_date_lag_flag == \"Y\")) %&gt;% \n  arrange(desc(date_lag_med), desc(total_incurred_avg)) %&gt;% \n  relocate(long_date_lag_flag, date_lag_avg, date_lag_med, .after = claim_count)\n\n# output and copy paste into workbook\nwrite.csv(data_pivot2, \"output/hierarchy-analysis.csv\")\n\n### ---- Long tail losses analysis ---- \n\n# another analysis\n# -&gt; attempting to answer: of the long date lag losses, what is the breakdown by grouping variable?\ndata_table &lt;- data_long_tail %&gt;% \n  filter(long_date_lag_flag == \"Y\") %&gt;% \n  summarize(.by = business_description,\n            n = n(),\n            large_loss_flag = sum(large_loss_flag == \"Y\")) %&gt;% \n  mutate(percent = n / sum(n)) %&gt;% \n         #percent_large_loss_flag = large_loss_flag / n) %&gt;% \n  relocate(percent, .after = n) %&gt;% \n  arrange(desc(n))\n\nwrite.csv(data_table, \"output/long-tail-losses1.csv\")\n\n\ndata_table2 &lt;- data_long_tail %&gt;% \n  filter(long_date_lag_flag == \"Y\") %&gt;% \n  summarize(.by = hierarchy_1,\n            n = n(),\n            large_loss_flag = sum(large_loss_flag == \"Y\")) %&gt;% \n  mutate(percent = n / sum(n)) %&gt;% \n         #percent_large_loss_flag = large_loss_flag / n) %&gt;% \n  relocate(percent, .after = n) %&gt;% \n  arrange(desc(n))\n\nwrite.csv(data_table2, \"output/long-tail-losses2.csv\")\n\n\n2.1.7 Policy life analysis\n\n### ---- Query data ----\n\n# Steps\n\n# 1. Run `policy-life-analysis.sql` query. (don't have code here...)\n\n# 2. Copy and paste all data into `policy-life-analysis.csv`.\n\n### ---- Load data ----\n\n# function to compare two objects\n# -&gt; using it to compare results of same thing from different methods\n# -&gt; works for all data types (numeric vectors, character / factor vectors, dataframes with same dimensions, lists of anything)\n# default options -&gt; return original items (for easy visual comparison in same output), tolerance in numeric comparison is 1 x 10^-5 (out to 5 decimals, 0.00001), check.names = FALSE to only check values and NOT the names of elements\n# return values -&gt; list of 1) summary of comparison, 2 and 3) original items if desired\n# -&gt; 1) includes logical of overall comparison and if NOT EQUAL description of differences + element-wise comparison of vectors or columns of dataframe\ncompare &lt;- function(item_1, item_2, return_items = TRUE, tolerance = 0.00001, check.names = FALSE) {\n  \n  # initialize a list with helpful names for the results and original items being compared\n  # -&gt; the extra functions for the names just return the name / call of the original arguments passed to item_1 and item_2\n  results = vector(mode = \"list\", length = 3)\n  names(results) = c(\"comparison\", deparse(substitute(item_1)), deparse(substitute(item_2)))\n  \n  # check equality with all.equal()\n  # -&gt; returns TRUE when TRUE and a character string describing the difference when FALSE\n  # -&gt; allows for a tolerance in numeric comparisons, which is ideal to account for rounding\n  # --&gt; AND includes option to ignore names (so just focus comparison on values of elements)\n  comparison = all.equal(item_1, item_2, tolerance = tolerance, check.names = check.names)\n  \n  # check class of item 1 (assuming item 2 is the same)\n  # check if numeric \n  \n  # if equal (with tolerance), returns TRUE comparison\n  #-&gt; by default, it is only looking at the values and NOT the names\n  # -&gt; check by seeing if comparison is TRUE, if so return TRUE\n  if (identical(comparison, TRUE)) {\n    \n    results[[1]] = comparison\n    \n  }\n  \n  # if not equal, return a list with items describing comparison \n  else {\n    \n    # fill results with elements for:\n    # -&gt; overall comparison result = FALSE\n    # -&gt; description of inequalities = output of all.equal when not TRUE\n    # -&gt; conditionally return vector of element wise comparison (with names removed) based on class of items\n    # --&gt; throws warning message when lengths differ, but still does comparison\n    results[[1]] = list(\n      \"result\" = identical(comparison, TRUE),\n      \"description\" = comparison,\n      \"element-wise\" = \n        \n        # if numeric, compare items after rounding\n        if (identical(class(item_1), \"numeric\")) {\n          \n          # calculate number of decimals to round to before element-wise comparison as a function of the tolerance, \n          # -&gt; e.g) tolerance = 0.00001 --&gt; abs(log10(tolerance)) = 5\n          # -&gt; ceiling() accounts for non base 10 tolerances so still have a whole number of digits for rounding\n          decimals = ceiling(abs(log10(tolerance)))\n          round(as.numeric(item_1), decimals) == round(as.numeric(item_2), decimals)\n          \n          \n        }\n      \n      # first if character or factor, simply compare\n      else if (identical(class(item_1), \"character\") | identical(class(item_1), \"factor\")) {\n        \n        # convert to character to take into account factors\n        as.character(item_1) == as.character(item_2)\n        \n        \n      }\n      \n      # if dataframe, correctly compare columns after checking column data type\n      # different comparison to also capture tibbles\n      else if (sum(class(item_1) == \"data.frame\") &gt; 0) {\n        \n        # convert to dataframes so element-wise comparisons work as desired\n        tmp_item_1 = data.frame(item_1)\n        tmp_item_2 = data.frame(item_2)\n        \n        decimals = ceiling(abs(log10(tolerance)))\n        \n        tmp = sapply(1:ncol(tmp_item_1), function(i) {\n          \n          if(identical(class(tmp_item_1[, i]), \"numeric\")) {\n            \n            # compare numerics after rounding\n            round(as.numeric(tmp_item_1[, i]), decimals) == round(as.numeric(tmp_item_2[, i]), decimals)\n            \n          } else {\n            \n            # compare factors or characters\n            as.character(tmp_item_1[, i]) == as.character(tmp_item_2[, i])\n            \n          }\n          \n        })\n        \n        # give result names of first item\n        colnames(tmp) = colnames(item_1)\n        tmp\n        \n      }\n      \n      # if other data type, do not do element-wise comparison\n      else {\n        \n        NULL\n        \n      })\n  }\n  \n  # add the original items being compared to the results for display\n  results[[2]] = item_1\n  results[[3]] = item_2\n  \n  # return results with conditional elements\n  # return comparison and original items\n  if (return_items) {\n    \n    return(results)\n    \n  }\n  \n  # just return the comparison by dropping original items\n  else {\n    \n    return(results[-c(2:3)])\n    \n  }\n  \n}\n\n# read and format data\ndata_life_raw &lt;- read_csv(\"policy-life-analysis.csv\",\n                      col_types = c(\"cccccccccccc\")) %&gt;% \n  janitor::clean_names()\n\n# preview data\ndata_life_raw %&gt;% head\n\n### ---- Clean data and calculate variables ----\n\n# **NOTE: Currently backdated to match ending of reference triangles data**\n\n# clean data and calculate variables\n# -&gt; convert to dates\n# -&gt; calculate new variables\n# --&gt; determine active or inactive\n# --&gt; calculate time interval between now (or end / cancel date) and when policy started\n# --&gt; calculate time difference in different units\n# --&gt; make policy period\n#date_ref &lt;- ymd(\"2024-05-31\")\ndate_ref &lt;- Sys.Date()\ndata_life &lt;- data_life_raw %&gt;% \n  mutate(across(ends_with(\"date\"), mdy),\n         active_policy = case_when(\n           original_effective_date &gt; date_ref ~ \"Future\",\n           term_expiration_date &gt;= date_ref & (is.na(cancellation_date) | cancellation_date &gt;= date_ref) ~ \"Yes\",\n           .default = \"No\"\n         )\n  ) %&gt;% \n  rowwise %&gt;% # need rowwise() so can use min() looking across and not down\n  mutate(time_interval = case_when(\n    active_policy == \"Future\" ~ NA,\n    active_policy == \"Yes\" ~ interval(original_effective_date, date_ref),\n    .default = interval(original_effective_date, min(term_expiration_date, cancellation_date, na.rm = TRUE)))\n  ) %&gt;% \n  ungroup %&gt;% \n  mutate(life_of_policy_in_days = time_interval / days(1),\n         life_of_policy_in_months = time_interval / months(1),\n         life_of_policy_in_years = time_interval / years(1),\n         policy_period = paste0(year(original_effective_date), sprintf(\"%02d\", month(original_effective_date))))\n\n# preview data\ndata_life %&gt;% head\n\n### ---- Clean data and calculate variables ----\n\n# Matches as best as possible :) to the reference survival pivot table (counts, cancels and percentages)\n\n# See !!! comments below\n\n# define function to calculate indicator variables for if the policy survived past threshold\n# -&gt; !!! pivot results take into account nonrenewals by doing the following:\n# --&gt; records 363 day indicator and a 12 month indicator (which could be different values); this is done for every cutoff period\n# -&gt; to replicate this, I have to use &gt; in the indicators comparison, not &gt;= (so need to survive past 12 months to be included in the 12 month indicator)\n# -&gt; NOTE that still there are probably unaccounted things and/or slightly different policy counts throw percentages off a tiny bit\ncalc_indicators &lt;- function(df, col) {\n  \n  # setup holding dataframe for indicator variables\n  indicators = c(6, seq(from = 12, to = 60, by = 12)) \n  data_survival = matrix(data = NA, nrow = nrow(df), ncol = length(indicators)) %&gt;% \n    data.frame %&gt;% \n    bind_cols(df %&gt;% select(any_of(col)), .)\n  names(data_survival)[-1] = paste0(indicators, \"_months\")\n  \n  # loop over rows\n  for (i in 1:nrow(data_survival)) {\n    \n    # loop over columns\n    for (j in 2:(length(indicators)+1)) {\n      \n      # assign indicator based on survival months and the cutoff\n      data_survival[i, j] = ifelse(data_survival[i,1] &gt; (str_sub(string = colnames(data_survival[, j]),\n                                                                 start = 1,\n                                                                 end = -8) %&gt;% as.numeric),\n                                   1,\n                                   0)\n      \n    }\n  }\n    \n  df %&gt;% \n    select(-any_of(col)) %&gt;% \n    bind_cols(data_survival) %&gt;% \n    return\n  \n}\n\n# calculate survival triangle\n# -&gt; zeros are included in the survival percentages in the reference table\n# !!! the purpose of this is to confirm that I am calculating survival days / months correctly\n# -&gt; only had the % indicators to match up to, so had to work with this\n# -&gt; now am confident everything is being calculated correctly\n# -&gt; loss % indicators are just off because of the problem described in the calc_indicators function\ndata_triangle &lt;- data_life %&gt;% \n  calc_indicators(col = \"life_of_policy_in_months\") %&gt;% \n  {. -&gt;&gt; data_check} %&gt;% \n  # stage where can then calculate counts to compare to reference data, have to comment out filtering to non-zeros\n  summarize(.by = policy_period,\n            across(matches(\"^\\\\d.*\"), ~ mean(.x))) %&gt;% \n  arrange(policy_period)\n\ndata_triangle %&gt;% head\n\n# !!! if wanted to, could increase this analysis by taking into account renewals and separating out by business class\n\n# DATA QUALITY CHECKS\n\n# organized smaller dataset to check calculations from above\nx = data_check %&gt;% \n  distinct(life_of_policy_in_months, .keep_all = TRUE) %&gt;% \n  select(ends_with(\"date\"), time_interval, starts_with(\"life\"), ends_with(\"months\"))\n\n# compare counts and flat cancel rates to reference survival triangles\n# -&gt; also compare triangle percentages\ndata_compare &lt;- data_life %&gt;% \n  filter(!is.na(life_of_policy_in_days)) %&gt;% \n  mutate(zero_life = ifelse(life_of_policy_in_days == 0, \"Yes\", \"No\")) %&gt;% \n  group_by(policy_period, zero_life) %&gt;% \n  summarize(n = n()) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = zero_life,\n              values_from = n,\n              names_prefix = \"zero_life_\") %&gt;% \n  mutate(total = zero_life_No + zero_life_Yes,\n         zero_prop = zero_life_Yes / total) %&gt;% \n  select(-c(zero_life_No, zero_life_Yes)) %&gt;% \n  left_join(data_triangle)\n\n# confirm results from reference pivot\n# -&gt; copy and paste into comparison-check.xlsx\n# -&gt; work in this document now\nwrite_csv(data_compare, \"comparison.csv\")\n\n# PASSED CHECK!\n\n### ---- Average policy life analysis ----\n\n# DATA QUALITY NOTE: Had to change  `,` to `-` for restaurants in the raw data to have them grouped together\n\n# calculate average policy life excluding those with life less than or equal to 60 days (i.e. underwriting cancel and/or flat cancels (zero life))\navg_policy_life &lt;- data_life %&gt;% \n  filter(life_of_policy_in_days &gt; 60) %&gt;% \n  summarize(mean(life_of_policy_in_years)) %&gt;% \n  as.numeric\n\n# create comparative boxplots (with means), ordered by number of policies\n# -&gt; add overall average line with annotation\n# -&gt; add policy count annotations\ndata_life %&gt;% \n  filter(life_of_policy_in_days &gt; 60) %&gt;% \n  mutate(.by = hierarchy_1,\n         n = n()) %&gt;%\n  mutate(hierarchy_1 = fct_reorder(.f = hierarchy_1, .x = n)) %&gt;% \n  ggplot() + \n  geom_boxplot(aes(x = life_of_policy_in_years,\n                   y = hierarchy_1)) + \n  stat_summary(aes(x = life_of_policy_in_years,\n                   y = hierarchy_1),\n               fun = \"mean\",\n               geom = \"point\",\n               shape = 4,\n               col = \"blue\") + \n  geom_vline(xintercept = avg_policy_life,\n             col = \"blue\") + \n  annotate(geom = \"text\",\n           x = avg_policy_life + 4,\n           y = \"Retail\",\n           label = paste0(\"overall avg = \", round(avg_policy_life, 2), \" years\"),\n           color = \"blue\") + \n  geom_text(aes(x = Inf,\n                y = hierarchy_1,\n                label = paste0(n, \" policies\")),\n            data = data_life %&gt;% filter(life_of_policy_in_days &gt; 60) %&gt;% count(hierarchy_1),\n            hjust = 2,\n            size = 2.5,\n            col = \"darkorange1\") + \n    geom_text(aes(x = Inf,\n                y = hierarchy_1,\n                label = paste0(n, \" active\")),\n            data = data_life %&gt;% filter(life_of_policy_in_days &gt; 60) %&gt;% count(hierarchy_1, active_policy) %&gt;% filter(active_policy == \"Yes\"),\n            hjust = 1,\n            size = 2.5,\n            col = \"darkgreen\") + \n  labs(title = \"Policy life analysis\",\n       caption = \"Specs: includes expired and active policies; excludes policies with life &lt;= 60 days\",\n       x = \"Life of policy in years\",\n       y = \"Hierarchy 1\") + \n  coord_cartesian(xlim = c(0, max(data_life$life_of_policy_in_years, na.rm = TRUE) + 3.5)) +\n  theme_bw()\n\n# create table summarizing average life of policy by business class (via proxy of hierarchy 1)\ndata_life %&gt;% \n  filter(life_of_policy_in_days &gt; 60) %&gt;% \n  {. -&gt;&gt; data_life_non_uw_cancel} %&gt;% \n  summarize(.by = hierarchy_1,\n            mean = mean(life_of_policy_in_years),\n            sd = sd(life_of_policy_in_years),\n            n = n()) %&gt;% \n  bind_rows(\n    data_life_non_uw_cancel %&gt;% \n      summarize(mean = mean(life_of_policy_in_years),\n                sd = sd(life_of_policy_in_years),\n                n = n()) %&gt;% \n      bind_cols(data.frame(hierarchy_1 = \"Overall\"), .)\n    ) %&gt;% \n  arrange(desc(n)) %&gt;% \n  gt %&gt;% \n  tab_header(title = md(\"**Policy life analysis**\"),\n             subtitle = \"(in years)\") %&gt;% \n  tab_footnote(\"Specs: includes expired and active policies; excludes policies with life &lt;= 60 days\") %&gt;% \n  cols_label(hierarchy_1 = md(\"**Hierarchy 1**\"),\n             mean = md(\"**Mean**\"),\n             sd = md(\"**Sd**\"),\n             n = md(\"**n**\")) %&gt;% \n  gtExtras::gt_highlight_rows(rows = mean &lt; avg_policy_life,\n                              fill = \"red\",\n                              font_weight = \"normal\",\n                              alpha = 0.05) %&gt;% \n  gtExtras::gt_highlight_rows(rows = mean &gt; avg_policy_life,\n                              fill = \"green\",\n                              font_weight = \"normal\",\n                              alpha = 0.05) %&gt;% \n  fmt_number(columns = c(mean, sd),\n             decimals = 2) %&gt;% \n  fmt_number(columns = n,\n             decimals = 0)\n\n### ---- Underwriting (or other) cancel analysis ----\n\n# create table summarizing policies underwriting (or other) by business class (via proxy of hierarchy 1)\ndata_life %&gt;% \n  filter(!is.na(life_of_policy_in_days)) %&gt;% \n  mutate(uw_cancel = ifelse(life_of_policy_in_days &lt;= 60, \"Yes\", \"No\")) %&gt;% \n  group_by(hierarchy_1, uw_cancel) %&gt;% \n  summarize(n = n()) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = uw_cancel,\n              values_from = n,\n              names_prefix = \"uw_cancel_\") %&gt;% \n  mutate(total = uw_cancel_No + uw_cancel_Yes,\n         uw_cancel_prop = uw_cancel_Yes / total) %&gt;% \n  select(-uw_cancel_No) %&gt;% \n  arrange(desc(uw_cancel_prop)) %&gt;% \n  {. -&gt;&gt; uw_cancel_wide} %&gt;% \n  bind_rows(uw_cancel_wide %&gt;% \n              summarize(hierarchy_1 = \"Overall\",\n                        uw_cancel_Yes = sum(uw_cancel_Yes),\n                        total = sum(total),\n                        uw_cancel_prop = sum(uw_cancel_Yes) / sum(total))\n  ) %&gt;% \n  gt %&gt;% \n  tab_header(title = md(\"**Underwriting (or other) cancel analysis**\")) %&gt;%\n  cols_label(hierarchy_1 = md(\"**Hierarchy 1**\"),\n             uw_cancel_Yes = md(\"**Cancelled policies**\"),\n             total = md(\"**Total policies**\"),\n             uw_cancel_prop = md(\"**Proportion**\")) %&gt;% \n  tab_style(style = cell_text(weight = \"bold\"),\n            locations = cells_body(columns = everything(),\n                                   rows = hierarchy_1 == \"Overall\")) %&gt;% \n  fmt_auto()\n\n\n2.1.8 Random loss analyis\n\n### ---- Load packages and define functions ----\n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(gt)\n\n`%!in%` &lt;- Negate(\"%in%\")\n\n### ---- Read in data ----\n\n# policy and loss data\ndata_premium_raw &lt;- read_csv(\"random-loss-analysis.csv\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(across(contains(\"year\"), as.numeric)) %&gt;% \n  rename(incurred_loss_and_lae = incurred_loss_lae) %&gt;% \n  mutate(roof_type = str_to_title(roof_type))\n\n# claim data\ndata_claims_raw &lt;- readxl::read_xlsx(\"claims commercial detail.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(incurred_loss_and_lae = incurred_loss + incurred_lae)\n\n### ---- Roof type analysis ----\n\n### Clean premium data\n\n# data cleaning\n# NOTE: could have also read in roof_types.xlsx (a more organized version of it) and did a left join to get the corrected roof types\ndata_premium &lt;- data_premium_raw %&gt;% \n  mutate(roof_type = \n           case_when(\n             roof_type %in% c(\"1\", \"Unknown\", \"Flat\", \"Gable\") ~ \"Other\",\n             roof_type %in% c(\"Comp\", \"Comp Toll\", \"Composition\",  \"Comp Roll\") ~ \"Asphalt Comp Roll\",\n             roof_type %in% c(\"As\", \"Shingle\", \"Asphault Shingle\") ~ \"Asphalt Shingle\",\n             roof_type %in% c(\"Tar, Tar And Gravel\", \"T & G\", \"T&G\", \"Tar & Gravel\") ~ \"Tar and Gravel\",\n             roof_type == \"Membrane\" ~ \"Plastic Membrane\",\n             roof_type %in% c(\"Plastic Membrane\", \"Thermo Plastic\") ~ \"Thermo-Plastic Membrane\",\n             roof_type == \"Rubber Membrane\" ~ \"Rubber\",\n             roof_type == \"Tile\" ~ \"Tile, Slate, Stone\",\n             .default = roof_type\n           )\n  ) %&gt;% \n  filter(!is.na(roof_type))\n\n# export slightly modified data (save as premium data in workbook)\nopenxlsx2::write_xlsx(data_premium, \"output/data-premium.xlsx\")\n\n### ---- Modify claims data ----\n\n# find duplicate policy number - roof type combos\nx &lt;- data_premium %&gt;% count(policy_number, roof_type) %&gt;% count(policy_number) %&gt;% filter(n &gt; 1)\n\n# add roof type to claim data\ndata_claims &lt;- data_claims_raw %&gt;% \n  left_join(data_premium %&gt;% distinct(policy_number, roof_type) %&gt;% filter(policy_number %!in% x$policy_number),\n            by = join_by(policy == policy_number))\n\n# export slightly modified data (save as claim data in workbook)\nopenxlsx2::write_xlsx(data_claims, \"output/data-claims.xlsx\")\n\n### ---- Summarize ----\n\n# summarize premium data by roof type\ndata_pivot_premium &lt;- data_premium %&gt;% \n  filter(policy_number != \"XXXXXXXXX\") %&gt;% \n  summarize(.by = roof_type,\n            across(c(earned_premium), sum),\n            policy_count = n()) %&gt;% \n    relocate(policy_count, .after = 1)\n\n# summarize claim data by roof type\ndata_pivot_claims &lt;- data_claims %&gt;% \n  filter(coverage %in% c(\"BDA\", \"BPA\", \"BDH\", \"BPH\", \"BDW\", \"BPW\")) %&gt;% \n  summarize(.by = roof_type,\n            claim_count = n_distinct(claim),\n            across(incurred_loss_and_lae, sum),\n            ) %&gt;% \n  filter(!is.na(roof_type))\n\n# combine tables\ndata_pivot &lt;- data_pivot_premium %&gt;% \n  left_join(data_pivot_claims, by = join_by(roof_type)) %&gt;% \n  mutate(loss_ratio = incurred_loss_and_lae / earned_premium)\n\n# export slightly modified data (save as claim data in workbook)\nopenxlsx2::write_xlsx(data_pivot, \"output/data-pivot.xlsx\")\n\n### ---- Fancy output ----\n\n# summarize data by roof type\n# -&gt; note that the policy counts are slightly off between here and tableau because tableau isn't counting duplicate policy numbers (although the loss data is correct)\n# NOTE: recreating this with pivot -&gt; everything matches!\ndata_premium %&gt;% \n  #filter(policy_number != \"XXXXXXXXX\") %&gt;% \n  summarize(.by = roof_type,\n            across(c(earned_premium, claim_count, incurred_loss_and_lae), sum),\n            n = n()) %&gt;% \n  relocate(n, .after = 1) %&gt;% \n  mutate(loss_ratio = incurred_loss_and_lae / earned_premium) %&gt;% \n  arrange(desc(loss_ratio)) %&gt;% \n  gt %&gt;% \n  tab_header(title = \"Inception-to-date roof type LRs\") %&gt;% \n             #subtitle = \"excluding Medford, OR loss\") %&gt;% \n  cols_label(roof_type = md(\"**Roof type**\"),\n             n = md(\"**Policy count**\"),\n             earned_premium = md(\"**EP**\"),\n             claim_count = md(\"**Claim count**\"),\n             incurred_loss_and_lae = md(\"**Incurred loss + LAE**\"),\n             loss_ratio = md(\"**LR**\")) %&gt;% \n  fmt_number(columns = c(n, earned_premium, incurred_loss_and_lae),\n             decimals = 0) %&gt;% \n  fmt_percent(columns = loss_ratio,\n             decimals = 1)\n\n### ---- Unknowns ---- \n\n# policy life data\n# -&gt; some odd duplicate policy numbers, just removing them\ndata_policy_life_raw &lt;- readxl::read_xlsx(path = \"policy-life-analysis.xlsx\") %&gt;%\n  janitor::clean_names() %&gt;% \n  distinct(policy_number, .keep_all = TRUE)\n\n# look into unknown roof types\ndata_unknown &lt;- data_premium_raw %&gt;% \n  filter(is.na(roof_type) | roof_type == \"Unknown\") %&gt;% \n  mutate(policy_prefix = str_sub(policy_number, 1, 3)) %&gt;% \n  left_join(data_policy_life_raw %&gt;% select(policy_number, contains(\"date\")), by = join_by(policy_number))\n\n# quick output to email screenshot\ndata_unknown %&gt;% count(roof_type, policy_prefix) %&gt;% rename(count = n) %&gt;% write.csv(file = \"data-unknown-summarized.csv\")\n\n# output policy numbers to send to David\ndata_unknown %&gt;% select(policy_number) %&gt;% write.csv(file = \"output/unknown-roof-policy-numbers.csv\")\n\n\n2.1.9 Restuarant audits analysis\n\n### ---- Load packages and define functions ---- \n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\n\n# define functions\n`%!in%` &lt;- Negate(\"%in%\")\n\n### ---- Read in and clean data ----\n\n# read in restaurant audit data\n# -&gt; recalculate calculated fields from spreadsheet\ndata_audits_raw &lt;- readxl::read_excel(\"Audit Review Spreadsheet with DTB Analysis 2025 05 16.xlsx\", sheet = 1, skip = 2) %&gt;% \n  janitor::clean_names() %&gt;% \n  rename(date_audit = date) %&gt;% \n  filter(notes_short %!in% c(\"Cancelled Pre Audit\", \"NR due to LQL sales\", \"NR pre audit\", \"NR Sales &gt; 6M\")) %&gt;% \n  mutate(pct_chg_in_sales = round(audited_sales / current_sales - 1, 4),\n         increase_or_decrease = case_when(\n           pct_chg_in_sales &lt; 0 ~ \"Dec\",\n           pct_chg_in_sales == 0 ~ \"No change\",\n           pct_chg_in_sales &gt; 0 ~ \"Inc\",\n           .default = NA),\n         audited_alcohol_percent = round(audited_alcohol_sales / audited_sales, 4),\n         pct_chg_in_premium = round(revised_premium / current_premium - 1, 4))\n\n# read in inforce file\ndata_inforce &lt;- readxl::read_xlsx(path = \"InForce_20250602.xlsx\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(date = ymd(\"2025-06-02\"), .before = 1)\n\n### ---- Calculate new variables ----\n\n# check ranges of variables\ndata_audits %&gt;% \n  select(starts_with(\"pct_chg_in\")) %&gt;% \n  map(\\(col) summary(col))\n\n# add retention information to audit data and create bins for variables of interest\ndata_audits &lt;- data_audits_raw %&gt;% \n  left_join(data_inforce %&gt;% select(policy_number, policy_effective_date), by = join_by(policy_number)) %&gt;% \n  relocate(policy_effective_date, .after = exp_date) %&gt;% \n  mutate(renewed = case_when(\n      policy_effective_date &gt;= exp_date ~ \"Yes\",\n      policy_effective_date &lt; exp_date ~ \"TBD\",\n      .default = \"No\"\n    ),\n    pct_chg_in_sales_group = case_when(\n      is.na(audited_sales) ~ NA,\n      pct_chg_in_sales &lt; -0.8 ~ \"&lt;-80%\",\n      pct_chg_in_sales &lt; -0.6 ~ \"[-80%,-60%)\",\n      pct_chg_in_sales &lt; -0.4 ~ \"[-60%,-40%)\",\n      pct_chg_in_sales &lt; -0.2 ~ \"[-40%,-20%)\",\n      pct_chg_in_sales &lt; 0 ~ \"[-20%,0%)\",\n      pct_chg_in_sales == 0 ~ \"0%\",\n      pct_chg_in_sales &lt; 0.2 ~ \"(0%,20%)\",\n      pct_chg_in_sales == 0.2 ~ \"20%\",\n      pct_chg_in_sales &lt; 0.4 ~ \"(20%,40%)\",\n      pct_chg_in_sales &lt; 0.6 ~ \"[40%,60%)\",\n      pct_chg_in_sales &lt; 0.8 ~ \"[60%,80%)\",\n      pct_chg_in_sales &lt; 1.0 ~ \"[80%,100%)\",\n      pct_chg_in_sales &lt; 2.0 ~ \"[100%,200%)\",\n      pct_chg_in_sales &gt;= 2.0 ~ \"&gt;=200%\"\n    ) %&gt;% ordered(levels = c(\"&lt;-80%\",\"[-80%,-60%)\",\"[-60%,-40%)\",\"[-40%,-20%)\",\"[-20%,0%)\",\"0%\",\"(0%,20%)\",\"20%\",\"(20%,40%)\",\"[40%,60%)\",\"[60%,80%)\",\"[80%,100%)\",\"[100%,200%)\",\"&gt;=200%\")),\n    pct_chg_in_premium_group = case_when(\n      is.na(revised_premium) ~ NA,\n      pct_chg_in_premium &lt; -0.8 ~ \"&lt;-80%\",\n      pct_chg_in_premium &lt; -0.6 ~ \"[-80%,-60%)\",\n      pct_chg_in_premium &lt; -0.4 ~ \"[-60%,-40%)\",\n      pct_chg_in_premium &lt; -0.2 ~ \"[-40%,-20%)\",\n      pct_chg_in_premium &lt; 0 ~ \"[-20%,0%)\",\n      pct_chg_in_premium == 0 ~ \"0%\",\n      pct_chg_in_premium &lt; 0.2 ~ \"(0%,20%)\",\n      pct_chg_in_premium &lt; 0.4 ~ \"[20%,40%)\",\n      pct_chg_in_premium &lt; 0.6 ~ \"[40%,60%)\",\n      pct_chg_in_premium &lt; 0.8 ~ \"[60%,80%)\",\n      pct_chg_in_premium &lt; 1.0 ~ \"[80%,100%)\",\n      pct_chg_in_premium &lt; 2.0 ~ \"[100%,200%)\",\n      pct_chg_in_premium &gt;= 2.0 ~ \"&gt;=200%\",\n      .default = NA\n    ) %&gt;% ordered(levels = c(\"&lt;-80%\",\"[-80%,-60%)\",\"[-60%,-40%)\",\"[-40%,-20%)\",\"[-20%,0%)\",\"0%\",\"(0%,20%)\",\"[20%,40%)\",\"[40%,60%)\",\"[60%,80%)\",\"[80%,100%)\",\"[100%,200%)\",\"&gt;=200%\"))\n  ) %&gt;% \n  relocate(renewed, .after = policy_number) %&gt;% \n  relocate(pct_chg_in_sales_group, .after = pct_chg_in_sales) %&gt;% \n  relocate(pct_chg_in_premium_group, .after = pct_chg_in_premium) \n\n### ---- Analyze ----\n\n# create exhibit tables\ndata_audits %&gt;% \n  count(pct_chg_in_sales_group, renewed) %&gt;% \n  pivot_wider(names_from = renewed, values_from = n, values_fill = 0) %&gt;% \n  rowwise %&gt;% \n  mutate(No_percent = No / (No + Yes + TBD),\n         Yes_percent = Yes / (No + Yes + TBD),\n         TBD_percent = TBD / (No + Yes + TBD)) %&gt;% \n  select(pct_chg_in_sales_group, starts_with(\"No\"), starts_with(\"Yes\"), starts_with(\"TBD\"))\n\ndata_audits %&gt;% \n  count(pct_chg_in_premium_group, renewed) %&gt;% \n  pivot_wider(names_from = renewed, values_from = n, values_fill = 0) %&gt;% \n  rowwise %&gt;% \n  mutate(No_percent = No / (No + Yes + TBD),\n         Yes_percent = Yes / (No + Yes + TBD),\n         TBD_percent = TBD / (No + Yes + TBD)) %&gt;% \n  select(pct_chg_in_premium_group, starts_with(\"No\"), starts_with(\"Yes\"), starts_with(\"TBD\"))\n\n\n2.1.10 Indications\n\n### ---- Load packages and define functions ----\n\n# load packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(gt)\n\n`%!in%` &lt;- Negate(\"%in%\")\n\n# function to format long data as triangle\n# -&gt; assuming age to ultimate is 63 quarters\n# -&gt; n_periods = 28 --&gt; 7 years of data for triangle\nformat_bases_as_triangle &lt;- function(df_agg_age, var, ult_age = 63, n_periods = 28) {\n  \n  var = enquo(var)\n \n  df_agg_age %&lt;&gt;%  \n    filter(age &lt;= ult_age) %&gt;% \n    select(1:3, !!var) %&gt;% \n    pivot_wider(names_from = age,\n                values_from = !!var) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr)) %&gt;% \n    select(accident_quarter, as.character(seq(from = 3, to = ult_age, by = 3))) %&gt;% \n    slice_tail(n = n_periods) %&gt;% \n    return\n  \n}\n\n# function to calculate development factors\ncalculate_dev_factors &lt;- function(df_agg_age, var) {\n  \n  var = enquo(var)\n  \n  # reduce input data to only needed columns\n  df_agg_age %&lt;&gt;% select(1:3, !!var)\n  \n  # setup output dataframe\n  df_dev = matrix(data = NA,\n                  ncol = ncol(df_agg_age) + 1,                  \n                  nrow = nrow(df_agg_age - 1)) %&gt;% # taking ratios, so one row less\n    data.frame\n  colnames(df_dev) = c(\"loss_year\",\"loss_qtr\", \"left\", \"right\", \"dev_factor\")\n  \n  # calculate development factors\n  for (i in 1:nrow(df_agg_age)-1) {\n    \n    # set constants\n    df_dev[i,1:2] = df_agg_age[i,1:2]\n    \n    # set ratio column indicators\n    df_dev[i,3] = df_agg_age[i+1,3]\n    df_dev[i,4] = df_agg_age[i,3]\n    \n    # calculate factor\n    df_dev[i,5] = ifelse(df_agg_age[i,4] == 0,\n                         NA,\n                         as.numeric(df_agg_age[i+1,4]) / as.numeric(df_agg_age[i,4]))\n    \n  }\n  \n  # remove unwanted comparisons and format ratio indicator\n  df_dev %&lt;&gt;% \n    filter(left &gt; right) %&gt;% \n    mutate(age_age = paste0(left, \":\", right),\n           .after = 2)\n  \n  df_dev %&gt;% return\n  \n}\n\n# function to format loss development factors as triangle\n# -&gt; assuming age to ultimate is 63 quarters\n# -&gt; n_periods = 27 --&gt; 7 years of data for triangle\nformat_dev_factors_as_triangle &lt;- function(df_dev, ult_age = 63, n_periods = 27) {\n  \n  df_dev %&gt;% \n    filter(left &lt;= ult_age) %&gt;% \n    select(-c(left, right)) %&gt;% \n    pivot_wider(names_from = age_age,\n                values_from = dev_factor) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr),\n           \"Ult:{{ult_age}}\" := NA) %&gt;% \n    select(accident_quarter, as.character(paste0(seq(from = 6, to = ult_age, by = 3),\":\", seq(from = 3, to = ult_age-3, by = 3))), paste0(\"Ult:\", ult_age)) %&gt;% \n    slice_tail(n = n_periods) %&gt;% \n    return\n  \n}\n\n# function to calculate weighted development factors\ncalculate_weighted_dev_factors &lt;- function(df_loss_tri, selects, ult_age = 63) {\n  \n  # setup output dataframe\n  df_weights = matrix(data = NA,\n                      ncol = ncol(df_loss_tri),                  \n                      nrow = 3) %&gt;%\n    data.frame\n  colnames(df_weights) = c(\"id\", paste0(seq(from = 6, to = ult_age, by = 3),\":\", seq(from = 3, to = ult_age-3, by = 3)), paste0(\"Ult:\", ult_age))\n\n  # set constants\n  df_weights$id = paste0(seq(from = 8, to = 16, by = 4), \" pts wtd\")\n\n  # calculated weighted development factors\n  for (i in 1:nrow(df_weights)) {\n    \n    # set number of periods to look back (i.e. weight)\n    weight = df_weights[i,1] %&gt;% str_sub(., 1, str_locate(., \" pts\")[1]-1) %&gt;% as.numeric\n    \n    for (j in 2:(ncol(df_weights)-1)) {\n      \n      # figure out number of periods with data in triangle for the larger age\n      data_count = nrow(df_loss_tri) - sum(is.na(df_loss_tri[,j+1]))\n      \n      # calculate X-pts weighted ratio\n      df_weights[i,j] = df_loss_tri %&gt;% \n        mutate(row_num = row_number()) %&gt;% \n        filter(between(row_num, data_count - weight + 1, data_count)) %&gt;% \n        select(all_of(c(1, j, j+1))) %&gt;% \n        rename(col_j = 2, col_j_minus_1 = 3) %&gt;% \n        summarize(sum(col_j_minus_1) / sum(col_j))\n      \n    }\n    \n  }\n  \n  # create dataframe of selects for each age:age\n  # -&gt; need to organize so can correctly calculate in next step\n  df_selects = data.frame(age_age = colnames(df_weights)[-1], selected = selects) %&gt;% \n    mutate(row_num = row_number()) %&gt;% \n    arrange(desc(row_num))\n  \n  # calculate cumulative selects \"backwards\"\n  selects_cumulative = df_selects$selected %&gt;% cumprod\n  \n  # append calculated factors and reorganize\n  df_selects %&lt;&gt;% \n    bind_cols(selects = data.frame(cumulative = selects_cumulative)) %&gt;% \n    arrange(row_num) %&gt;% \n    select(-row_num) %&gt;% \n    select(2:3) %&gt;% \n    t %&gt;% \n    data.frame %&gt;% \n    rownames_to_column()\n  colnames(df_selects) = colnames(df_weights)\n  \n  # combine dataframes\n  df_weights %&lt;&gt;% \n    bind_rows(df_selects)\n  \n  df_weights %&gt;% return\n  \n}\n\n# function to calculate ultimate incurred\ncalculate_ultimate_incurred &lt;- function(df_agg, df_selects, var) {\n  \n  # extract cumulative select factors\n  cumlative_selects = df_selects %&gt;% \n    filter(id == \"cumulative\") %&gt;% \n    select(-id) %&gt;% \n    pivot_longer(cols = everything(),\n                 names_to = \"age_age\",\n                 values_to = \"cumulative_factor\")\n  \n  # reorganize summary table for appending cumulative selects\n  df_agg %&lt;&gt;% \n    arrange(state, desc(loss_year), desc(loss_qtr)) %&gt;% \n    select(state, loss_year, loss_qtr, any_of(var))\n  \n  # append cumulative selects, organize data, and calculate new column\n  # -&gt; fill rest of values with NA\n  df_agg %&gt;% \n    nest_by(state) %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data) {\n        \n        data$factor &lt;- c(cumlative_selects$cumulative_factor, rep(NA, nrow(data) - nrow(cumlative_selects)))\n        \n        data %&gt;% return\n        \n      })\n    ) %&gt;% \n    reframe(data) %&gt;%  \n    arrange(state, loss_year, loss_qtr) %&gt;% \n    filter(!is.na(factor)) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr),\n           ult_incurred = !!sym(var) * factor) %&gt;% \n    select(state, accident_quarter, incurred = any_of(var), factor, ult_incurred) %&gt;% \n    return\n  \n}\n\n# summarize data by fiscal year\nsummarize_by_fiscal_year &lt;- function(df) {\n  \n  df %&lt;&gt;% \n    rename(var1 = 3, factor = 4, var2 = 5) %&gt;% # standardize names\n    nest_by(state) %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data) {\n\n        # drop most recent period, calculate rolling sum by fiscal year, calculate factor, and organize\n        data %&lt;&gt;% \n          slice_head(n = nrow(.)-1) %&gt;% \n          mutate(var1_cumulative = roll::roll_sum(var1, width = 4),\n                 var2_cumulative = roll::roll_sum(var2, width = 4),\n                 factor = ifelse(var1_cumulative == 0, NA, var2_cumulative / var1_cumulative),\n                 quarter = str_sub(accident_quarter, -1, -1))\n          \n        # get most recent quarter to work from\n        ref_qtr = data %&gt;% \n          slice_tail(n = 1) %&gt;% \n          pull(quarter) %&gt;% \n          as.numeric\n        \n        # keep only relevant periods\n        data %&gt;% \n          filter(quarter == ref_qtr) %&gt;% \n          select(fiscal_year_ended = accident_quarter, var1_cumulative, factor, var2_cumulative) %&gt;% \n          return\n      \n      })\n    )\n  \n  # set NAs to Countrywide values\n  df_cw = df %&gt;% \n    filter(state == \"Countrywide\") %&gt;% \n    reframe(data) %&gt;% \n    select(fiscal_year_ended, factor)\n  \n  # use Countrywide values if NA for state factors and organize data\n  df %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data, df_cw) {\n\n        data %&gt;% \n          left_join(df_cw,\n                    by = join_by(fiscal_year_ended),\n                    suffix = c(\"_st\", \"_cw\")) %&gt;% \n          mutate(factor = ifelse(is.na(factor_st), factor_cw, factor_st)) %&gt;% \n          select(fiscal_year_ended, var1_cumulative, factor, var2_cumulative)\n        \n      },\n      df_cw)\n    ) %&gt;% \n    reframe(data) %&gt;% \n    return\n  \n}\n\n# function to calculate the final step of the trending (x is a vector of two fits)\ncalculate_final_fit &lt;- function(x) {\n  \n  x[2] / x[1] - 1\n  \n}\n\n# function calculated weighted fits\ncalculate_weighted_fits &lt;- function(df_calendar, var) {\n  \n  # initialize needed items\n  pts = seq(from = 8, to = 24, by = 4)\n  fits = rep(NA, length(pts))\n  j = 1\n  \n  # loop through different weights (fits)\n  for (x in pts) {\n    \n    # reassign full dataset\n    df_temp = df_calendar\n    \n    # limit dataset and calculate fit\n    df_temp %&lt;&gt;% \n      slice_tail(n = 24) %&gt;% # skip periods where cumulative sum isn't full\n      mutate(i = row_number()) %&gt;% # set Xs\n      slice_tail(n = x)\n    \n    if (sum(is.na(df_temp %&gt;% pull(any_of(var)))) == nrow(df_temp)) { # if no data, stop don't calculate anything\n      \n      fits[j] = NA\n      \n    } else {\n      \n      fits[j] = df_temp %&gt;% \n        lm(paste0(var, \" ~ i\") %&gt;% as.formula, data = .) %&gt;% \n        predict(newdata = data.frame(i = c(20,24))) %&gt;% \n        calculate_final_fit\n      \n    }\n\n    j = j + 1\n    \n  }\n  \n  # reorganize\n  fits %&lt;&gt;% \n    data.frame %&gt;% \n    t %&gt;% \n    data.frame\n  colnames(fits) = paste0(seq(from = 8, to = 24, by = 4), \" pt\")\n  fits %&gt;% \n    mutate(across(everything(), \\(x) ifelse(is.nan(x), NA, x))) %&gt;% \n    return\n  \n}\n\n# function to output indication summary table\nformat_as_indication_summary &lt;- function(data_ind, sel_state, sel_data_ended, sel_eval_date) {\n  \n  data_ind %&gt;% \n    filter(state == sel_state) %&gt;% \n    select(fiscal_year_ended,current_level_earned_premium, premium_trend_factors, trended_current_level_earned_premium, incurred_loss, implied_incurred_age_to_ult, ult_incurred_loss, loss_trend_factors, trended_ult_incurred_loss, trended_ult_incurred_partial_loss_ratio, ay_weights) %&gt;% \n    gt %&gt;% \n    opt_stylize(style = 3) %&gt;%  \n    tab_header(title = md(paste0(\"**\", sel_state, \" indications**\")),\n               subtitle = md(paste0(\"**Calendar / accident year data ended \", month(sel_data_ended, label = TRUE, abbr = FALSE), \" \", day(sel_data_ended), \", \", year(sel_data_ended), \" as of \", month(sel_eval_date, label = TRUE, abbr = FALSE), \" \", day(sel_eval_date), \", \", year(sel_eval_date), \"**\"))) %&gt;% \n    cols_label(fiscal_year_ended = \"Year ended\",\n               current_level_earned_premium = \"Current level earned premium\",\n               premium_trend_factors = \"Premium trend factors\",\n               trended_current_level_earned_premium = \"Trended current level earned poremium\",\n               incurred_loss = \"Non-cat incurred loss + LAE\",\n               implied_incurred_age_to_ult = \"Loss development factors\",\n               ult_incurred_loss = \"Ultimate non-cat incurred loss + LAE\",\n               loss_trend_factors = \"Loss trend factors\",\n               trended_ult_incurred_loss = \"Trended ultimate non-cat incurred loss + lae\",\n               trended_ult_incurred_partial_loss_ratio = \"Trended ultimate non-cat incurred parial loss + LAE ratio\",\n               ay_weights = \"Accident year weights\"\n    ) %&gt;%\n    fmt_number(columns = c(current_level_earned_premium, trended_current_level_earned_premium, incurred_loss, ult_incurred_loss, trended_ult_incurred_loss),\n               decimals = 0) %&gt;% \n    fmt_number(columns = c(premium_trend_factors, implied_incurred_age_to_ult, loss_trend_factors),\n               decimals = 3) %&gt;% \n    fmt_percent(columns = c(trended_ult_incurred_partial_loss_ratio, ay_weights),\n                decimals = 1)\n  \n}\n\n# function to output indication calculations table\nformat_as_indication_calculations &lt;- function(data_ind3_long, sel_state) {\n  \n  data_ind3_long %&gt;% \n    filter(state == sel_state,\n           variable %!in% c(\"modeled_hurricane_ratio\", \"modeled_fire_following_earthquake_ratio\", \"modeled_severe_convective_storm_ratio\", \"modeled_wildfire_ratio\")) %&gt;% \n    filter(!is.na(value)) %&gt;% \n    select(variable_display, value) %&gt;% \n    gt %&gt;% \n    tab_options(column_labels.hidden = TRUE) %&gt;% \n    cols_align(columns = variable_display, align = \"right\") %&gt;% \n    cols_align(columns = value, align = \"right\") %&gt;% \n    fmt_percent(columns = value, decimals = 1) %&gt;% \n    tab_style(\n      style = list(\n        cell_text(weight = \"bold\")\n      ),\n      locations = cells_body(\n        columns = c(variable_display, value),\n        rows = variable_display == \"Indicated rate level needed:\"\n      )\n    ) %&gt;% \n    tab_style(\n      style = list(\n        cell_fill(color = \"yellow\")\n      ),\n      locations = cells_body(\n        columns = value,\n        rows = variable_display == \"Indicated rate level needed:\"\n      )\n    )\n  \n}\n\n# function to output supporting table of indication calculations\nformat_as_indication_calculations_support &lt;- function(data_ind3_long, sel_state) {\n  \n  data_ind3_long %&gt;% \n    filter(state == sel_state,\n           variable %in% c(\"modeled_hurricane_ratio\", \"modeled_fire_following_earthquake_ratio\", \"modeled_severe_convective_storm_ratio\", \"modeled_wildfire_ratio\")) %&gt;% \n    filter(!is.na(value)) %&gt;% \n    select(variable_display, value) %&gt;% \n    gt %&gt;% \n    tab_options(column_labels.hidden = TRUE) %&gt;% \n    cols_align(columns = variable_display, align = \"right\") %&gt;% \n    cols_align(columns = value, align = \"right\") %&gt;% \n    fmt_percent(columns = value, decimals = 1)\n  \n}\n\n### ---- Raw data ----\n\n# read in data from access process\n\n# -&gt; premium data\ndata_premium_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"PremiumData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  rename(qtr = quarter)\n\n# -&gt; loss data\ndata_loss_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"LossData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(across(ends_with(\"qtr\"), as.numeric))\n\n# -&gt; reported frequency data\ndata_rept_freq_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ReptFreqData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(across(ends_with(\"qtr\"), as.numeric))\n\n# -&gt; closed by closed evaluation data\ndata_clsd_by_clsd_eval_date_raw &lt;- readxl::read_xlsx(path =  \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ClsdByClsdEvalDt\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(eval_qtr = as.numeric(eval_qtr))\n\n# -&gt; closed by evaluation data\ndata_clsd_by_eval_date_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ClsdByEvalDt\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(eval_qtr = as.numeric(eval_qtr))\n\n# -&gt; RMS modeled loss\ndata_rms_modeled_loss &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"RMSModLoss\") %&gt;% \n  janitor::clean_names()\n\n# -&gt; TS modeled loss\ndata_ts_modeled_loss &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"TSModLoss\") %&gt;% \n  janitor::clean_names()\n\n# single out vectors\nvec_states &lt;- unique(data_premium_raw$state) # use premium data to capture all states\nvec_loss_years &lt;- unique(data_loss_raw$loss_year)\nvec_loss_qtrs &lt;- unique(data_loss_raw$loss_qtr)\nvec_eval_years &lt;- unique(data_loss_raw$eval_year)\nvec_eval_qtrs &lt;- unique(data_loss_raw$eval_qtr)\n\n# create dataset of all possible combos, then add the needed combos for the most recent year\n# -&gt; this is so that later in the process, data has rows of zero rather than no row if no losses were in that particular period\ndata_all_combos &lt;- expand.grid(vec_states, vec_loss_years, vec_loss_qtrs, vec_eval_years, vec_eval_qtrs) %&gt;% \n  data.frame\ncolnames(data_all_combos) &lt;- c(\"state\", \"loss_year\", \"loss_qtr\", \"eval_year\", \"eval_qtr\")\n\n# keep only valid periods\n# -&gt; set current eval quarter\ncur_eval_qtr &lt;- 3\ndata_all_combos %&lt;&gt;%\n  filter(loss_year &lt;= eval_year) %&gt;% \n  arrange(state, loss_year, loss_qtr, eval_year, eval_qtr) %&gt;% \n  mutate(keep = \n           case_when(\n             loss_year == eval_year & loss_qtr &gt; eval_qtr ~ 0, # illogical periods\n             loss_year == max(loss_year) & loss_qtr &gt; cur_eval_qtr ~ 0, # future periods\n             eval_year == max(eval_year) & eval_qtr &gt; cur_eval_qtr ~ 0, # future periods\n             .default = 1\n           )\n  ) %&gt;% \n  filter(keep != 0) %&gt;% \n  select(-keep)\n\n### Premium data\n\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_premium_agg &lt;- data_premium_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, year == loss_year, qtr == loss_qtr)) %&gt;% \n  arrange(state, year, qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n### Loss data\n\n# add placeholder rows to loss data\ndata_loss_raw2 &lt;- data_loss_raw %&gt;% \n  right_join(data_all_combos, by = join_by(state, loss_year, loss_qtr, eval_year, eval_qtr)) %&gt;% \n  arrange(state, loss_year, loss_qtr, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n# create age variable\ndata_loss &lt;- data_loss_raw2 %&gt;% \n  mutate(age = (eval_year - loss_year) * 12 + (eval_qtr - loss_qtr) * 3 + 3, # evaluating in same quarter as loss counts as 3 months of development\n         paid_loss_plus_lae = paid_loss + paid_lae + -subrogation_salvage,\n         incurred_loss = paid_loss_plus_lae + case_reserve + expense_reserve,\n         incurred_claim_count = cwp_count + open_count) \n  \n# create summarized loss data by state and overall (cw)\ndata_loss_agg_age_cw &lt;- data_loss %&gt;% \n  summarize(.by = c(state, loss_year, loss_qtr, age),\n            across(c(paid_loss_plus_lae, incurred_loss, incurred_claim_count), \\(x) sum(x,na.rm = TRUE))) %&gt;% \n  arrange(state, loss_year, loss_qtr, age) %&gt;% \n  {. -&gt;&gt; data_loss_agg_age_st} %&gt;% \n  summarize(.by = c(loss_year, loss_qtr, age),\n            across(c(paid_loss_plus_lae, incurred_loss, incurred_claim_count), \\(x) sum(x,na.rm = TRUE)))\n\n# assumption of number of months to ultimate loss\nult_age &lt;- 63\n\n### Reported frequency data\n\n# add placeholder rows to loss data\ndata_rept_freq_raw2 &lt;- data_rept_freq_raw %&gt;% \n  right_join(data_all_combos, by = join_by(state, rept_year == loss_year, rept_qtr == loss_qtr, eval_year, eval_qtr)) %&gt;% \n  arrange(state, rept_year, rept_qtr, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n### Closed by closed evaluation date\n\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_clsd_by_clsd_eval_date_agg &lt;- data_clsd_by_clsd_eval_date_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, eval_year == loss_year, eval_qtr == loss_qtr)) %&gt;% \n  arrange(state, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n### Closed by evaluation date\n\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_clsd_by_eval_date_agg &lt;- data_clsd_by_eval_date_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, eval_year == loss_year, eval_qtr == loss_qtr)) %&gt;% \n  arrange(state, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n### ---- Premium trend ----\n\n# create summarized premium data overall (cw) and then combine\ndata_premium_agg_cw &lt;- data_premium_agg %&gt;% \n  group_by(year, qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_premium_agg %&lt;&gt;% bind_rows(data_premium_agg_cw)\n\n# summarize all columns by calendar year\ndata_premium_trend_calendar &lt;- data_premium_agg %&gt;% \n  select(state, year, qtr, on_level_earned_premium, earned_exposure) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(year,\"-Q\", qtr),\n               across(c(on_level_earned_premium, earned_exposure), \\(col) roll::roll_sum(col, width = 4)),\n               average_premium = ifelse(earned_exposure == 0, 0, on_level_earned_premium / earned_exposure)) %&gt;% \n        select(-c(year, qtr)) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits\ndata_prem_trend_fits &lt;- data_premium_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n\n      calculate_weighted_fits(df_calendar = data, var = \"average_premium\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"average_premium\")\n\n# calculate Countrywide selections\ndata_premium_trend_selected_cw &lt;- data_premium_agg %&gt;% \n  filter(state == \"Countrywide\") %&gt;% \n  slice_tail(n = 4) %&gt;% \n  summarize(credibility = sum(earned_exposure) %&gt;% multiply_by(0.035) %&gt;% divide_by(1084) %&gt;% sqrt) %&gt;% \n  mutate(state = \"Countrywide\",\n         selected = 0.075,\n         credibility_comp = 0.016,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n\n# calculate state selections and add back in Countrywide\ndata_premium_trend_selected &lt;- data_premium_agg %&gt;% \n  filter(state != \"Countrywide\") %&gt;% \n  slice_tail(n = 4,\n             by = state) %&gt;% \n  summarize(.by = state,\n            credibility = sum(earned_exposure) %&gt;% multiply_by(0.035) %&gt;% divide_by(1084) %&gt;% sqrt) %&gt;% \n  mutate(selected = 0.05,\n         credibility_comp = data_premium_trend_selected_cw$z_wtd_selected,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n  bind_rows(data_premium_trend_selected_cw)\n\n### ---- Current level earned premium ----\n\n# calculate current level factor\ndata_premium_current_level &lt;- data_premium_agg %&gt;% \n  mutate(accident_quarter = paste0(year, \"-Q\", qtr),\n         current_level_factor = earned_premium == 0, 1, on_level_earned_premium / earned_premium) %&gt;% \n  select(state, accident_quarter, earned_premium, current_level_factor, on_level_earned_premium) %&gt;% \n  slice_tail(n = 21, by = state) # 5 years of data + 1 quarter\n\n# summarize data by fiscal year\ndata_premium_current_level_fiscal &lt;- summarize_by_fiscal_year(df = data_premium_current_level) %&gt;% \n  rename(earned_premium = var1_cumulative, current_level_factor = factor, current_level_earned_premium = var2_cumulative)\n\n### ---- Paid loss ----\n\n### Loss triangle\n\n# format as triangle\ndata_paid_loss_triangle &lt;- format_bases_as_triangle(df_agg_age = data_loss_agg_age_cw, var = \"paid_loss_plus_lae\")\n\n# output triangle\ndata_paid_loss_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Non-catastrophe paid loss + LAE**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Evaluation months\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 0) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Development factors\n\n# calculate development factors\ndata_paid_loss_dev &lt;- calculate_dev_factors(df_agg_age = data_loss_agg_age_cw, var = \"paid_loss_plus_lae\")\n\n# format as triangle\ndata_paid_loss_dev_triangle &lt;- format_dev_factors_as_triangle(df_dev = data_paid_loss_dev)\n\n# output triangle\ndata_paid_loss_dev_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Selections\n\n# hardcoding selections\nselects_paid_loss &lt;- c(3.000,1.230,1.200,1.180,1.030,1.040,1.060,1.025,1.050,1.040,1.025,1.050,1.080,1.050,1.040,1.010,1.000,1.000,1.000,1.000,1.040)\n\n# weighted development factors\ndata_paid_loss_selects &lt;- calculate_weighted_dev_factors(df_loss_tri = data_paid_loss_triangle, selects = selects_paid_loss)\n\n# output table\ndata_paid_loss_selects %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**X-weighted development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(id = \"Weight\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### ---- Incurred loss ----\n\n### Loss triangle\n\n# format as triangle\ndata_incurred_loss_triangle &lt;- format_bases_as_triangle(df_agg_age = data_loss_agg_age_cw, var = \"incurred_loss\")\n\n# output triangle\ndata_incurred_loss_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Non-catastrophe incurred loss + LAE**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Evaluation months\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 0) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Development factors\n\n# calculate development factors\ndata_incurred_loss_dev &lt;- calculate_dev_factors(df_agg = data_loss_agg_age_cw, var = \"incurred_loss\")\n\n# format as triangle\ndata_incurred_loss_dev_triangle &lt;- format_dev_factors_as_triangle(df_dev = data_incurred_loss_dev)\n\n# output triangle\ndata_incurred_loss_dev_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Selections\n\n# hardcoding selections\nselects_incurred_loss &lt;- c(1.230,1.050,1.020,1.030,1.000,1.020,1.020,1.020,1.050,1.080,1.030,1.080,1.080,1.030,1.020,1.010,1.010,1.000,1.000,1.000,1.000)\n\n# weighted development factors\ndata_incurred_loss_selects &lt;- calculate_weighted_dev_factors(df_loss_tri = data_incurred_loss_triangle ,selects = selects_incurred_loss)\n\n# output table\ndata_incurred_loss_selects %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**X-weighted development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(id = \"Weight\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### ---- Incurred claim count ----\n\n### Claim count triangle\n\n# format as triangle\ndata_incurred_claim_count_triangle &lt;- format_bases_as_triangle(df_agg = data_loss_agg_age_cw, var = \"incurred_claim_count\")\n\n# output triangle\ndata_incurred_claim_count_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Non-catastrophe incurred claim count**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Evaluation months\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 0) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Development factors\n\n# calculate development factors\ndata_incurred_claim_count_dev &lt;- calculate_dev_factors(df_agg = data_loss_agg_age_cw, var = \"incurred_claim_count\")\n\n# format as triangle\ndata_incurred_claim_count_dev_triangle &lt;-  format_dev_factors_as_triangle(df_dev = data_incurred_claim_count_dev)\n\n# output triangle\ndata_incurred_claim_count_dev_triangle %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**Development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(accident_quarter = \"Accident\\nQuarter\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### Selections\n\n# hardcoding selections\nselects_incurred_claim_count &lt;- c(1.015,1.000,0.990,1.000,0.990,rep(1.000, 16))\n\n# weighted development factors\ndata_incurred_claim_count_selects &lt;- calculate_weighted_dev_factors(df_loss_tri = data_incurred_claim_count_triangle, selects = selects_incurred_claim_count)\n\n# output table\ndata_incurred_claim_count_selects %&gt;% \n  gt %&gt;% \n  opt_stylize(style = 3) %&gt;%  \n  tab_header(title = md(\"**X-weighted development factors**\"),\n             subtitle = md(\"**2024-Q2 indication evaluated as of 2024-Q3**\")) %&gt;% \n  tab_spanner(label = \"Age : Age\",\n              columns = -1) %&gt;% \n  cols_label(id = \"Weight\") %&gt;%\n  fmt_number(columns = -1,\n             decimals = 3) %&gt;% \n  sub_missing(missing_text = \"\")\n\n### ---- Ultimate ----\n\n### Summarize data\n\n# create summarized loss data (accident quarter) by state, then overall (cw), and then combine\ndata_loss_agg &lt;- data_loss %&gt;% \n  filter(eval_year == max(eval_year)) %&gt;% # only use rows in most recent evaluation period\n  filter(eval_qtr == max(eval_qtr)) %&gt;% # -&gt; this makes it accident quarter\n  group_by(state, loss_year, loss_qtr) %&gt;% \n  summarize(across(starts_with(\"incurred\"), sum)) %&gt;% \n  ungroup\ndata_loss_agg_cw &lt;- data_loss_agg %&gt;% \n  group_by(loss_year, loss_qtr) %&gt;% \n  summarize(across(starts_with(\"incurred\"), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_loss_agg %&lt;&gt;% bind_rows(data_loss_agg_cw)\n\n### Loss\n\n# append age to ultimate factors and calculate ultimate losses \ndata_ult_loss &lt;- calculate_ultimate_incurred(df_agg = data_loss_agg, df_selects = data_incurred_loss_selects, var = \"incurred_loss\") %&gt;% \n  rename(incurred_loss = incurred, incurred_age_to_ult = factor, ult_incurred_loss = ult_incurred)\n\n# summarize data by fiscal year\ndata_ult_loss_fiscal &lt;- summarize_by_fiscal_year(df = data_ult_loss) %&gt;% \n  rename(incurred_loss = var1_cumulative, implied_incurred_age_to_ult = factor, ult_incurred_loss = var2_cumulative)\n\n### Claim count\n\n# append age to ultimate factors and calculate ultimate claim count\ndata_ult_claim_count &lt;- calculate_ultimate_incurred(df_agg = data_loss_agg, df_selects = data_incurred_claim_count_selects, var = \"incurred_claim_count\") %&gt;% \n  rename(incurred_claim_count = incurred, implied_incurred_age_to_ult = factor, ult_incurred_claim_count = ult_incurred)\n\n# summarize data by fiscal year\ndata_ult_claim_count_fiscal &lt;- summarize_by_fiscal_year(df = data_ult_claim_count) %&gt;% \n  rename(incurred_claim_count = var1_cumulative, implied_incurred_age_to_ult = factor, ult_incurred_claim_count = var2_cumulative)\n\n### ---- Frequency trend ----\n\n# create summarized loss data (calendar quarter) by state, then overall (cw), and then combine\n# -&gt; data is already only using the most recent evaluation period\ndata_rept_freq_agg &lt;- data_rept_freq_raw2 %&gt;% \n  group_by(state, rept_year, rept_qtr) %&gt;% \n  summarize(reported_count = sum(reported_count)) %&gt;% \n  ungroup\ndata_rept_freq_agg_cw &lt;- data_rept_freq_agg %&gt;% \n  group_by(rept_year, rept_qtr) %&gt;% \n  summarize(reported_count = sum(reported_count)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_rept_freq_agg %&lt;&gt;% bind_rows(data_rept_freq_agg_cw)\n\n# create summarized closed by closed evaluation data (calendar quarter) overall (cw) and then combine\ndata_clsd_by_clsd_eval_date_agg_cw &lt;- data_clsd_by_clsd_eval_date_agg %&gt;% \n  group_by(eval_year, eval_qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_clsd_by_clsd_eval_date_agg %&lt;&gt;% bind_rows(data_clsd_by_clsd_eval_date_agg_cw)\n\n# summarize all columns by calendar year\ndata_freq_trend_calendar &lt;- data_premium_agg %&gt;% \n  select(state, year, qtr, earned_exposure) %&gt;% \n  left_join(data_rept_freq_agg %&gt;% select(state, rept_year, rept_qtr, reported_count), by = join_by(state, year == rept_year, qtr == rept_qtr)) %&gt;% \n  left_join(data_clsd_by_clsd_eval_date_agg %&gt;% select(state, eval_year, eval_qtr, closed_w_pay_count), by = join_by(state, year == eval_year, qtr == eval_qtr)) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  {. -&gt;&gt; data_freq_trend_agg} %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(year, \"-Q\", qtr),\n               across(c(earned_exposure, reported_count, closed_w_pay_count), \\(col) roll::roll_sum(col, width = 4)),\n               reported_freq = ifelse(earned_exposure == 0, NA, reported_count / earned_exposure),\n               closed_w_pay_freq = ifelse(earned_exposure == 0, NA, closed_w_pay_count / earned_exposure)) %&gt;% \n        select(calendar_quarter_ended, earned_exposure, reported_count, reported_freq, closed_w_pay_count, closed_w_pay_freq) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits one variable at a time, then combine\n# -&gt; reported frequency\ndata_freq_trend_fits_a &lt;- data_freq_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n\n      calculate_weighted_fits(df_calendar = data, var = \"reported_freq\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"reported_freq\")\n# -&gt; closed with pay frequency\ndata_freq_trend_fits_b &lt;- data_freq_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n\n      calculate_weighted_fits(df_calendar = data, var = \"closed_w_pay_freq\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"closed_w_pay_freq\")\n# -&gt; combine\ndata_freq_trend_fits &lt;- data_freq_trend_fits_a %&gt;% left_join(data_freq_trend_fits_b, by = join_by(state, pt))\n\n# calculate Countrywide selections\ndata_freq_trend_selected_cw &lt;- data_freq_trend_agg %&gt;% \n  filter(state == \"Countrywide\") %&gt;% \n  slice_tail(n = 4) %&gt;% \n  summarize(credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n  mutate(state = \"Countrywide\",\n         selected = 0.04,\n         credibility_comp = 0,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n\n# calculate state selections and add back in Countrywide\ndata_freq_trend_selected &lt;- data_freq_trend_agg %&gt;% \n  filter(state != \"Countrywide\") %&gt;% \n  slice_tail(n = 4,\n             by = state) %&gt;% \n  summarize(.by = state,\n            credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n  mutate(selected = 0.04,\n         credibility_comp = data_freq_trend_selected_cw$z_wtd_selected,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n  bind_rows(data_freq_trend_selected_cw)\n\n### ---- Severity trend ----\n\n# create summarized closed by evaluation data (calendar quarter) overall (cw) and then combine\ndata_clsd_by_eval_date_agg_cw &lt;- data_clsd_by_eval_date_agg %&gt;% \n  group_by(eval_year, eval_qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_clsd_by_eval_date_agg %&lt;&gt;% bind_rows(data_clsd_by_eval_date_agg_cw)\n\n# summarize all columns by calendar year\ndata_sev_trend_calendar &lt;- data_clsd_by_clsd_eval_date_agg %&gt;% \n  select(state, eval_year, eval_qtr, closed_w_pay_count, total_paid_loss_lae_net_of_s_s) %&gt;% \n  left_join(data_clsd_by_eval_date_agg %&gt;% select(state, eval_year, eval_qtr, total_paid_loss_lae_net_of_s_s, post_closure_total_paid_loss_lae_net_of_s_s), by = join_by(state, eval_year, eval_qtr), suffix = c(\"_clsdbyclsd\", \"_clsd\")) %&gt;% \n  rename(paid_loss = total_paid_loss_lae_net_of_s_s_clsd) %&gt;% \n  mutate(paid_on_closed_loss = total_paid_loss_lae_net_of_s_s_clsdbyclsd + post_closure_total_paid_loss_lae_net_of_s_s) %&gt;% \n  select(-c(post_closure_total_paid_loss_lae_net_of_s_s, total_paid_loss_lae_net_of_s_s_clsdbyclsd)) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  {. -&gt;&gt; data_sev_trend_agg} %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(eval_year, \"-Q\", eval_qtr),\n               across(c(closed_w_pay_count, paid_loss, paid_on_closed_loss), \\(col) roll::roll_sum(col, width = 4)),\n               paid_sev = ifelse(closed_w_pay_count == 0, NA, paid_loss / closed_w_pay_count),\n               paid_on_closed_sev = ifelse(closed_w_pay_count == 0, NA, paid_on_closed_loss / closed_w_pay_count)) %&gt;% \n        select(calendar_quarter_ended, closed_w_pay_count, paid_loss, paid_sev, paid_on_closed_loss, paid_on_closed_sev) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits one variable at a time, then combine\n# -&gt; paid severity\ndata_sev_trend_fits_a &lt;- data_sev_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n\n      calculate_weighted_fits(df_calendar = data, var = \"paid_sev\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"paid_sev\")\n# -&gt; paid on closed severity\ndata_sev_trend_fits_b &lt;- data_sev_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n\n      calculate_weighted_fits(df_calendar = data, var = \"paid_on_closed_sev\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"paid_on_closed_sev\")\n# -&gt; combine\ndata_sev_trend_fits &lt;- data_sev_trend_fits_a %&gt;% left_join(data_sev_trend_fits_b, by = join_by(state, pt))\n\n# calculate Countrywide selections\ndata_sev_trend_selected_cw &lt;- data_sev_trend_agg %&gt;% \n  filter(state == \"Countrywide\") %&gt;% \n  slice_tail(n = 4) %&gt;% \n  summarize(credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n  mutate(state = \"Countrywide\",\n         selected = 0.14,\n         credibility_comp = 0.02,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n\n# calculate state selections and add back in Countrywide\ndata_sev_trend_selected &lt;- data_sev_trend_agg %&gt;% \n  filter(state != \"Countrywide\") %&gt;% \n  slice_tail(n = 4,\n             by = state) %&gt;% \n  summarize(.by = state,\n            credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n  mutate(selected = 0.14,\n         credibility_comp = data_sev_trend_selected_cw$z_wtd_selected,\n         z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n  bind_rows(data_sev_trend_selected_cw)\n\n### ---- Indication ----\n\n### Calculations\n\n# initialize needed items\nselection_state &lt;- \"California\"\nselection_data_ended &lt;- \"2024-06-30\"\nselection_effective_date &lt;- \"2025-02-04\"\nselection_lcm &lt;- 1.669\nselection_underlying_plr &lt;- 1 / selection_lcm\nselection_ay_weights &lt;- data_ult_loss_fiscal %&gt;% \n  filter(state != \"Countrywide\") %&gt;% \n  distinct(state, fiscal_year_ended) %&gt;% \n  bind_cols(data.frame(ay_weights = rep(c(0,0,0.15,0.40,0.45), nrow(.) / 5)))\nselection_ay_weights_cw &lt;- data_ult_loss_fiscal %&gt;% \n  distinct(fiscal_year_ended) %&gt;% \n  bind_cols(data.frame(ay_weights = c(0.10,0.15,0.20,0.25,0.30))) %&gt;% \n  mutate(state = \"Countrywide\")\n# -&gt; shiny quark, can't use assign pipe\nselection_ay_weights2 &lt;- selection_ay_weights %&gt;% bind_rows(selection_ay_weights_cw)\n\n# calculate indication table\ndata_indication &lt;- data_premium_current_level_fiscal %&gt;% \n  select(state, fiscal_year_ended, current_level_earned_premium) %&gt;% \n  mutate(trend_time_premium = \n           case_when(\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 0 ~ 12,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 1 ~ 24,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 2 ~ 36,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 3 ~ 48,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 4 ~ 60\n           )) %&gt;% \n  left_join(data_premium_trend_selected %&gt;% select(state, prem_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;% \n  mutate(premium_trend_factors = prem_trend_z_wtd_selected %&gt;% \n           add(1) %&gt;% \n           # raise_to_power(interval(ymd(selection_data_ended) %m-% years(5),\n           #                         ymd(selection_effective_date) %m+% months(6)) %&gt;% \n           #                  divide_by(years(1))) %&gt;% # more accurate way\n           raise_to_power(subtract(ymd(selection_effective_date) %m+% months(6),\n                                   ymd(selection_data_ended) %m-% months(trend_time_premium)) %&gt;% \n                            divide_by(365) %&gt;% as.numeric), # equivalent to excel\n         trended_current_level_earned_premium = current_level_earned_premium * premium_trend_factors\n  ) %&gt;% \n  left_join(data_ult_loss_fiscal %&gt;% select(state, fiscal_year_ended, incurred_loss, implied_incurred_age_to_ult, ult_incurred_loss), join_by(state, fiscal_year_ended)) %&gt;% \n  left_join(data_freq_trend_selected %&gt;% select(state, freq_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;% \n  left_join(data_sev_trend_selected %&gt;% select(state, sev_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;% \n  mutate(trend_time_loss = \n           case_when(\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 0 ~ 6,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 1 ~ 18,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 2 ~ 30,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 3 ~ 42,\n             year(ymd(selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 4 ~ 54\n           ),\n         loss_trend_factors = freq_trend_z_wtd_selected %&gt;% \n           add(1) %&gt;% \n           multiply_by(sev_trend_z_wtd_selected \n                       %&gt;% add(1))%&gt;% \n           raise_to_power(subtract(ymd(selection_effective_date) %m+% months(12),\n                                   ymd(selection_data_ended) %m-% months(trend_time_loss)) %&gt;% \n                            divide_by(365) %&gt;% as.numeric),\n         trended_ult_incurred_loss = ult_incurred_loss * loss_trend_factors,\n         trended_ult_incurred_partial_loss_ratio = ifelse(trended_current_level_earned_premium == 0, NA, trended_ult_incurred_loss / trended_current_level_earned_premium)) %&gt;% \n  left_join(selection_ay_weights2, by = join_by(state, fiscal_year_ended))\n\n# calculate catastrophe ratios\n# -&gt; statewide\ndata_cat &lt;- data_rms_modeled_loss %&gt;% \n  mutate(modeled_hurricane_ratio = rms_hurricane_gross_aal / in_force_premium,\n         .keep = \"unused\") %&gt;% \n  left_join(data_ts_modeled_loss %&gt;% \n              mutate(modeled_fire_following_earthquake_ratio = touchstone_eq_fire_following_gross_aal / in_force_premium,\n                     modeled_severe_convective_storm_ratio = touchstone_severe_convective_storm_gross_aal / in_force_premium,\n                     modeled_wildfire_ratio = touchstone_wildfire_gross_aal / in_force_premium,\n                     .keep = \"unused\"),\n            by = join_by(state))\n# -&gt; Countrywide\ndata_cat_cw &lt;- data_rms_modeled_loss %&gt;% \n  summarize(modeled_hurricane_ratio = sum(rms_hurricane_gross_aal) / sum(in_force_premium)) %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1) %&gt;% \n  left_join(data_ts_modeled_loss %&gt;% \n              summarize(modeled_fire_following_earthquake_ratio = sum(touchstone_eq_fire_following_gross_aal) / sum(in_force_premium),\n                     modeled_severe_convective_storm_ratio = sum(touchstone_severe_convective_storm_gross_aal) / sum(in_force_premium),\n                     modeled_wildfire_ratio = sum(touchstone_wildfire_gross_aal) / sum(in_force_premium)) %&gt;% \n              mutate(state = \"Countrywide\",\n                     .before = 1),\n            by = join_by(state))\n# -&gt; combine\ndata_cat %&lt;&gt;% bind_rows(data_cat_cw) \n\n# final indication calculations\ndata_indication2 &lt;- data_indication %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n     \n      data %&gt;% \n        mutate(trended_ult_incurred_partial_loss_ratio = replace_na(trended_ult_incurred_partial_loss_ratio, 0)) %$%\n        crossprod(trended_ult_incurred_partial_loss_ratio, ay_weights) %&gt;% \n        data.frame(ay_weighted_trended_ult_incurred_partial_loss_ratio = .) %&gt;% \n        return\n       \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  left_join(data_ult_claim_count_fiscal %&gt;% \n              summarize(.by = state, ult_incurred_claim_count = sum(ult_incurred_claim_count)) %&gt;% \n              rowwise() %&gt;% \n              mutate(credibility = ult_incurred_claim_count %&gt;% divide_by(1084) %&gt;% sqrt %&gt;% min(., 1)) %&gt;% \n              select(state, credibility),\n            by = join_by(state)) %&gt;% \n  left_join(data_cat, by = join_by(state)) %&gt;% \n  rowwise() %&gt;% \n  mutate(total_modeled_peril_partial_loss_ratio = sum(modeled_hurricane_ratio, modeled_fire_following_earthquake_ratio, modeled_severe_convective_storm_ratio, modeled_wildfire_ratio) * 1.15,\n  trended_underlying_plr_less_modeled_perils = case_when(\n    state == \"Countrywide\" ~ selection_underlying_plr %&gt;% \n      subtract(total_modeled_peril_partial_loss_ratio) %&gt;% \n      multiply_by(data_freq_trend_selected_cw$selected %&gt;% \n                    add(1)) %&gt;% \n      multiply_by(data_sev_trend_selected_cw$selected %&gt;% \n                    add(1)) %&gt;% \n      divide_by(data_premium_trend_selected_cw$selected %&gt;% \n                  add(1)),\n    .default = NA),\n    credibility_weighted_trended_ult_incurred_loss_ratio = case_when(\n      state == \"Countrywide\" ~ ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;% \n        multiply_by(credibility) %&gt;% \n        add(trended_underlying_plr_less_modeled_perils %&gt;% \n              multiply_by(1 %&gt;% \n                            subtract(credibility))),\n      .default = NA)\n  )\n\n# set constant\ncredibility_weighted_trended_ult_incurred_loss_ratio_cw &lt;- data_indication2 %&gt;% \n  filter(state == \"Countrywide\") %&gt;% \n  pull(credibility_weighted_trended_ult_incurred_loss_ratio) %&gt;% \n  as.numeric\n\n# continue final indication calculations\n# -&gt; shiny quark again\ndata_indication3 &lt;- data_indication2 %&gt;% \n  mutate(cw_ay_weighted_trended_ult_incurred_partial_loss_ratio = case_when(\n    state != \"Countrywide\" ~ credibility_weighted_trended_ult_incurred_loss_ratio_cw,\n    .default = NA),\n    credibility_weighted_trended_ult_incurred_loss_ratio = case_when(\n      state != \"Countrywide\" ~ ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;% \n        multiply_by(credibility) %&gt;% \n        add(cw_ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;% \n              multiply_by(1 %&gt;% \n                            subtract(credibility))),\n      .default = credibility_weighted_trended_ult_incurred_loss_ratio\n    ),\n    margin_for_reinsurance = 0,\n    total_prospective_loss_ratio = credibility_weighted_trended_ult_incurred_loss_ratio + total_modeled_peril_partial_loss_ratio + margin_for_reinsurance,\n    permissable_loss_ratio = 0.601,\n    indicated_rate_level_needed = total_prospective_loss_ratio / permissable_loss_ratio - 1)\n  \n### Display\n\nselection_eval_date &lt;- ymd(selection_data_ended) %m+% months(3)\n\n# output summary table\nformat_as_indication_summary(data_ind = data_indication, sel_state = \"Countrywide\", sel_data_ended = selection_data_ended, sel_eval_date = selection_eval_date)\n\n# organize, convert to long data, and reformat variable names for displaying\ndata_indication3_long &lt;- data_indication3 %&gt;% \n  select(state, ay_weighted_trended_ult_incurred_partial_loss_ratio, credibility, trended_underlying_plr_less_modeled_perils, cw_ay_weighted_trended_ult_incurred_partial_loss_ratio, credibility_weighted_trended_ult_incurred_loss_ratio, starts_with(\"modeled\"), total_modeled_peril_partial_loss_ratio, margin_for_reinsurance, total_prospective_loss_ratio, permissable_loss_ratio, indicated_rate_level_needed) %&gt;% \n  pivot_longer(cols = -1,\n               names_to = \"variable\",\n               values_to = \"value\") %&gt;% \n  mutate(variable_display = \n           case_when(\n             variable == \"ay_weighted_trended_ult_incurred_partial_loss_ratio\" ~ \"Accident year weighted trended ultimate incurred partial loss ratio:\",\n             variable == \"credibility\" ~ \"Credibility (ultimate claims using 1,084 standard):\",\n             variable == \"trended_underlying_plr_less_modeled_perils\" ~ \"Trended, underlying permissible loss ratio less modeled perils:\",\n             variable == \"cw_ay_weighted_trended_ult_incurred_partial_loss_ratio\" ~ \"Countrywide accident year weighted trended ultimate ncurred partial loss + LAE ratio:\",\n             variable == \"credibility_weighted_trended_ult_incurred_loss_ratio\" ~ \"Credibility weighted trended ultimate incurred loss + LAE ratio:\",\n             variable == \"modeled_hurricane_ratio\" ~ \"Modeled hurricane ratio:\",\n             variable == \"modeled_fire_following_earthquake_ratio\" ~ \"Modeled fire following earthquake ratio:\", \n             variable == \"modeled_severe_convective_storm_ratio\" ~ \"Modeled severe convective storm ratio:\",\n             variable == \"modeled_wildfire_ratio\" ~ \"Modeled wildfire ratio:\",\n             variable == \"total_modeled_peril_partial_loss_ratio\" ~ \"Total modeled peril partial loss + LAE ratio (modeled ratios x 1.15 LAE factor):\",\n             variable == \"margin_for_reinsurance\" ~ \"Margin for reinsurance:\",\n             variable == \"total_prospective_loss_ratio\" ~ \"Total prospective loss + LAE ratio:\",\n             variable == \"permissable_loss_ratio\" ~ \"Permissable loss + LAE ratio:\",\n             variable == \"indicated_rate_level_needed\" ~ \"Indicated rate level needed:\"\n           ),\n         .after = variable\n  )\n\n# output indication calculations table\nformat_as_indication_calculations(data_ind3_long = data_indication3_long, sel_state = \"Countrywide\")\n\n# output indication calculations supporting table\nformat_as_indication_calculations_support(data_ind3_long = data_indication3_long, sel_state = \"Countrywide\")\n\n### ---- Data checks ----\n\n# -&gt; paid loss triangle\ny &lt;- summarize(data_paid_loss_triangle, across(where(is.numeric), \\(x) sum(x, na.rm = TRUE)))\nwrite.csv(y, \"test.csv\")\n\n\n2.1.11 Indications - app\n\n### ---- Load packages ----\n\nlibrary(shiny)\nlibrary(plotly)\nlibrary(gridlayout)\nlibrary(bslib)\nlibrary(DT)\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(gt)\n\n### ---- Functions ----\n\n`%!in%` &lt;- Negate(\"%in%\")\n\n# function to format long data as triangle\n# -&gt; assuming age to ultimate is 63 quarters\n# -&gt; n_periods = 28 --&gt; 7 years of data for triangle\nformat_bases_as_triangle &lt;- function(df_agg_age, var, ult_age = 63, n_periods = 28) {\n  \n  var = enquo(var)\n  \n  df_agg_age %&lt;&gt;%  \n    filter(age &lt;= ult_age) %&gt;% \n    select(1:3, !!var) %&gt;% \n    pivot_wider(names_from = age,\n                values_from = !!var) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr)) %&gt;% \n    select(accident_quarter, as.character(seq(from = 3, to = ult_age, by = 3))) %&gt;% \n    slice_tail(n = n_periods) %&gt;% \n    return\n  \n}\n\n# define function to calculate development factors\ncalculate_dev_factors &lt;- function(df_agg_age, var) {\n  \n  var = enquo(var)\n  \n  # reduce input data to only needed columns\n  df_agg_age %&lt;&gt;% select(1:3, !!var)\n  \n  # setup output dataframe\n  df_dev = matrix(data = NA,\n                  ncol = ncol(df_agg_age) + 1,                  \n                  nrow = nrow(df_agg_age - 1)) %&gt;% # taking ratios, so one row less\n    data.frame\n  colnames(df_dev) = c(\"loss_year\",\"loss_qtr\", \"left\", \"right\", \"dev_factor\")\n  \n  # calculate development factors\n  for (i in 1:nrow(df_agg_age)-1) {\n    \n    # set constants\n    df_dev[i,1:2] = df_agg_age[i,1:2]\n    \n    # set ratio column indicators\n    df_dev[i,3] = df_agg_age[i+1,3]\n    df_dev[i,4] = df_agg_age[i,3]\n    \n    # calculate factor\n    df_dev[i,5] = ifelse(df_agg_age[i,4] == 0,\n                         NA,\n                         as.numeric(df_agg_age[i+1,4]) / as.numeric(df_agg_age[i,4]))\n    \n  }\n  \n  # remove unwanted comparisons and format ratio indicator\n  df_dev %&lt;&gt;% \n    filter(left &gt; right) %&gt;% \n    mutate(age_age = paste0(left, \":\", right),\n           .after = 2)\n  \n  df_dev %&gt;% return\n  \n}\n\n# format loss development factors as triangle\n# -&gt; assuming age to ultimate is 63 quarters\n# -&gt; n_periods = 27 --&gt; 7 years of data for triangle\nformat_dev_factors_as_triangle &lt;- function(df_dev, ult_age = 63, n_periods = 27) {\n  \n  df_dev %&gt;% \n    filter(left &lt;= ult_age) %&gt;% \n    select(-c(left, right)) %&gt;% \n    pivot_wider(names_from = age_age,\n                values_from = dev_factor) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr),\n           \"Ult:{{ult_age}}\" := NA) %&gt;% \n    select(accident_quarter, as.character(paste0(seq(from = 6, to = ult_age, by = 3),\":\", seq(from = 3, to = ult_age-3, by = 3))), paste0(\"Ult:\", ult_age)) %&gt;% \n    slice_tail(n = n_periods) %&gt;% \n    return\n  \n}\n\n# define function to calculate weighted development factors\ncalculate_weighted_dev_factors &lt;- function(df_loss_tri, selects, ult_age = 63) {\n  \n  # setup output dataframe\n  df_weights = matrix(data = NA,\n                      ncol = ncol(df_loss_tri),                  \n                      nrow = 3) %&gt;%\n    data.frame\n  colnames(df_weights) = c(\"id\", paste0(seq(from = 6, to = ult_age, by = 3),\":\", seq(from = 3, to = ult_age-3, by = 3)), paste0(\"Ult:\", ult_age))\n  \n  # set constants\n  df_weights$id = paste0(seq(from = 8, to = 16, by = 4), \" pts wtd\")\n  \n  # calculated weighted development factors\n  for (i in 1:nrow(df_weights)) {\n    \n    # set number of periods to look back (i.e. weight)\n    weight = df_weights[i,1] %&gt;% str_sub(., 1, str_locate(., \" pts\")[1]-1) %&gt;% as.numeric\n    \n    for (j in 2:(ncol(df_weights)-1)) {\n      \n      # figure out number of periods with data in triangle for the larger age\n      data_count = nrow(df_loss_tri) - sum(is.na(df_loss_tri[,j+1]))\n      \n      # calculate X-pts weighted ratio\n      df_weights[i,j] = df_loss_tri %&gt;% \n        mutate(row_num = row_number()) %&gt;% \n        filter(between(row_num, data_count - weight + 1, data_count)) %&gt;% \n        select(all_of(c(1, j, j+1))) %&gt;% \n        rename(col_j = 2, col_j_minus_1 = 3) %&gt;% \n        summarize(sum(col_j_minus_1) / sum(col_j))\n      \n    }\n    \n  }\n  \n  # create dataframe of selects for each age:age\n  # -&gt; need to organize so can correctly calculate in next step\n  df_selects = data.frame(age_age = colnames(df_weights)[-1], selected = selects) %&gt;% \n    mutate(row_num = row_number()) %&gt;% \n    arrange(desc(row_num))\n  \n  # calculate cumulative selects \"backwards\"\n  selects_cumulative = df_selects$selected %&gt;% cumprod\n  \n  # append calculated factors and reorganize\n  df_selects %&lt;&gt;% \n    bind_cols(selects = data.frame(cumulative = selects_cumulative)) %&gt;% \n    arrange(row_num) %&gt;% \n    select(-row_num) %&gt;% \n    select(2:3) %&gt;% \n    t %&gt;% \n    data.frame %&gt;% \n    rownames_to_column()\n  colnames(df_selects) = colnames(df_weights)\n  \n  # combine dataframes\n  df_weights %&lt;&gt;% \n    bind_rows(df_selects)\n  \n  df_weights %&gt;% return\n  \n}\n\n# function to calculate ultimate incurred\ncalculate_ultimate_incurred &lt;- function(df_agg, df_selects, var) {\n  \n  # extract cumulative select factors\n  cumlative_selects = df_selects %&gt;% \n    filter(id == \"cumulative\") %&gt;% \n    select(-id) %&gt;% \n    pivot_longer(cols = everything(),\n                 names_to = \"age_age\",\n                 values_to = \"cumulative_factor\")\n  \n  # reorganize summary table for appending cumulative selects\n  df_agg %&lt;&gt;% \n    arrange(state, desc(loss_year), desc(loss_qtr)) %&gt;% \n    select(state, loss_year, loss_qtr, any_of(var))\n  \n  # append cumulative selects, organize data, and calculate new column\n  # -&gt; fill rest of values with NA\n  df_agg %&gt;% \n    nest_by(state) %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data) {\n        \n        data$factor &lt;- c(cumlative_selects$cumulative_factor, rep(NA, nrow(data) - nrow(cumlative_selects)))\n        \n        data %&gt;% return\n        \n      })\n    ) %&gt;% \n    reframe(data) %&gt;%  \n    arrange(state, loss_year, loss_qtr) %&gt;% \n    filter(!is.na(factor)) %&gt;% \n    mutate(accident_quarter = paste0(loss_year, \"-Q\", loss_qtr),\n           ult_incurred = !!sym(var) * factor) %&gt;% \n    select(state, accident_quarter, incurred = any_of(var), factor, ult_incurred) %&gt;% \n    return\n  \n}\n\n# summarize data by fiscal year\nsummarize_by_fiscal_year &lt;- function(df) {\n  \n  df %&lt;&gt;% \n    rename(var1 = 3, factor = 4, var2 = 5) %&gt;% # standardize names\n    nest_by(state) %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data) {\n        \n        # drop most recent period, calculate rolling sum by fiscal year, calculate factor, and organize\n        data %&lt;&gt;% \n          slice_head(n = nrow(.)-1) %&gt;% \n          mutate(var1_cumulative = roll::roll_sum(var1, width = 4),\n                 var2_cumulative = roll::roll_sum(var2, width = 4),\n                 factor = ifelse(var1_cumulative == 0, NA, var2_cumulative / var1_cumulative),\n                 quarter = str_sub(accident_quarter, -1, -1))\n        \n        # get most recent quarter to work from\n        ref_qtr = data %&gt;% \n          slice_tail(n = 1) %&gt;% \n          pull(quarter) %&gt;% \n          as.numeric\n        \n        # keep only relevant periods\n        data %&gt;% \n          filter(quarter == ref_qtr) %&gt;% \n          select(fiscal_year_ended = accident_quarter, var1_cumulative, factor, var2_cumulative) %&gt;% \n          return\n        \n      })\n    )\n  \n  # set NAs to Countrywide values\n  df_cw = df %&gt;% \n    filter(state == \"Countrywide\") %&gt;% \n    reframe(data) %&gt;% \n    select(fiscal_year_ended, factor)\n  \n  # use Countrywide values if NA for state factors and organize data\n  df %&gt;% \n    mutate(data = map(\n      .x = list(data),\n      .f = \\(data, df_cw) {\n        \n        data %&gt;% \n          left_join(df_cw,\n                    by = join_by(fiscal_year_ended),\n                    suffix = c(\"_st\", \"_cw\")) %&gt;% \n          mutate(factor = ifelse(is.na(factor_st), factor_cw, factor_st)) %&gt;% \n          select(fiscal_year_ended, var1_cumulative, factor, var2_cumulative)\n        \n      },\n      df_cw)\n    ) %&gt;% \n    reframe(data) %&gt;% \n    return\n  \n}\n\n# function to calculate the final step of the trending (x is a vector of two fits)\ncalculate_final_fit &lt;- function(x) {\n  \n  x[2] / x[1] - 1\n  \n}\n\n# function calculated weighted fits\ncalculate_weighted_fits &lt;- function(df_calendar, var) {\n  \n  # initialize needed items\n  pts = seq(from = 8, to = 24, by = 4)\n  fits = rep(NA, length(pts))\n  j = 1\n  \n  # loop through different weights (fits)\n  for (x in pts) {\n    \n    # reassign full dataset\n    df_temp = df_calendar\n    \n    # limit dataset and calculate fit\n    df_temp %&lt;&gt;% \n      slice_tail(n = 24) %&gt;% # skip periods where cumulative sum isn't full\n      mutate(i = row_number()) %&gt;% # set Xs\n      slice_tail(n = x)\n    \n    if (sum(is.na(df_temp %&gt;% pull(any_of(var)))) == nrow(df_temp)) { # if no data, stop don't calculate anything\n      \n      fits[j] = NA\n      \n    } else {\n      \n      fits[j] = df_temp %&gt;% \n        lm(paste0(var, \" ~ i\") %&gt;% as.formula, data = .) %&gt;% \n        predict(newdata = data.frame(i = c(20,24))) %&gt;% \n        calculate_final_fit\n      \n    }\n    \n    j = j + 1\n    \n  }\n  \n  # reorganize\n  fits %&lt;&gt;% \n    data.frame %&gt;% \n    t %&gt;% \n    data.frame\n  colnames(fits) = paste0(seq(from = 8, to = 24, by = 4), \" pt\")\n  fits %&gt;% \n    mutate(across(everything(), \\(x) ifelse(is.nan(x), NA, x))) %&gt;% \n    return\n  \n}\n\n# function to output indication summary table\nformat_as_indication_summary &lt;- function(data_ind, sel_state, sel_data_ended, sel_eval_date) {\n  \n  data_ind %&gt;% \n    filter(state == sel_state) %&gt;% \n    select(fiscal_year_ended,current_level_earned_premium, premium_trend_factors, trended_current_level_earned_premium, incurred_loss, implied_incurred_age_to_ult, ult_incurred_loss, loss_trend_factors, trended_ult_incurred_loss, trended_ult_incurred_partial_loss_ratio, ay_weights) %&gt;% \n    gt %&gt;% \n    opt_stylize(style = 3) %&gt;%  \n    tab_header(title = md(paste0(\"**\", sel_state, \" indications**\")),\n               subtitle = md(paste0(\"**Calendar / accident year data ended \", month(sel_data_ended, label = TRUE, abbr = FALSE), \" \", day(sel_data_ended), \", \", year(sel_data_ended), \" as of \", month(sel_eval_date, label = TRUE, abbr = FALSE), \" \", day(sel_eval_date), \", \", year(sel_eval_date), \"**\"))) %&gt;% \n    cols_label(fiscal_year_ended = \"Year ended\",\n               current_level_earned_premium = \"Current level earned premium\",\n               premium_trend_factors = \"Premium trend factors\",\n               trended_current_level_earned_premium = \"Trended current level earned poremium\",\n               incurred_loss = \"Non-cat incurred loss + LAE\",\n               implied_incurred_age_to_ult = \"Loss development factors\",\n               ult_incurred_loss = \"Ultimate non-cat incurred loss + LAE\",\n               loss_trend_factors = \"Loss trend factors\",\n               trended_ult_incurred_loss = \"Trended ultimate non-cat incurred loss + lae\",\n               trended_ult_incurred_partial_loss_ratio = \"Trended ultimate non-cat incurred parial loss + LAE ratio\",\n               ay_weights = \"Accident year weights\"\n    ) %&gt;%\n    fmt_number(columns = c(current_level_earned_premium, trended_current_level_earned_premium, incurred_loss, ult_incurred_loss, trended_ult_incurred_loss),\n               decimals = 0) %&gt;% \n    fmt_number(columns = c(premium_trend_factors, implied_incurred_age_to_ult, loss_trend_factors),\n               decimals = 3) %&gt;% \n    fmt_percent(columns = c(trended_ult_incurred_partial_loss_ratio, ay_weights),\n                decimals = 1)\n  \n}\n\n# function to output indication calculations table\nformat_as_indication_calculations &lt;- function(data_ind3_long, sel_state) {\n  \n  data_ind3_long %&gt;% \n    filter(state == sel_state,\n           variable %!in% c(\"modeled_hurricane_ratio\", \"modeled_fire_following_earthquake_ratio\", \"modeled_severe_convective_storm_ratio\", \"modeled_wildfire_ratio\")) %&gt;% \n    filter(!is.na(value)) %&gt;% \n    select(variable_display, value) %&gt;% \n    gt %&gt;% \n    tab_options(column_labels.hidden = TRUE) %&gt;% \n    cols_align(columns = variable_display, align = \"right\") %&gt;% \n    cols_align(columns = value, align = \"right\") %&gt;% \n    fmt_percent(columns = value, decimals = 1) %&gt;% \n    tab_style(\n      style = list(\n        cell_text(weight = \"bold\")\n      ),\n      locations = cells_body(\n        columns = c(variable_display, value),\n        rows = variable_display == \"Indicated rate level needed:\"\n      )\n    ) %&gt;% \n    tab_style(\n      style = list(\n        cell_fill(color = \"orange\")\n      ),\n      locations = cells_body(\n        columns = value,\n        rows = variable_display == \"Indicated rate level needed:\"\n      )\n    )\n  \n}\n\n# function to output supporting table of indication calculations\nformat_as_indication_calculations_support &lt;- function(data_ind3_long, sel_state) {\n  \n  data_ind3_long %&gt;% \n    filter(state == sel_state,\n           variable %in% c(\"modeled_hurricane_ratio\", \"modeled_fire_following_earthquake_ratio\", \"modeled_severe_convective_storm_ratio\", \"modeled_wildfire_ratio\")) %&gt;% \n    filter(!is.na(value)) %&gt;% \n    select(variable_display, value) %&gt;% \n    gt %&gt;% \n    tab_options(column_labels.hidden = TRUE) %&gt;% \n    cols_align(columns = variable_display, align = \"right\") %&gt;% \n    cols_align(columns = value, align = \"right\") %&gt;% \n    fmt_percent(columns = value, decimals = 1)\n  \n}\n\n### ---- Read in and create data ----\n\n# read in data from access process\n\n# -&gt; premium data\ndata_premium_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"PremiumData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  rename(qtr = quarter)\n\n# -&gt; loss data\ndata_loss_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"LossData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(across(ends_with(\"qtr\"), as.numeric))\n\n# -&gt; reported frequency data\ndata_rept_freq_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ReptFreqData\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(across(ends_with(\"qtr\"), as.numeric))\n\n# -&gt; closed by closed evaluation data\ndata_clsd_by_clsd_eval_date_raw &lt;- readxl::read_xlsx(path =  \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ClsdByClsdEvalDt\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(eval_qtr = as.numeric(eval_qtr))\n\n# -&gt; closed by evaluation data\ndata_clsd_by_eval_date_raw &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"ClsdByEvalDt\") %&gt;% \n  janitor::clean_names() %&gt;% \n  mutate(eval_qtr = as.numeric(eval_qtr))\n\n# -&gt; RMS modeled loss\ndata_rms_modeled_loss &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"RMSModLoss\") %&gt;% \n  janitor::clean_names()\n\n# -&gt; TS modeled loss\ndata_ts_modeled_loss &lt;- readxl::read_xlsx(path = \"indication-data-2024-q2-eval-2024-q3.xlsx\", sheet = \"TSModLoss\") %&gt;% \n  janitor::clean_names()\n\n# single out vectors\nvec_states &lt;- unique(data_premium_raw$state) # use premium data to capture all states\nvec_loss_years &lt;- unique(data_loss_raw$loss_year)\nvec_loss_qtrs &lt;- unique(data_loss_raw$loss_qtr)\nvec_eval_years &lt;- unique(data_loss_raw$eval_year)\nvec_eval_qtrs &lt;- unique(data_loss_raw$eval_qtr)\n\n# create dataset of all possible combos, then add the needed combos for the most recent year\n# -&gt; this is so that later in the process, data has rows of zero rather than no row if no losses were in that particular period\ndata_all_combos &lt;- expand.grid(vec_states, vec_loss_years, vec_loss_qtrs, vec_eval_years, vec_eval_qtrs) %&gt;% \n  data.frame\ncolnames(data_all_combos) &lt;- c(\"state\", \"loss_year\", \"loss_qtr\", \"eval_year\", \"eval_qtr\")\n\n# keep only valid periods\n# -&gt; set current eval quarter\ncur_eval_qtr &lt;- 3\ndata_all_combos %&lt;&gt;%\n  filter(loss_year &lt;= eval_year) %&gt;% \n  arrange(state, loss_year, loss_qtr, eval_year, eval_qtr) %&gt;% \n  mutate(keep = \n           case_when(\n             loss_year == eval_year & loss_qtr &gt; eval_qtr ~ 0, # illogical periods\n             loss_year == max(loss_year) & loss_qtr &gt; cur_eval_qtr ~ 0, # future periods\n             eval_year == max(eval_year) & eval_qtr &gt; cur_eval_qtr ~ 0, # future periods\n             .default = 1\n           )\n  ) %&gt;% \n  filter(keep != 0) %&gt;% \n  select(-keep)\n\n### ---- Modify data ----\n\n# premium data\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_premium_agg &lt;- data_premium_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, year == loss_year, qtr == loss_qtr)) %&gt;% \n  arrange(state, year, qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n# loss data\n# add placeholder rows to loss data\ndata_loss_raw2 &lt;- data_loss_raw %&gt;% \n  right_join(data_all_combos, by = join_by(state, loss_year, loss_qtr, eval_year, eval_qtr)) %&gt;% \n  arrange(state, loss_year, loss_qtr, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n# create age variable\ndata_loss &lt;- data_loss_raw2 %&gt;% \n  mutate(age = (eval_year - loss_year) * 12 + (eval_qtr - loss_qtr) * 3 + 3, # evaluating in same quarter as loss counts as 3 months of development\n         paid_loss_plus_lae = paid_loss + paid_lae + -subrogation_salvage,\n         incurred_loss = paid_loss_plus_lae + case_reserve + expense_reserve,\n         incurred_claim_count = cwp_count + open_count) \n\n# create summarized loss data by state and overall (cw)\ndata_loss_agg_age_cw &lt;- data_loss %&gt;% \n  summarize(.by = c(state, loss_year, loss_qtr, age),\n            across(c(paid_loss_plus_lae, incurred_loss, incurred_claim_count), \\(x) sum(x,na.rm = TRUE))) %&gt;% \n  arrange(state, loss_year, loss_qtr, age) %&gt;% \n  {. -&gt;&gt; data_loss_agg_age_st} %&gt;% \n  summarize(.by = c(loss_year, loss_qtr, age),\n            across(c(paid_loss_plus_lae, incurred_loss, incurred_claim_count), \\(x) sum(x,na.rm = TRUE)))\n\n# assumption of number of months to ultimate loss\nult_age &lt;- 63\n\n# reported frequency data\n# add placeholder rows to loss data\ndata_rept_freq_raw2 &lt;- data_rept_freq_raw %&gt;% \n  right_join(data_all_combos, by = join_by(state, rept_year == loss_year, rept_qtr == loss_qtr, eval_year, eval_qtr)) %&gt;% \n  arrange(state, rept_year, rept_qtr, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n# closed by closed evaluation date data\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_clsd_by_clsd_eval_date_agg &lt;- data_clsd_by_clsd_eval_date_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, eval_year == loss_year, eval_qtr == loss_qtr)) %&gt;% \n  arrange(state, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n# closed by evaluation date data\n# add placeholder rows to premium data\n# -&gt; note raw data is already aggregated\ndata_clsd_by_eval_date_agg &lt;- data_clsd_by_eval_date_raw %&gt;% \n  right_join(data_all_combos %&gt;% distinct(state, loss_year, loss_qtr), by = join_by(state, eval_year == loss_year, eval_qtr == loss_qtr)) %&gt;% \n  arrange(state, eval_year, eval_qtr) %&gt;%  \n  replace(is.na(.), 0)\n\n### ---- Premium trend ----\n\n# create summarized premium data overall (cw) and then combine\ndata_premium_agg_cw &lt;- data_premium_agg %&gt;% \n  group_by(year, qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_premium_agg %&lt;&gt;% bind_rows(data_premium_agg_cw)\n\n# summarize all columns by calendar year\ndata_premium_trend_calendar &lt;- data_premium_agg %&gt;% \n  select(state, year, qtr, on_level_earned_premium, earned_exposure) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(year,\"-Q\", qtr),\n               across(c(on_level_earned_premium, earned_exposure), \\(col) roll::roll_sum(col, width = 4)),\n               average_premium = ifelse(earned_exposure == 0, 0, on_level_earned_premium / earned_exposure)) %&gt;% \n        select(-c(year, qtr)) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits\ndata_prem_trend_fits &lt;- data_premium_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n      \n      calculate_weighted_fits(df_calendar = data, var = \"average_premium\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"average_premium\")\n\n### ---- Current level earned premium ----\n\n# calculate current level factor\ndata_premium_current_level &lt;- data_premium_agg %&gt;% \n  mutate(accident_quarter = paste0(year, \"-Q\", qtr),\n         current_level_factor = earned_premium == 0, 1, on_level_earned_premium / earned_premium) %&gt;% \n  select(state, accident_quarter, earned_premium, current_level_factor, on_level_earned_premium) %&gt;% \n  slice_tail(n = 21, by = state) # 5 years of data + 1 quarter\n\n# summarize data by fiscal year\ndata_premium_current_level_fiscal &lt;- summarize_by_fiscal_year(df = data_premium_current_level) %&gt;% \n  rename(earned_premium = var1_cumulative, current_level_factor = factor, current_level_earned_premium = var2_cumulative)\n\n### ---- Paid loss ----\n\n# format as triangle\ndata_paid_loss_triangle &lt;- format_bases_as_triangle(df_agg_age = data_loss_agg_age_cw, var = \"paid_loss_plus_lae\")\n\n# calculate development factors\ndata_paid_loss_dev &lt;- calculate_dev_factors(df_agg_age = data_loss_agg_age_cw, var = \"paid_loss_plus_lae\")\n\n# format as triangle\ndata_paid_loss_dev_triangle &lt;- format_dev_factors_as_triangle(df_dev = data_paid_loss_dev)\n\n### ---- Incurred loss ----\n\n# format as triangle\ndata_incurred_loss_triangle &lt;- format_bases_as_triangle(df_agg_age = data_loss_agg_age_cw, var = \"incurred_loss\")\n\n# calculate development factors\ndata_incurred_loss_dev &lt;- calculate_dev_factors(df_agg = data_loss_agg_age_cw, var = \"incurred_loss\")\n\n# format as triangle\ndata_incurred_loss_dev_triangle &lt;- format_dev_factors_as_triangle(df_dev = data_incurred_loss_dev)\n\n### ---- Incurred claim count ----\n\n# format as triangle\ndata_incurred_claim_count_triangle &lt;- format_bases_as_triangle(df_agg = data_loss_agg_age_cw, var = \"incurred_claim_count\")\n\n# calculate development factors\ndata_incurred_claim_count_dev &lt;- calculate_dev_factors(df_agg = data_loss_agg_age_cw, var = \"incurred_claim_count\")\n\n# format as triangle\ndata_incurred_claim_count_dev_triangle &lt;-  format_dev_factors_as_triangle(df_dev = data_incurred_claim_count_dev)\n\n### ---- Ultimate ----\n\n# summarize data\n# -&gt; create summarized loss data (accident quarter) by state, then overall (cw), and then combine\ndata_loss_agg &lt;- data_loss %&gt;% \n  filter(eval_year == max(eval_year)) %&gt;% # only use rows in most recent evaluation period\n  filter(eval_qtr == max(eval_qtr)) %&gt;% # -&gt; this makes it accident quarter\n  group_by(state, loss_year, loss_qtr) %&gt;% \n  summarize(across(starts_with(\"incurred\"), sum)) %&gt;% \n  ungroup\ndata_loss_agg_cw &lt;- data_loss_agg %&gt;% \n  group_by(loss_year, loss_qtr) %&gt;% \n  summarize(across(starts_with(\"incurred\"), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_loss_agg %&lt;&gt;% bind_rows(data_loss_agg_cw)\n\n### ---- Frequency trend ----\n\n# create summarized loss data (calendar quarter) by state, then overall (cw), and then combine\n# -&gt; data is already only using the most recent evaluation period\ndata_rept_freq_agg &lt;- data_rept_freq_raw2 %&gt;% \n  group_by(state, rept_year, rept_qtr) %&gt;% \n  summarize(reported_count = sum(reported_count)) %&gt;% \n  ungroup\ndata_rept_freq_agg_cw &lt;- data_rept_freq_agg %&gt;% \n  group_by(rept_year, rept_qtr) %&gt;% \n  summarize(reported_count = sum(reported_count)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_rept_freq_agg %&lt;&gt;% bind_rows(data_rept_freq_agg_cw)\n\n# create summarized closed by closed evaluation data (calendar quarter) overall (cw) and then combine\ndata_clsd_by_clsd_eval_date_agg_cw &lt;- data_clsd_by_clsd_eval_date_agg %&gt;% \n  group_by(eval_year, eval_qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_clsd_by_clsd_eval_date_agg %&lt;&gt;% bind_rows(data_clsd_by_clsd_eval_date_agg_cw)\n\n# summarize all columns by calendar year\ndata_freq_trend_calendar &lt;- data_premium_agg %&gt;% \n  select(state, year, qtr, earned_exposure) %&gt;% \n  left_join(data_rept_freq_agg %&gt;% select(state, rept_year, rept_qtr, reported_count), by = join_by(state, year == rept_year, qtr == rept_qtr)) %&gt;% \n  left_join(data_clsd_by_clsd_eval_date_agg %&gt;% select(state, eval_year, eval_qtr, closed_w_pay_count), by = join_by(state, year == eval_year, qtr == eval_qtr)) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  {. -&gt;&gt; data_freq_trend_agg} %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(year, \"-Q\", qtr),\n               across(c(earned_exposure, reported_count, closed_w_pay_count), \\(col) roll::roll_sum(col, width = 4)),\n               reported_freq = ifelse(earned_exposure == 0, NA, reported_count / earned_exposure),\n               closed_w_pay_freq = ifelse(earned_exposure == 0, NA, closed_w_pay_count / earned_exposure)) %&gt;% \n        select(calendar_quarter_ended, earned_exposure, reported_count, reported_freq, closed_w_pay_count, closed_w_pay_freq) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits one variable at a time, then combine\n# -&gt; reported frequency\ndata_freq_trend_fits_a &lt;- data_freq_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n      \n      calculate_weighted_fits(df_calendar = data, var = \"reported_freq\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"reported_freq\")\n# -&gt; closed with pay frequency\ndata_freq_trend_fits_b &lt;- data_freq_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n      \n      calculate_weighted_fits(df_calendar = data, var = \"closed_w_pay_freq\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"closed_w_pay_freq\")\n# -&gt; combine\ndata_freq_trend_fits &lt;- data_freq_trend_fits_a %&gt;% left_join(data_freq_trend_fits_b, by = join_by(state, pt))\n\n### ---- Severity trend ----\n\n# create summarized closed by evaluation data (calendar quarter) overall (cw) and then combine\ndata_clsd_by_eval_date_agg_cw &lt;- data_clsd_by_eval_date_agg %&gt;% \n  group_by(eval_year, eval_qtr) %&gt;% \n  summarize(across(where(is.numeric), sum)) %&gt;% \n  ungroup %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1)\ndata_clsd_by_eval_date_agg %&lt;&gt;% bind_rows(data_clsd_by_eval_date_agg_cw)\n\n# summarize all columns by calendar year\ndata_sev_trend_calendar &lt;- data_clsd_by_clsd_eval_date_agg %&gt;% \n  select(state, eval_year, eval_qtr, closed_w_pay_count, total_paid_loss_lae_net_of_s_s) %&gt;% \n  left_join(data_clsd_by_eval_date_agg %&gt;% select(state, eval_year, eval_qtr, total_paid_loss_lae_net_of_s_s, post_closure_total_paid_loss_lae_net_of_s_s), by = join_by(state, eval_year, eval_qtr), suffix = c(\"_clsdbyclsd\", \"_clsd\")) %&gt;% \n  rename(paid_loss = total_paid_loss_lae_net_of_s_s_clsd) %&gt;% \n  mutate(paid_on_closed_loss = total_paid_loss_lae_net_of_s_s_clsdbyclsd + post_closure_total_paid_loss_lae_net_of_s_s) %&gt;% \n  select(-c(post_closure_total_paid_loss_lae_net_of_s_s, total_paid_loss_lae_net_of_s_s_clsdbyclsd)) %&gt;% \n  slice_tail(n = 27, by = state) %&gt;% # 6 years of data + 3 quarters\n  {. -&gt;&gt; data_sev_trend_agg} %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data) {\n      \n      data %&gt;% \n        mutate(calendar_quarter_ended = paste0(eval_year, \"-Q\", eval_qtr),\n               across(c(closed_w_pay_count, paid_loss, paid_on_closed_loss), \\(col) roll::roll_sum(col, width = 4)),\n               paid_sev = ifelse(closed_w_pay_count == 0, NA, paid_loss / closed_w_pay_count),\n               paid_on_closed_sev = ifelse(closed_w_pay_count == 0, NA, paid_on_closed_loss / closed_w_pay_count)) %&gt;% \n        select(calendar_quarter_ended, closed_w_pay_count, paid_loss, paid_sev, paid_on_closed_loss, paid_on_closed_sev) %&gt;% \n        return\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  relocate(calendar_quarter_ended, .after = 1)\n\n# calculate weighted fits one variable at a time, then combine\n# -&gt; paid severity\ndata_sev_trend_fits_a &lt;- data_sev_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n      \n      calculate_weighted_fits(df_calendar = data, var = \"paid_sev\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"paid_sev\")\n# -&gt; paid on closed severity\ndata_sev_trend_fits_b &lt;- data_sev_trend_calendar %&gt;% \n  nest_by(state) %&gt;% \n  mutate(data = map(\n    .x = list(data),\n    .f = \\(data){\n      \n      calculate_weighted_fits(df_calendar = data, var = \"paid_on_closed_sev\")\n      \n    })\n  ) %&gt;% \n  reframe(data) %&gt;% \n  pivot_longer(cols = -1, names_to = \"pt\", values_to = \"paid_on_closed_sev\")\n# -&gt; combine\ndata_sev_trend_fits &lt;- data_sev_trend_fits_a %&gt;% left_join(data_sev_trend_fits_b, by = join_by(state, pt))\n\n### ---- Indication ----\n\n# calculate catastrophe ratios\n# -&gt; statewide\ndata_cat &lt;- data_rms_modeled_loss %&gt;% \n  mutate(modeled_hurricane_ratio = rms_hurricane_gross_aal / in_force_premium,\n         .keep = \"unused\") %&gt;% \n  left_join(data_ts_modeled_loss %&gt;% \n              mutate(modeled_fire_following_earthquake_ratio = touchstone_eq_fire_following_gross_aal / in_force_premium,\n                     modeled_severe_convective_storm_ratio = touchstone_severe_convective_storm_gross_aal / in_force_premium,\n                     modeled_wildfire_ratio = touchstone_wildfire_gross_aal / in_force_premium,\n                     .keep = \"unused\"),\n            by = join_by(state))\n# -&gt; Countrywide\ndata_cat_cw &lt;- data_rms_modeled_loss %&gt;% \n  summarize(modeled_hurricane_ratio = sum(rms_hurricane_gross_aal) / sum(in_force_premium)) %&gt;% \n  mutate(state = \"Countrywide\",\n         .before = 1) %&gt;% \n  left_join(data_ts_modeled_loss %&gt;% \n              summarize(modeled_fire_following_earthquake_ratio = sum(touchstone_eq_fire_following_gross_aal) / sum(in_force_premium),\n                        modeled_severe_convective_storm_ratio = sum(touchstone_severe_convective_storm_gross_aal) / sum(in_force_premium),\n                        modeled_wildfire_ratio = sum(touchstone_wildfire_gross_aal) / sum(in_force_premium)) %&gt;% \n              mutate(state = \"Countrywide\",\n                     .before = 1),\n            by = join_by(state))\n# -&gt; combine\ndata_cat %&lt;&gt;% bind_rows(data_cat_cw) \n\n### ---- Define UI ----\n\nui &lt;- grid_page(\n  layout = c(\n    \"header  results\",\n    \"sidebar results  \"\n  ),\n  row_sizes = c(\n    \"100px\",\n    \"1fr\"\n  ),\n  col_sizes = c(\n    \"400px\",\n    \"1fr\"\n  ),\n  gap_size = \"1rem\",\n  grid_card_text(\n    area = \"header\",\n    content = \"Quarterly indications\",\n    alignment = \"start\",\n    is_title = FALSE\n  ),\n  grid_card(\n    area = \"sidebar\",\n    card_body(\n      uiOutput(outputId = \"indicated_rates\"),\n      selectInput(\n        inputId = \"selection_state\",\n        label = \"Select state\",\n        choices = unique(data_premium_raw$state),\n        selected = \"California\"\n      ),\n      selectInput(\n        inputId = \"selection_Countrywide\",\n        label = \"Select Countrywide\",\n        choices = list(\n          \"Countrywide\" = \"Countrywide\",\n          \"Countrywide excluding California\" = \"Countrywide x california\"\n        ),\n        selected = \"Countrywide\"\n      ),\n      dateInput(inputId = \"selection_data_ended\",\n                            label = \"Data ended\",\n                            value = \"2024-06-30\",\n                            format = \"mm/dd/yyyy\"),\n      dateInput(inputId = \"selection_effective_date\",\n                            label = \"Proposed effective date\",\n                            format = \"mm/dd/yyyy\"),\n      grid_container(\n        layout = c(\n          \"selection_lcm selection_underlying_plr\"\n        ),\n        row_sizes = c(\n          \"110px\"\n        ),\n        col_sizes = c(\n          \"1fr\",\n          \"1fr\"\n        ),\n        gap_size = \"10px\",\n        grid_card(\n          area = \"selection_lcm\",\n          card_body(\n            numericInput(\n              inputId = \"selection_lcm\",\n              label = \"Select LCM\",\n              value = 1.669,\n              min = 0,\n              step = 0.01\n            )\n          )\n        ),\n        grid_card(\n          area = \"selection_underlying_plr\",\n          card_body(\n            textOutput(outputId = \"selection_underlying_plr\")\n          )\n        )\n      ),\n      grid_container(\n        layout = c(\n          \"premium_trend_cw premium_trend_sw\",\n          \"freq_trend_cw    freq_trend_sw   \",\n          \"sev_trend_cw     sev_trend_sw    \"\n        ),\n        row_sizes = c(\n          \"110px\",\n          \"110px\",\n          \"110px\"\n        ),\n        col_sizes = c(\n          \"1.15fr\",\n          \"0.85fr\"\n        ),\n        gap_size = \"10px\",\n        grid_card(\n          area = \"premium_trend_cw\",\n          card_body(\n            numericInput(\n              inputId = \"premium_trend_cw\",\n              label = \"Premium trend: CW\",\n              value = 0.075,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        ),\n        grid_card(\n          area = \"freq_trend_cw\",\n          card_body(\n            numericInput(\n              inputId = \"freq_trend_cw\",\n              label = \"Frequency trend: CW\",\n              value = 0.04,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        ),\n        grid_card(\n          area = \"sev_trend_cw\",\n          card_body(\n            numericInput(\n              inputId = \"sev_trend_cw\",\n              label = \"Severity trend: CW\",\n              value = 0.14,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        ),\n        grid_card(\n          area = \"premium_trend_sw\",\n          card_body(\n            numericInput(\n              inputId = \"premium_trend_sw\",\n              label = \"SW\",\n              value = 0.05,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        ),\n        grid_card(\n          area = \"freq_trend_sw\",\n          card_body(\n            numericInput(\n              inputId = \"freq_trend_sw\",\n              label = \"SW\",\n              value = 0.04,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        ),\n        grid_card(\n          area = \"sev_trend_sw\",\n          card_body(\n            numericInput(\n              inputId = \"sev_trend_sw\",\n              label = \"SW\",\n              value = 0.14,\n              min = 0,\n              max = 2,\n              step = 0.005\n            )\n          )\n        )\n      ),\n      actionButton(\n        inputId = \"other_inputs\",\n        label = \"Reload other inputs\",\n        width = \"100%\"\n      )\n    )\n  ),\n  card_body(\n    tabsetPanel(\n      nav_panel(\n        title = \"CW indication\",\n        grid_card(\n          area = \"indication_cw\",\n          card_body(\n            grid_container(\n              layout = c(\n                \"indication_summary_cw              indication_summary_cw     \",\n                \"indication_calculations_support_cw indication_calculations_cw\"\n              ),\n              gap_size = \"10px\",\n              col_sizes = c(\n                \"1fr\",\n                \"1fr\"\n              ),\n              row_sizes = c(\n                \"1fr\",\n                \"1fr\"\n              ),\n              grid_card(\n                area = \"indication_summary_cw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_summary_cw\"\n                                                      )\n                )\n              ),\n              grid_card(\n                area = \"indication_calculations_cw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_calculations_cw\"\n                                                      )\n                )\n              ),\n              grid_card(\n                area = \"indication_calculations_support_cw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_calculations_support_cw\"\n                                                      )\n                )\n              )\n            )\n          )\n        )\n      ),\n      nav_panel(\n        title = \"SW indication\",\n        grid_card(\n          area = \"indication_sw\",\n          card_body(\n            grid_container(\n              layout = c(\n                \"indication_summary_sw              indication_summary_sw     \",\n                \"indication_calculations_support_sw indication_calculations_sw\"\n              ),\n              row_sizes = c(\n                \"1fr\",\n                \"1fr\"\n              ),\n              col_sizes = c(\n                \"1fr\",\n                \"1fr\"\n              ),\n              gap_size = \"10px\",\n              grid_card(\n                area = \"indication_summary_sw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_summary_sw\"\n                                                      )\n                )\n              ),\n              grid_card(\n                area = \"indication_calculations_sw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_calculations_sw\"\n                                                      )\n                )\n              ),\n              grid_card(\n                area = \"indication_calculations_support_sw\",\n                card_body(\n                  gt_output(\n                                                        outputId = \"indication_calculations_support_sw\"\n                                                      )\n                )\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n)\n\n\n### ---- Define server ----\n\nserver &lt;- function(input, output) {\n  \n  ### Recalculate things based on selections / inputs\n  \n  # calculate selected underlying PLR\n  selection_underlying_plr &lt;- reactive({\n    \n    1 / input$selection_lcm\n    \n  }) %&gt;% \n    bindEvent(input$selection_lcm)\n  \n  # calculate evaluation date\n  selection_eval_date &lt;- reactive({\n    \n    ymd(input$selection_data_ended) %m+% months(3)\n    \n  }) %&gt;% \n    bindEvent(input$selection_data_ended)\n  \n  # display underlying PLR\n  output$selection_underlying_plr &lt;- renderText({\n    \n    paste0(\"Underlying PLR: \", round(selection_underlying_plr() * 100, 1), \"%\")\n    \n  })\n  \n  # input selections / input data after clicking action button\n  # -&gt; loss development factors\n  data_other_inputs &lt;- reactive({\n    \n    readxl::read_xlsx(path = \"app-inputs.xlsx\", sheet = \"long\")\n    \n  }) %&gt;% \n    bindEvent(input$other_inputs,\n              ignoreNULL = FALSE)\n  \n  # value box\n  output$indicated_rates &lt;- renderUI(\n      \n      HTML(paste0(\"&lt;h3 style = 'color: orange'&gt;Countrywide = \", data_indication3() %&gt;% filter(state == \"Countrywide\") %&gt;% pull(indicated_rate_level_needed) %&gt;% as.numeric %&gt;% multiply_by(100) %&gt;% round(1), \"%&lt;/h3&gt;\",\n                  \"&lt;h3 style = 'color: orange'&gt;\", input$selection_state, \" = \", data_indication3() %&gt;% filter(state == input$selection_state) %&gt;% pull(indicated_rate_level_needed) %&gt;% as.numeric %&gt;% multiply_by(100) %&gt;% round(1), \"%&lt;/h3&gt;\"))\n  \n  )\n  \n  ### Recalculate datasets now based on inputs\n  \n  # premium trend\n  # -&gt; calculate Countrywide selections\n  data_premium_trend_selected_cw &lt;- reactive({\n    \n    data_premium_agg %&gt;% \n      filter(state == \"Countrywide\") %&gt;% \n      slice_tail(n = 4) %&gt;% \n      summarize(credibility = sum(earned_exposure) %&gt;% multiply_by(0.035) %&gt;% divide_by(1084) %&gt;% sqrt) %&gt;% \n      mutate(state = \"Countrywide\",\n             selected = input$premium_trend_cw,\n             credibility_comp = 0.016,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n    \n  })\n  \n  # premium trend\n  # -&gt; calculate state selections and add back in Countrywide\n  data_premium_trend_selected &lt;- reactive({\n    \n    data_premium_agg %&gt;% \n      filter(state != \"Countrywide\") %&gt;% \n      slice_tail(n = 4,\n                 by = state) %&gt;% \n      summarize(.by = state,\n                credibility = sum(earned_exposure) %&gt;% multiply_by(0.035) %&gt;% divide_by(1084) %&gt;% sqrt) %&gt;% \n      mutate(selected = input$premium_trend_sw,\n             credibility_comp = data_premium_trend_selected_cw()$z_wtd_selected,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n      bind_rows(data_premium_trend_selected_cw())\n    \n  })\n  \n  # paid loss\n  # -&gt; weighted development factors\n  data_paid_loss_selects &lt;- reactive({\n    \n    calculate_weighted_dev_factors(df_loss_tri = data_paid_loss_triangle, selects = data_other_inputs() %&gt;% \n                                     filter(table == \"loss development factors\", key2 == \"Paid loss\") %&gt;% \n                                     pull(value))\n    \n  })\n  \n  # incurred loss\n  # -&gt; weighted development factors\n  data_incurred_loss_selects &lt;- reactive({\n    \n    calculate_weighted_dev_factors(df_loss_tri = data_incurred_loss_triangle, selects = data_other_inputs() %&gt;% \n                                     filter(table == \"loss development factors\", key2 == \"Incurred loss\") %&gt;% \n                                     pull(value))\n    \n  })\n  \n  # incurred claim count\n  # -&gt; weighted development factors\n  data_incurred_claim_count_selects &lt;- reactive({\n    \n    calculate_weighted_dev_factors(df_loss_tri = data_incurred_claim_count_triangle, selects = data_other_inputs() %&gt;% \n                                     filter(table == \"loss development factors\", key2 == \"Incurred claim count\") %&gt;% \n                                     pull(value))\n    \n  })\n  \n  # ultimate loss\n  # -&gt; append age to ultimate factors and calculate ultimate losses \n  data_ult_loss &lt;- reactive({\n    \n    calculate_ultimate_incurred(df_agg = data_loss_agg, df_selects = data_incurred_loss_selects(), var = \"incurred_loss\") %&gt;% \n      rename(incurred_loss = incurred, incurred_age_to_ult = factor, ult_incurred_loss = ult_incurred)\n    \n  })\n  \n  # -&gt; summarize data by fiscal year\n  data_ult_loss_fiscal &lt;- reactive({\n    \n    summarize_by_fiscal_year(df = data_ult_loss()) %&gt;% \n      rename(incurred_loss = var1_cumulative, implied_incurred_age_to_ult = factor, ult_incurred_loss = var2_cumulative)\n    \n  })\n  \n  # claim count\n  # -&gt; append age to ultimate factors and calculate ultimate claim count\n  data_ult_claim_count &lt;- reactive({\n    \n    calculate_ultimate_incurred(df_agg = data_loss_agg, df_selects = data_incurred_claim_count_selects(), var = \"incurred_claim_count\") %&gt;% \n      rename(incurred_claim_count = incurred, implied_incurred_age_to_ult = factor, ult_incurred_claim_count = ult_incurred)\n    \n  })\n  \n  # -&gt; summarize data by fiscal year\n  data_ult_claim_count_fiscal &lt;- reactive({\n    \n    summarize_by_fiscal_year(df = data_ult_claim_count()) %&gt;% \n      rename(incurred_claim_count = var1_cumulative, implied_incurred_age_to_ult = factor, ult_incurred_claim_count = var2_cumulative)\n    \n  })\n  \n  # frequency trend\n  # -&gt; calculate Countrywide selections\n  data_freq_trend_selected_cw &lt;- reactive({\n    \n    data_freq_trend_agg %&gt;% \n      filter(state == \"Countrywide\") %&gt;% \n      slice_tail(n = 4) %&gt;% \n      summarize(credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n      mutate(state = \"Countrywide\",\n             selected = input$freq_trend_cw,\n             credibility_comp = 0,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n    \n  })\n  \n  # -&gt; calculate state selections and add back in Countrywide\n  data_freq_trend_selected &lt;- reactive({\n    \n    data_freq_trend_agg %&gt;% \n      filter(state != \"Countrywide\") %&gt;% \n      slice_tail(n = 4,\n                 by = state) %&gt;% \n      summarize(.by = state,\n                credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n      mutate(selected = input$freq_trend_sw,\n             credibility_comp = data_freq_trend_selected_cw()$z_wtd_selected,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n      bind_rows(data_freq_trend_selected_cw())\n    \n  })\n  \n  # severity trend\n  # -&gt; calculate Countrywide selections\n  data_sev_trend_selected_cw &lt;- reactive({\n    \n    data_sev_trend_agg %&gt;% \n      filter(state == \"Countrywide\") %&gt;% \n      slice_tail(n = 4) %&gt;% \n      summarize(credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n      mutate(state = \"Countrywide\",\n             selected = input$sev_trend_cw,\n             credibility_comp = 0.02,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility))\n    \n  })\n  \n  # -&gt; calculate state selections and add back in Countrywide\n  data_sev_trend_selected &lt;- reactive({\n    \n    data_sev_trend_agg %&gt;% \n      filter(state != \"Countrywide\") %&gt;% \n      slice_tail(n = 4,\n                 by = state) %&gt;% \n      summarize(.by = state,\n                credibility = sum(closed_w_pay_count) %&gt;% divide_by(3000) %&gt;% sqrt) %&gt;% \n      mutate(selected = input$sev_trend_sw,\n             credibility_comp = data_sev_trend_selected_cw()$z_wtd_selected,\n             z_wtd_selected = selected * credibility + credibility_comp * (1 - credibility)) %&gt;% \n      bind_rows(data_sev_trend_selected_cw())\n    \n  })\n  \n  # input selections / input data after clicking action button (again...)\n  # -&gt; accident year weights\n  selection_ay_weights &lt;- reactive({\n    \n    data_ult_loss_fiscal() %&gt;%\n      filter(state != \"Countrywide\") %&gt;%\n      distinct(state, fiscal_year_ended) %&gt;%\n      bind_cols(data.frame(ay_weights = rep(data_other_inputs() %&gt;%\n                                              filter(table == \"accident year weights\", key1 == \"Statewide\") %&gt;%\n                                              pull(value), nrow(.) / 5)))\n    \n  })\n  selection_ay_weights_cw &lt;- reactive({\n    \n    data_ult_loss_fiscal() %&gt;%\n      distinct(fiscal_year_ended) %&gt;%\n      bind_cols(data.frame(ay_weights = data_other_inputs() %&gt;%\n                             filter(table == \"accident year weights\", key1 == \"Complement\") %&gt;%\n                             pull(value))) %&gt;%\n      mutate(state = \"Countrywide\")\n    \n  })\n  selection_ay_weights2 &lt;- reactive({\n    \n    selection_ay_weights() %&gt;% bind_rows(selection_ay_weights_cw())\n    \n  })\n  \n  # indication\n  # -&gt; calculate indication table\n  data_indication &lt;- reactive({\n    \n    data_premium_current_level_fiscal %&gt;%\n      select(state, fiscal_year_ended, current_level_earned_premium) %&gt;%\n      mutate(trend_time_premium =\n               case_when(\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 0 ~ 12,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 1 ~ 24,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 2 ~ 36,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 3 ~ 48,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 4 ~ 60\n               )) %&gt;%\n      left_join(data_premium_trend_selected() %&gt;% select(state, prem_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;%\n      mutate(premium_trend_factors = prem_trend_z_wtd_selected %&gt;%\n               add(1) %&gt;%\n               # raise_to_power(interval(ymd(selection_data_ended) %m-% years(5),\n               #                         ymd(selection_effective_date) %m+% months(6)) %&gt;%\n               #                  divide_by(years(1))) %&gt;% # more accurate way\n               raise_to_power(subtract(ymd(input$selection_effective_date) %m+% months(6),\n                                       ymd(input$selection_data_ended) %m-% months(trend_time_premium)) %&gt;%\n                                divide_by(365) %&gt;% as.numeric), # equivalent to excel\n             trended_current_level_earned_premium = current_level_earned_premium * premium_trend_factors\n      ) %&gt;%\n      left_join(data_ult_loss_fiscal() %&gt;% select(state, fiscal_year_ended, incurred_loss, implied_incurred_age_to_ult, ult_incurred_loss), join_by(state, fiscal_year_ended)) %&gt;%\n      left_join(data_freq_trend_selected() %&gt;% select(state, freq_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;%\n      left_join(data_sev_trend_selected() %&gt;% select(state, sev_trend_z_wtd_selected = z_wtd_selected), by = join_by(state)) %&gt;%\n      mutate(trend_time_loss =\n               case_when(\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 0 ~ 6,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 1 ~ 18,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 2 ~ 30,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 3 ~ 42,\n                 year(ymd(input$selection_data_ended)) - as.numeric(str_sub(fiscal_year_ended, start = 1, end = 4)) == 4 ~ 54\n               ),\n             loss_trend_factors = freq_trend_z_wtd_selected %&gt;%\n               add(1) %&gt;%\n               multiply_by(sev_trend_z_wtd_selected\n                           %&gt;% add(1))%&gt;%\n               raise_to_power(subtract(ymd(input$selection_effective_date) %m+% months(12),\n                                       ymd(input$selection_data_ended) %m-% months(trend_time_loss)) %&gt;%\n                                divide_by(365) %&gt;% as.numeric),\n             trended_ult_incurred_loss = ult_incurred_loss * loss_trend_factors,\n             trended_ult_incurred_partial_loss_ratio = ifelse(trended_current_level_earned_premium == 0, NA, trended_ult_incurred_loss / trended_current_level_earned_premium)) %&gt;%\n      left_join(selection_ay_weights2(), by = join_by(state, fiscal_year_ended))\n    \n  })\n  \n  # -&gt; final indication calculations\n  data_indication2 &lt;- reactive({\n    \n    data_indication() %&gt;%\n      nest_by(state) %&gt;%\n      mutate(data = map(\n        .x = list(data),\n        .f = \\(data) {\n          \n          data %&gt;%\n            mutate(trended_ult_incurred_partial_loss_ratio = replace_na(trended_ult_incurred_partial_loss_ratio, 0)) %$%\n            crossprod(trended_ult_incurred_partial_loss_ratio, ay_weights) %&gt;%\n            data.frame(ay_weighted_trended_ult_incurred_partial_loss_ratio = .) %&gt;%\n            return\n          \n        })\n      ) %&gt;%\n      reframe(data) %&gt;%\n      left_join(data_ult_claim_count_fiscal() %&gt;%\n                  summarize(.by = state, ult_incurred_claim_count = sum(ult_incurred_claim_count)) %&gt;%\n                  rowwise() %&gt;%\n                  mutate(credibility = ult_incurred_claim_count %&gt;% divide_by(1084) %&gt;% sqrt %&gt;% min(., 1)) %&gt;%\n                  select(state, credibility),\n                by = join_by(state)) %&gt;%\n      left_join(data_cat, by = join_by(state)) %&gt;%\n      rowwise() %&gt;%\n      mutate(total_modeled_peril_partial_loss_ratio = sum(modeled_hurricane_ratio, modeled_fire_following_earthquake_ratio, modeled_severe_convective_storm_ratio, modeled_wildfire_ratio) * 1.15,\n             trended_underlying_plr_less_modeled_perils = case_when(\n               state == \"Countrywide\" ~ selection_underlying_plr() %&gt;%\n                 subtract(total_modeled_peril_partial_loss_ratio) %&gt;%\n                 multiply_by(data_freq_trend_selected_cw()$selected %&gt;%\n                               add(1)) %&gt;%\n                 multiply_by(data_sev_trend_selected_cw()$selected %&gt;%\n                               add(1)) %&gt;%\n                 divide_by(data_premium_trend_selected_cw()$selected %&gt;%\n                             add(1)),\n               .default = NA),\n             credibility_weighted_trended_ult_incurred_loss_ratio = case_when(\n               state == \"Countrywide\" ~ ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;%\n                 multiply_by(credibility) %&gt;%\n                 add(trended_underlying_plr_less_modeled_perils %&gt;%\n                       multiply_by(1 %&gt;%\n                                     subtract(credibility))),\n               .default = NA)\n      )\n    \n  })\n  \n  # -&gt; set constant\n  credibility_weighted_trended_ult_incurred_loss_ratio_cw &lt;- reactive({\n    \n    data_indication2() %&gt;%\n      filter(state == \"Countrywide\") %&gt;%\n      pull(credibility_weighted_trended_ult_incurred_loss_ratio) %&gt;%\n      as.numeric\n    \n  })\n  \n  # -&gt; continue final indication calculations\n  data_indication3 &lt;- reactive({\n    \n    data_indication2() %&gt;%\n      mutate(cw_ay_weighted_trended_ult_incurred_partial_loss_ratio = case_when(\n        state != \"Countrywide\" ~ credibility_weighted_trended_ult_incurred_loss_ratio_cw(),\n        .default = NA),\n        credibility_weighted_trended_ult_incurred_loss_ratio = case_when(\n          state != \"Countrywide\" ~ ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;%\n            multiply_by(credibility) %&gt;%\n            add(cw_ay_weighted_trended_ult_incurred_partial_loss_ratio %&gt;%\n                  multiply_by(1 %&gt;%\n                                subtract(credibility))),\n          .default = credibility_weighted_trended_ult_incurred_loss_ratio\n        ),\n        margin_for_reinsurance = 0,\n        total_prospective_loss_ratio = credibility_weighted_trended_ult_incurred_loss_ratio + total_modeled_peril_partial_loss_ratio + margin_for_reinsurance,\n        permissable_loss_ratio = 0.601,\n        indicated_rate_level_needed = total_prospective_loss_ratio / permissable_loss_ratio - 1)\n    \n  })\n  \n  # -&gt; organize, convert to long data, and reformat variable names for displaying\n  data_indication3_long &lt;- reactive({\n    \n    data_indication3() %&gt;% \n      select(state, ay_weighted_trended_ult_incurred_partial_loss_ratio, credibility, trended_underlying_plr_less_modeled_perils, cw_ay_weighted_trended_ult_incurred_partial_loss_ratio, credibility_weighted_trended_ult_incurred_loss_ratio, starts_with(\"modeled\"), total_modeled_peril_partial_loss_ratio, margin_for_reinsurance, total_prospective_loss_ratio, permissable_loss_ratio, indicated_rate_level_needed) %&gt;% \n      pivot_longer(cols = -1,\n                   names_to = \"variable\",\n                   values_to = \"value\") %&gt;% \n      mutate(variable_display = \n               case_when(\n                 variable == \"ay_weighted_trended_ult_incurred_partial_loss_ratio\" ~ \"Accident year weighted trended ultimate incurred partial loss ratio:\",\n                 variable == \"credibility\" ~ \"Credibility (ultimate claims using 1,084 standard):\",\n                 variable == \"trended_underlying_plr_less_modeled_perils\" ~ \"Trended, underlying permissible loss ratio less modeled perils:\",\n                 variable == \"cw_ay_weighted_trended_ult_incurred_partial_loss_ratio\" ~ \"Countrywide accident year weighted trended ultimate ncurred partial loss + LAE ratio:\",\n                 variable == \"credibility_weighted_trended_ult_incurred_loss_ratio\" ~ \"Credibility weighted trended ultimate incurred loss + LAE ratio:\",\n                 variable == \"modeled_hurricane_ratio\" ~ \"Modeled hurricane ratio:\",\n                 variable == \"modeled_fire_following_earthquake_ratio\" ~ \"Modeled fire following earthquake ratio:\", \n                 variable == \"modeled_severe_convective_storm_ratio\" ~ \"Modeled severe convective storm ratio:\",\n                 variable == \"modeled_wildfire_ratio\" ~ \"Modeled wildfire ratio:\",\n                 variable == \"total_modeled_peril_partial_loss_ratio\" ~ \"Total modeled peril partial loss + LAE ratio (modeled ratios x 1.15 LAE factor):\",\n                 variable == \"margin_for_reinsurance\" ~ \"Margin for reinsurance:\",\n                 variable == \"total_prospective_loss_ratio\" ~ \"Total prospective loss + LAE ratio:\",\n                 variable == \"permissable_loss_ratio\" ~ \"Permissable loss + LAE ratio:\",\n                 variable == \"indicated_rate_level_needed\" ~ \"Indicated rate level needed:\"\n               ),\n             .after = variable\n      )\n    \n  })\n  \n  ### Display results\n  \n  # countrywide indication summary table\n  output$indication_summary_cw &lt;- render_gt(\n    \n    format_as_indication_summary(data_ind = data_indication(), sel_state = \"Countrywide\", sel_data_ended = input$selection_data_ended, sel_eval_date = selection_eval_date())\n    \n  )\n  \n  # countrywide indication calculations table\n  output$indication_calculations_cw &lt;- render_gt(\n    \n    format_as_indication_calculations(data_ind3_long = data_indication3_long(), sel_state = \"Countrywide\")\n    \n  )\n  \n  # countrywide indication calculations supporting table\n  output$indication_calculations_support_cw &lt;- render_gt(\n    \n    format_as_indication_calculations_support(data_ind3_long = data_indication3_long(), sel_state = \"Countrywide\")\n    \n  )\n  \n  # statewide indication summary table\n  output$indication_summary_sw &lt;- render_gt(\n    \n    format_as_indication_summary(data_ind = data_indication(), sel_state = input$selection_state, sel_data_ended = input$selection_data_ended, sel_eval_date = selection_eval_date())\n    \n  )\n  \n  # statewide indication calculations table\n  output$indication_calculations_sw &lt;- render_gt(\n    \n    format_as_indication_calculations(data_ind3_long = data_indication3_long(), sel_state = input$selection_state)\n    \n  )\n  \n  # statewide indication calculations supporting table\n  output$indication_calculations_support_sw &lt;- render_gt(\n    \n    format_as_indication_calculations_support(data_ind3_long = data_indication3_long(), sel_state = input$selection_state)\n    \n  )\n  \n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R</span>"
    ]
  }
]